<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小毛驴</title>
  <icon>https://www.gravatar.com/avatar/f846aadee6c8f6f3945510781c210bbf</icon>
  <subtitle>Adventure may hurt you, but monotony will kill you.</subtitle>
  <link href="http://xudongyang.coding.me/atom.xml" rel="self"/>
  
  <link href="http://xudongyang.coding.me/"/>
  <updated>2020-12-07T06:26:09.780Z</updated>
  <id>http://xudongyang.coding.me/</id>
  
  <author>
    <name>yangxudong</name>
    <email>yangxudongsuda@gmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>网页文本内容安全风险识别算法</title>
    <link href="http://xudongyang.coding.me/web-risk-detect/"/>
    <id>http://xudongyang.coding.me/web-risk-detect/</id>
    <published>2020-12-07T06:21:33.000Z</published>
    <updated>2020-12-07T06:26:09.780Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>随着互联网扁平化的发展，内容信息的分发和获取比以往更加便利，这也大大方便了以色情、赌博、非法政治言论、违禁药品买卖等为代表的违规信息的快速传播。这类信息的传播会造成难以估计的社会影响，甚至有可能影响国家的安定和谐。网站所有者可以随意更改网站页面的内容，发布任意形式的信息。论坛、博客、社交产品等web 2.0的网站可以让普通用户随意发布UGC内容。安全防控做得不到位的网站页面内容还可能被黑客随意篡改，甚至安装木马病毒。综上，网站页面内容的生成方式多种多样，内容发布者也是形形色色，其中就会有不少不法分子利用网络传播违规信息以达到非法牟利，甚至控制网民意识形态，颠覆国家政权的目的。</p><p>为了净化云平台以及维护网络环境的安全和稳定，对云上网站中存在的各类违规内容进行治理成为了意义重大又迫在眉睫的问题。本文主要介绍如何通过深度学习算法检测网页中是否包含了特定类型的违规内容。<br><a id="more"></a></p><h2 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h2><p>网页内容安全风险识别体系由数据资产构建和算法模型构建两方面组成，整体框架如下图所示。</p><p><img src="https://ftp.bmp.ovh/imgs/2020/09/d2c33817128febf8.jpg" alt="算法框架.jpg"></p><h3 id="数据资产构建"><a href="#数据资产构建" class="headerlink" title="数据资产构建"></a>数据资产构建</h3><h4 id="1-语料库"><a href="#1-语料库" class="headerlink" title="1. 语料库"></a>1. 语料库</h4><p>为了训练有效的算法模型，我们需要较多的训练样本。可以用爬虫来采集网页，构建训练数据集。</p><p>下面以非法政治风险为例，简要介绍如何构建训练语料。通过爬虫采集的方式，从海外主要的反华媒体，如新唐人电视台、大纪元、品葱、膜乎、中文禁文网等采集一批黑样本页面；从国内主要涉政媒体，如中国政府网、人民网、政治家网、求是网等采集一批白样本数据。当然，采集的语料的标签不完全正确，还需要集合其他技术手段做数据清洗。</p><h4 id="2-敏感词规则"><a href="#2-敏感词规则" class="headerlink" title="2. 敏感词规则"></a>2. 敏感词规则</h4><p>敏感词规则主要用来召回风险，是风险防控的第一道漏斗。对风险识别算法的最终效果、服务性能都有重要的影响。另外一方面，敏感词规则在语料集数据清洗、网页敏感文本抽取、特征工程等多个环节都有重要的作用。</p><p>敏感词规则可以从各个渠道收集整理而来，比如针对色情风险，我们可以很容易找到很多AV女优名单。另外，也可以从语料库中挖掘敏感词规则。针对有标签的语料，我们采用RuleLearning算法挖掘敏感词规则。针对无监督语料，我们使用TopMine算法自动生成候选短语，再通过人工review的方式确定最终使用的敏感词集合。</p><h3 id="算法模型构建"><a href="#算法模型构建" class="headerlink" title="算法模型构建"></a>算法模型构建</h3><h4 id="1-文本预处理"><a href="#1-文本预处理" class="headerlink" title="1. 文本预处理"></a>1. 文本预处理</h4><p>文本预处理模块包括HTML代码解析与文本归一化两部分。</p><ul><li>HTML代码解析</li></ul><p>HTML代码解析不仅仅是去除HTML标签保留纯文本，有两个重要的行动是保障算法效果的必要步骤。第一，是要根据CSS样式代码去除掉在页面渲染时无法展示的干扰内容；第二，是<strong>要尽可能保留页面内容的区块、段落、分行结构</strong>，这一步是为了保障敏感词规则匹配时尽可能减少误匹配。举例而言，敏感词规则有很多形如“A&amp;B”这样的规则，那么A和B这两个子串如果分别在不同的区块、段落、甚至在不同行之间的匹配都是我们不希望的。因此，解析HTML代码需要细粒度识别每个HTML元素的语义，比如是块元素还是内联元素等，以及需要考虑是否与前一个元素内容连接等因素。</p><ul><li>文本归一化</li></ul><p>文本归一化模块提供一些通用的变异文本还原功能，主要包括：</p><ol><li>繁体转简体</li><li>全角转半角</li><li>大写转小写</li><li>html实体符号还原：<code>&quot;&amp;lambda;&quot; -&gt; &quot;λ&quot;; &quot;&amp;lt;&quot; -&gt; &quot;&lt;&quot;; &quot;&amp;nbsp;&quot; -&gt; 空格</code></li><li>unicode字符规范化：<code>① -&gt; 1 ; ㊉㊚ -&gt; 十男 ; ㏴  -&gt;  21日</code></li><li>html标签去除:  <code>&lt;div style=&#39;xxx&#39;&gt;hello world&lt;/div&gt;   -&gt;   hello world</code></li><li>emoji表情转汉字：<code>“🇨🇳🇺🇸📦📽️🇩🇪⬅️🏊🐓”-&gt;“中美合拍的西游记”</code></li><li>拆分字合并：<code>三去车仓工力 -&gt; 法轮功</code></li><li>特殊符号过滤</li><li>抽象字还原：<code>艹比 -&gt; 操逼; 六亖 -&gt; 六四; 六罒事件 -&gt; 六四事件</code></li></ol><p>举例如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：😲！㊥.國Zui.無.耳止 的&lt;strong&gt;謊.訁&lt;&#x2F;strong&gt;就要大.白.於天.㊦</span><br><span class="line">输出：震惊 中国最无耻的谎言就要大白于天下</span><br></pre></td></tr></table></figure></p><h4 id="2-特征工程"><a href="#2-特征工程" class="headerlink" title="2. 特征工程"></a>2. 特征工程</h4><ul><li>HTML标签特征</li></ul><p>除了常规的字符embedding（中文汉字，英文wordpiece）和位置embedding特征之外，我们根据网页内容的特点加入了<strong>html标签embedding</strong>。根据云管控业务的管控标准，某些风险如网络招嫖、赌博等违规内容需要有明显的联系方式或者超链接才会判定为违规。另外，网页信息的展现样式跟html标签有很强的关联，因此文本内容对应的html标签路径是一个很有用的特征。我们选择了一些重要的html标签，比如<code>&lt;a&gt;</code>等，作为模型的特征之一。</p><ul><li>文本数据增强</li></ul><p>数据增强是提升深度学习模型鲁棒性的一种重要手段。在少样本学习、正负类别样本分布不平衡、半监督学习等场景，通过数据增强给数据加上杠杆，是快速提升模型效果的一种简单易行的方法。</p><p>典型文本数据增强技术方案包括EDA、回译（Back translation）、基于上下文信息的文本增强、基于语言生成模型的文本增强等。</p><p>EDA是一种简单有效且实现成本低的方法，具体操作包括随机词删除、同义词替换、同义词插入、位置交换等。中文的同义词可以使用哈工大开源的同义词词林，或者使用阿里NLP团队的相关积累。另一种思路是使用word2vec模型生成近义词/相关词，用近义词替换或插入来做数据增强，这种方法可以大大扩充近义词数量，但也有改变原始文本的语义的风险。由于我们的业务场景需要从一大段文本中提取文本片段，因此我还尝试了通过<strong>平移或缩放滑动窗口</strong>的方法来生成数据增强的候选文本，这种方法可以在不改变语义的情况下获取大量的增强文本，也是一种很好用的方法。</p><p>得益于近几年文本翻译领域的显著进展、各种先进翻译模型的开源（包括百度、google 等翻译工具的接口开放），基于回译（back translation）方法的文本数据增强成为了质量高又几乎无技术门槛的通用文本增强技术。回译方法的基本流程很简单，利用翻译模型将语种1的原始文本翻译为语种2的文本表达，基于语种2的表达再翻译为语种3的文本表达，最后再直接从语种3的形式翻译回语种1的文本表达，此文本即是原始文本增强后的文本。当然，很多时候只采用一种中间语种也可以实现很好的增强效果。</p><p>基于上下文信息的文本增强技术在原理上也很直观：首先需要一个训练好的语言模型（LM），对于需要增强的原始文本，随机去掉文中的一个词或字（这取决于语言模型支持字还是词）。接下来，将文本的剩余部分输入语言模型，选择语言模型所预测的 top k 个词去替换原文中被去掉的词，以形成 k 条新的文本。</p><p>文本数据增强还有不少其他方法值得进一步探索，比如文本风格迁移等。该方法之所以有效，首先它无疑是一种有效的正则化方法，无论是回译、EDA、非核心词替换还是基于上下文的文本增强，本质上都是设计者表达了一种模型偏好（归纳偏置），或者对于模型的分布施加了较强的先验分布假设。其中，回译表达的模型偏好是，模型应该对于不同表达形式但同一语义的文本具有不变性。EDA、关键词替换等表达的模型偏好则是，模型应该对于文本的局部噪声不敏感，实现了类似于 dropout 层的功能。任何学习都需要有效的外部信息指导，上面所提的基于上下文信息的文本增强技术的有效性无疑也可以从迁移学习的角度来理解。因此，即使面临少样本场景，基于文本增强的模型也能够在假设空间中有效地收敛，实现较好的泛化误差。</p><h4 id="3-文本Encoder-DGCNN模型"><a href="#3-文本Encoder-DGCNN模型" class="headerlink" title="3. 文本Encoder: DGCNN模型"></a>3. 文本Encoder: DGCNN模型</h4><p>文本编码器采用了膨胀门卷积神经网络（Dilate Gated Convolutional Neural Network），基于膨胀卷积和门卷积的CNN和简单的Attention的模型，由于没有用到RNN和Transformer结构，因此速度相当快。模型结构如下图所示。</p><p><img src="https://ata2-img.oss-cn-zhangjiakou.aliyuncs.com/3cf1d5d0c12fdd89e655c18ab54c6def.jpg" alt="DGCNN.jpg"></p><p>模型中采用的门卷积结构，来自FaceBook的《Convolutional Sequence to Sequence Learning》。假设我们要处理的向量序列是$\boldsymbol{X}=[\boldsymbol{x}_1,\boldsymbol{x}_2,\dots,\boldsymbol{x}_n]$，那么我们可以给普通的一维卷积加个门：<script type="math/tex">\boldsymbol{Y}=\text{Conv1D}_1(\boldsymbol{X}) \otimes \sigma\Big(\text{Conv1D}_2(\boldsymbol{X})\Big)\tag{1}</script><br>这里的两个Conv1D形式一样（比如卷积核数、窗口大小都一样），但权值是不共享的，也就是说参数翻倍了，其中一个用sigmoid函数激活，另外一个不加激活函数，然后将它们逐位相乘。因为sigmoid函数的值域是(0,1)，所以直觉上来看，就是给Conv1D的每个输出都加了一个“阀门”来控制流量。这就是GCNN的结构了，可以将这种结构看成一个激活函数，称为GLU（Gated Linear Unit）。进一步，可以采用残差结构使得信息能够在多通道传输。</p><script type="math/tex; mode=display">\boldsymbol{Y}=\boldsymbol{X} + \text{Conv1D}_1(\boldsymbol{X}) \otimes \sigma\Big(\text{Conv1D}_2(\boldsymbol{X})\Big)\tag{2}</script><p>接下来，为了使得CNN模型能够捕捉更远的的距离，并且又不至于增加模型参数，我们使用了膨胀卷积。普通卷积跟膨胀卷积的对比如下图所示。</p><p><img src="https://spaces.ac.cn/usr/uploads/2018/04/3933779911.png" alt="普通卷积vs膨胀卷积"></p><p>同样是三层的卷积神经网络（第一层是输入层），窗口大小为3。普通卷积在第三层时，每个节点只能捕捉到前后3个输入，而跟其他输入完全不沾边。</p><p>而膨胀卷积在第三层时则能够捕捉到前后7个输入，但参数量和速度都没有变化。这是因为在第二层卷积时，膨胀卷积跳过与中心直接相邻的输入，直接捕捉中心和次相邻的输入（膨胀率为2），也可以看成是一个“窗口大小为5的、但被挖空了两个格的卷积”，所以膨胀卷积也叫空洞卷积（Atrous Convolution）。在第三层卷积时，则连续跳过了三个输入（膨胀率为4），也可以看成一个“窗口大小为9、但被挖空了6个格的卷积”。而如果在相关的输入输出连一条线，就会发现第三层的任意一个节点，跟前后7个原始输入都有联系。</p><p>按照“尽量不重不漏”的原则，膨胀卷积的膨胀率一般是按照1、2、4、8、…这样的几何级数增长。</p><h4 id="4-学习范式：多示例学习"><a href="#4-学习范式：多示例学习" class="headerlink" title="4. 学习范式：多示例学习"></a>4. 学习范式：多示例学习</h4><p>多示例学习(multiple-instance learning)与监督学习、半监督学习和非监督学习有所不同，它是以多示例包(bag)为训练单元的学习问题。在此类学习中，训练集由若干个具有标签的包组成，每个包包含若干没有标签的示例。若一个包中至少有一个正例，则该包被标记为正（positive），若一个包中所有示例都是反例，则包被标记为反（negative）。通过对训练包的学习，希望学习系统尽可能正确地对训练集之外的包的标签进行预测。</p><p>与监督学习相比，多示例学习中的训练示例是没有标签的，这与监督学习中所有训练示例都有标签不同；与非监督学习相比，多示例学习中训练包是有标签的，这与非监督学习的训练样本中没有任何标签也不同。更重要的是，在以往的各种学习框架中，一个样本就是一个示例，即样本和示例是一一对应关系；而在多示例学习中，一个样本（包）包含了多个示例，即样本和示例是一对多的关系。</p><p>对应到网页风险识别场景，我们从每个网页中抽取若干文本片段作为训练数据。每个文本片段对应一个示例，若干个文本片段组成一个包，也就是一条训练样本。风险类型标签与网页相关联，而不与文本片段相关联，对应到多示例学习框架中就是标签与包相关联，而不与示例相关联。</p><p>我们从网页中抽取的若干文本片段并不能保证所有文本片段都包含了特定风险的违规信息，抽取的过程中可能存在噪音。多示例学习框架只要求每个包中至少包含一个正例，则该包就可以标记为正例；因此，我们只需要尽可能保证批量抽取的文本片段中有一个文本片段包含了违规内容，就可以放心地把该包标记为违规。由此可见，多示例学习对数据噪声有很好的鲁棒性，比较贴合网页风险识别业务的需求。</p><p>在预测阶段，使用与训练阶段相同的流程从待检测网页中抽取若干文本片段，每个文本片段作为一个示例，同一网页中抽取出的所有文本片段组成一个包，输入给预测模型，由模型结果来判断是否是某种类型的风险违规。</p><p>我们参考《Attention-based Deep Multiple Instance Learning》论文中的方法来构建训练模型。首先，我们对每个包中的若干个示例，通过上文提到的DGCNN文本编码器转换为一个固定长度的embedding向量；其次，通过attention机制把第一步得到的若干个embedding向量融合为一个最终的embedding向量；最后，在上一步得到的embedding向量之后接一个softmax分类层即可。架构示例图如下。</p><p><img src="https://ata2-img.oss-cn-zhangjiakou.aliyuncs.com/b34372d1a534fdcc6e85fda788162630.jpg" alt="Attention MIL.jpg"></p><p>具体地，假设第 $k$ 个文本片段对应的embedding向量为 $h_k$，则最终得到的包的embedding向量为$z=\sum_{k=1}^K a_k h_k$，其中<script type="math/tex">a_k=\frac{exp\{w_k^T tanh(Vh_k^T)\}}{\sum_{j=1}^K exp\{w_j^T tanh(Vh_j^T)\}}</script></p><p>上式中，$w,V$ 都是待学习的参数。</p><h4 id="5-损失函数：F1-score-动态加权的类别分布自平衡-loss-function"><a href="#5-损失函数：F1-score-动态加权的类别分布自平衡-loss-function" class="headerlink" title="5. 损失函数：F1 score 动态加权的类别分布自平衡 loss function"></a>5. 损失函数：F1 score 动态加权的类别分布自平衡 loss function</h4><p>现实世界中的监督学习问题，大多是类别分布不平衡的。虽然已存在多种处理类别分布不平衡的方法，常用的方法包括re-sampling和re-weighting两大类。Re-sampling类方法存在浪费训练数据或有过拟合的风险。Re-weighting大多对数据中的噪音非常敏感。</p><p>我经常使用的处理类别分布不平衡问题的损失函数是F1 score动态加权损失函数，该损失函数经测试能较好地处理类别分布不平衡问题，比如在正负样本比例为1:200的情况下也能有较好的表现，并且有一个很好的特性就是对数据噪声不敏感。使用该损失函数还可以根据业务需求动态调整对准确率-召回率的偏好。</p><p>简单地说，F1 score动态加权损失函数保持正样本的权重为 1，为负样本动态地计算权重：</p><script type="math/tex; mode=display">w_\beta=\frac{TP(\theta)}{\beta^2P+N-TN(\theta)}</script><p>其中，$\beta$ 为准确率-召回率的偏好调节因子，$P$、$N$ 分别为当前mini batch中的正样本和负样本数量，$TP(\theta)$、$TN(\theta)$ 分别为当前mini batch中用当前模型参数预测为True-Positive和True-Nagative的样本数量。</p><p>关于该损失函数，更详细的信息可参考《Adaptive Scaling for Sparse Detection in Information Extraction》。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>网页风险防控因数据是以源码的形式作为输入，区别于传统的文本安全场景的输入，具有一定的独特性，后续可以进一步挖掘该类型文本的特征。另外，长文本分类也属于一类比较难的NLP问题，值得进一步研究。欢迎有兴趣的同学交流想法，共同探讨。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h2&gt;&lt;p&gt;随着互联网扁平化的发展，内容信息的分发和获取比以往更加便利，这也大大方便了以色情、赌博、非法政治言论、违禁药品买卖等为代表的违规信息的快速传播。这类信息的传播会造成难以估计的社会影响，甚至有可能影响国家的安定和谐。网站所有者可以随意更改网站页面的内容，发布任意形式的信息。论坛、博客、社交产品等web 2.0的网站可以让普通用户随意发布UGC内容。安全防控做得不到位的网站页面内容还可能被黑客随意篡改，甚至安装木马病毒。综上，网站页面内容的生成方式多种多样，内容发布者也是形形色色，其中就会有不少不法分子利用网络传播违规信息以达到非法牟利，甚至控制网民意识形态，颠覆国家政权的目的。&lt;/p&gt;
&lt;p&gt;为了净化云平台以及维护网络环境的安全和稳定，对云上网站中存在的各类违规内容进行治理成为了意义重大又迫在眉睫的问题。本文主要介绍如何通过深度学习算法检测网页中是否包含了特定类型的违规内容。&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="内容安全" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8/"/>
    
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="智能安全" scheme="http://xudongyang.coding.me/tags/%E6%99%BA%E8%83%BD%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>关键词规则挖掘在商品合规风险识别中的应用</title>
    <link href="http://xudongyang.coding.me/rule-learning/"/>
    <id>http://xudongyang.coding.me/rule-learning/</id>
    <published>2020-12-04T15:04:31.000Z</published>
    <updated>2020-12-07T06:26:30.258Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、背景概述"><a href="#一、背景概述" class="headerlink" title="一、背景概述"></a>一、背景概述</h2><p>合规服务业务是基于法律法规建立的信息安全保障机制，保障电商平台的合规经营。商品合规风险指商家未能遵循国家有关法律法规、监管要求或平台制定的经营规则，在平台发布了禁止或限制销售的商品或服务。从发布内容的维度看，违规风险内容主要分为危害国家安全、民生安全、公共安全和市场秩序四大块内容。其中，危害国家安全的违规商品内容包括非法政治、枪支弹药、管制器具、军警用品、暴恐分裂渗透等；危害民生安全的违规商品内容包括毒品、危险化学品、管制药品、管制医疗器械、保护动植物等；危害公共安全的违规商品内容包括色情、低俗、赌博、个人隐私、作弊造假等；违反市场秩序的违规商品内容包括诚信交易类、公序良俗类等。大类的风险类别共计30余种。</p><p><img src="https://ftp.bmp.ovh/imgs/2020/02/a250bc02f66df2e4.jpg" alt></p><a id="more"></a><p>坚守风险底线，为用户服务提供良好的制度保障，助力平台提供更简单、更友好的经营环境，保护消费者权益是商品合规业务的主要目标。在商品合规场景，内容维度的风险，文本违规占比约80%。文本违规的主要发现手段之一是关键词规则匹配策略。该策略具有简单、高召回、响应速度快等优点，是必不可少的的一种风险识别策略。</p><h2 id="二、问题与挑战"><a href="#二、问题与挑战" class="headerlink" title="二、问题与挑战"></a>二、问题与挑战</h2><p>长期以来，关键词规则由业务运营小二人工添加和维护，不同小二会独立构建不同的关键词规则集，规则集的日常迭代更新完全依赖人力，<strong>维护成本高，且相互之间难以有效形成合力</strong>。</p><p>由于 <em>一词多义、主题漂移（topic drift）、对抗变异、敏感词滥用</em> 等问题的存在，关键词规则匹配策略的<strong>准确率普遍较低</strong>。</p><p>【一词多义】带来的语义匹配错误问题，在信息检索领域很常见。比如：“奇彩炫” 既是一个美瞳（管制医疗器械）的品牌，也是和路雪旗下一个雪糕的品牌；“云南白药”不仅仅是（管制）药品的品牌，也可能是牙膏、纸巾、洗发水等产品的品牌；“天润”、“海昌”既是隐形眼镜（管制医疗器械）的品牌，也是很多地名、广场、商贸名；“中华”既可能指香烟（烟草违规），也可能指牙膏。</p><p>【主题漂移】在关键词规则匹配过程中也很常见，比如“芙蓉王”既可能匹配上香烟（烟草类目违规），也可能匹配上印有芙蓉王香烟图案的抱枕和手机壳；“m16枪”既可能匹配上自动步枪也可能匹配上玩具枪模型；“中华”除了作为香烟品牌外，也可能作为一个修饰词存在，如“中华沙棘籽油软胶囊”。还有一种情况需要特别说明一下，因为关键词规则匹配引擎是基于字符串多模匹配，而不是搜索引擎常用的倒排索引，不存在文本分词的过程，因此关键词可能会跨越分词边界匹配上文本，比如关键词“雅塑”（一个管制药品品牌）会命中“….优<em>雅 塑</em>料….”；“中保”会命中“日版CUREL珂润干燥浸润 集<em>中 保</em>湿 身体乳液”。</p><p>【对抗变异】是风控领域特有的现象，主要指违规内容发布者在感知到其发布的内容被平台拦截之后，会想方设法地通过音近、形近、暗喻等手段，发布与原有违规内容语义相同但描述不同的新内容，从而绕过系统的拦截。比如“香烟”变异为“香yan”；“催情水”会变异为“听话水”、“乖乖水”、“回春水”、“g水”等；某种毒品会被称之为“恰特草”（俗称阿拉伯茶）、“咔哇潮饮”、“咔哇水”、“小金丝”、“小金瓶”、“梦幻草”、“三口鲍”等；危化品液氮会变异为“冒烟冰淇淋”。对抗变异会导致关键词规则集上线之后的准确率逐渐降低。</p><p>另外一类导致规则匹配策略准确率较低的原因是【敏感词滥用】，指有些卖正常商品的商家为了吸引流量，会在商品标题里添加一些违规的敏感词，比如部分卖内衣的商家可能会使用“开档”、“露乳”等低俗词，但因种种原因这些滥用敏感词描述的商品并没有被业务判定为违规，也就是说部分关键词规则匹配上的商品既可能被判定为违规，也可能被判定为不违规（商品本身不违规）。</p><p><strong>关键词规则缺少细粒度的效果跟踪和汰换机制</strong>。一方面由于关键词规则很少单独使用，一般会和其他限制条件一起使用，比如限定在特定类目或商家上，导致细粒度的关键词规则匹配效果难以准确统计；另一方面，由于之前系统没有关键词规则集的自动更新功能，手动汰换关键词规则操作繁琐易出错。因而，关键词规则集越积累越多，臃肿冗余且不强。</p><p>正是由于上述 _构建维护成本高、准确率低和难以跟踪与汰换_ 的问题，使用算法手段自动挖掘关键词规则集的需求应运而生，旨在<strong>自动挖掘 高准确率</strong>的关键词规则集，同时能够根据实际效果<strong>自动更新和汰换</strong>。</p><p>数据驱动的关键词规则自动挖掘面临的主要挑战，除了之前提到的一词多义、主题漂移、对抗变异、敏感词滥用等问题外，还面临<strong>样本空间巨大且开放、缺乏干净的标签数据的问题</strong>。</p><p>样本空间大很好理解。近亿级别的处罚商品，几十亿的在线商品。大数据带来工程实现的复杂性和较长的迭代周期。同时，因为样本空间是开放的，用户随时可能发布任意内容的商品，这对挖掘出的关键词规则的鲁棒性提出了很高的要求。目前的机器学习技术非常擅长挖掘与目标具有关联关系的特征，却难以挖掘特征与目标之间的因果关系。然而，因果关系才是稳定的，关联关系是脆弱的，随着时间变化的。这本质上是因为风控业务都在很大程度上违背了机器之所以能学习的前提条件：独立同分布。风控实际上就是一场猫捉老鼠的游戏。</p><p>缺乏干净的标签数据这个问题产生的原因就非常多了，列举一二如下：</p><ol><li>业务的违规风险类目标签是打在商品这个实体上的，而不是算法需要的商品标题这一维度上的。违规商品的违规内容可能出现在标题、副标题、详情、图片、视频、SKU等任意属性上，因此我们不知道在一个商品违规的前提下，商品标题本身是否违规。</li><li>商品被处罚可能仅仅是因为发布这个商品的商家的某些行为，而不是商品内容本身。经常发布违规内容的恶意商家发布的所有商品都有可能被判定违规，哪怕实际内容是正常的，比如，积分消耗完，被全店删除。我们发现了很多黑灰产借正常商品的壳发布违规商品的案例。</li><li>由于审核人员的失误，商品审核时被张冠李戴地打上了错误的风险标签。</li><li>管控标准发生了变化，比如19年双11前电子烟还不在管控范围内，现在已经全面禁售了。</li><li>标签本身的变化。风险类目体系存在拆分、合并和迁移的可能，但是历史被处罚商品不会重新关联上新的风险类目。我们还发现因为种种原因，不同层级的风险类目之间还存在重叠的现象，即不同类目都可以包含相同内容的商品。</li></ol><h2 id="三、技术方案"><a href="#三、技术方案" class="headerlink" title="三、技术方案"></a>三、技术方案</h2><h3 id="1-噪音标签数据清洗"><a href="#1-噪音标签数据清洗" class="headerlink" title="1. 噪音标签数据清洗"></a>1. 噪音标签数据清洗</h3><p>初略估计，噪音标签的比例高达44%（和外包人工审核不一致的比率），严重影响算法的效果。数据质量决定了业务效果的上限，而算法只能决定多大程度上逼近这个上限。因此，第一步需要清洗脏数据。</p><p>目前基于带噪标签数据的学习方法主要有两大类，一类是直接训练对噪声鲁棒的模型（noise-robust models），另一类方法首先识别出噪声数据，然后基于清洗后的数据训练模型。我们主要关注第二类方法，因为我们的目标是挖掘关键词规则集，由规则集构成的风险识别模型并不具备对噪声鲁棒的能力。尝试过的去噪方法简单介绍如下。</p><h4 id="a-基于Confidence-Learning识别错误标签"><a href="#a-基于Confidence-Learning识别错误标签" class="headerlink" title="a. 基于Confidence Learning识别错误标签"></a>a. 基于Confidence Learning识别错误标签</h4><p><a href="https://l7.curtisnorthcutt.com/confident-learning">Confidence Learning</a>是一种弱监督学习方法，它能够识别错误标签。Confidence Learning基于<a href="http://homepages.math.uic.edu/~lreyzin/papers/angluin88b.pdf">分类噪声过程假设（classification noise process )</a>，认为噪声标签是以类别为条件的，仅仅依赖于潜在的正确类别，而不依赖与数据。通过估计给定带噪标签与潜在正确标签之间的条件概率分别来识别错误标签。</p><p><img src="https://pic3.zhimg.com/80/v2-733811ce311a9bff5895ac21992e599e_1440w.jpg" alt="example"></p><p>Confidence Learning只依赖两个输入：模型的样本外预测概率和带噪标签。学习过程首先通过预测标签与标注标签的计数矩阵估计带噪标签与潜在正确标签之间的条件概率分布，然后根据该条件概率分布和样本预测概率来识别噪声标签。</p><h4 id="b-基于Forgetting-Events识别错误标签"><a href="#b-基于Forgetting-Events识别错误标签" class="headerlink" title="b. 基于Forgetting Events识别错误标签"></a>b. 基于Forgetting Events识别错误标签</h4><p>在模型训练过程中，某个样本已经被模型正确分类，随着模型参数的更新，该样本又被错误分类，这一过程被称之为该样本的一次遗忘事件（forgetting event）。根据论文《AN EMPIRICAL STUDY OF EXAMPLE FORGETTING DURING DEEP NEURAL NETWORK LEARNING》的研究，在模型训练过程中噪声样本往往会比正常样本经历更多的遗忘事件。基于这一启发式规则，我们可以记录下每个样本经历的遗忘事件总次数，进一步辨别出可能的噪声标签数据。</p><h4 id="c-基于训练过程的样本loss值识别错误标签"><a href="#c-基于训练过程的样本loss值识别错误标签" class="headerlink" title="c. 基于训练过程的样本loss值识别错误标签"></a>c. 基于训练过程的样本loss值识别错误标签</h4><p>基于训练过程中样本的loss值的相对大小来识别错误标签，这一方法是淘宝技术部的同学在ICCV2019的论文《O2U-Net: A Simple Noisy Label Detection Approach for Deep Neural Networks》中提出的。</p><p>大致思路基于以下逻辑：在一次训练中，随着迭代轮次增加，网络逐渐从欠拟合逐渐过渡到过拟合状态，在训练的初期，模型精度的提升是非常明显的，因为网络很快学会了那部分“简单的”样本，因此这类样本的loss比较小，与之相反，那些“困难的”样本通常在训练的后期才逐渐被学会。观察训练过程发现，噪声样本通常是在训练的后期才被学会，因而在训练的早期，噪声样本的平均loss是远大于干净样本的，而在训练的后期，因为网络逐渐学会了所有样本，两类样本的loss区别不大。纵观整个训练过程，从欠拟合到过拟合，噪声样本loss的均值和方差都比干净样本要大。通过循环学习率策略，使网络在欠拟合和过拟合之间多次切换，并追踪不同阶段不同参数的模型对样本的loss，通过在时间维度上捕获多样性足够丰富的模型（类似集成学习，对满足多样性和准确性的多个模型进行ensemble），统计各个样本loss的均值和方差，均值和方差越大，样本属于噪声样本的概率也就越大。</p><h4 id="d-基于样本相似度识别错误标签"><a href="#d-基于样本相似度识别错误标签" class="headerlink" title="d. 基于样本相似度识别错误标签"></a>d. 基于样本相似度识别错误标签</h4><p>基于样本相似度识别错误标签的思路也很简单，首先要训练一个样本相似度模型，然后采样一批置信度较高的白样本，计算白样本与黑样本之间的相似度。识别出与白样本相似度大于阈值，且能多次匹配上白样本的黑样本集合。这些黑样本集合很可能就是噪声标签数据。</p><h4 id="e-基于业务理解及人工规则识别错误标签"><a href="#e-基于业务理解及人工规则识别错误标签" class="headerlink" title="e. 基于业务理解及人工规则识别错误标签"></a>e. 基于业务理解及人工规则识别错误标签</h4><p>通过数据分析，我们发现部分噪声标签的来源具有一定的规律，通过这些规律可以提取出一些简单有效的过滤规则，可以直接清除掉一定数量的噪声标签数据。</p><p>例如，一些黑灰产商家主要通过图片来传递违规内容信息，为了规避审查他们发布的商品标题可能是一些无意义的字母和数字，或者是伪装成正常的商品描述。其中，无意义的字母和数字可以通过简单的字符类型识别来定位，我们总共检测出十万量级的无意义标题。另外，通过查看各个风险类目下风险点的定义和数据样本，提炼出一些系统性标签错误的规律，比如“军警用品”违规类目下不当使用国旗、国徽、党旗、党徽的风险点下标题不含“国旗、国徽、党旗、党徽”文字的商品一般是图片违规；图片类“暴力血腥”风险点下标题文本一般没有问题；保护动植物“情节特别严重”风险点下有很多恶意会员店铺正常商品连带处罚；以及不规范展示类“管制刀具”和摄影录像设备（涉嫌“个人隐私”违规）等。这些风险类目下是黑样本商品通常可以直接过滤，或者添加关键词匹配约束后过滤。</p><h4 id="f-实践及思考"><a href="#f-实践及思考" class="headerlink" title="f. 实践及思考"></a>f. 实践及思考</h4><p>观察并分析数据，从数据中总结规律，通常是每个项目首先应该做的事情，并且值得投资更多时间和精力。然而，由于该过程比较繁琐，且显得没有技术含量，所以经常被我们忽略或轻视，最终导致事倍功半。回头总结数据清洗的实践，我们发现基于业务理解及人工规则识别错误标签是非常有效，能够过滤掉几十万到百万量级的噪声样本，并且能够修正部分错误标签，同时也能够给后续的学习过程提供不错的启发。</p><p>我们的实验结果表明基于Confidence Learning识别错误标签的方法，以及基于Forgetting Events识别错误标签的方法，还有基于训练过程的样本loss值识别错误标签的方法，在单独使用的时候效果均不是十分令人满意。虽然他们都能够识别出一定量的错误标签，但同时也会把一部分比较难学的黑样本错误地当成噪声标签，这部分的比例取决于阈值的设定。个人觉得这三种方法的前提假设都不是必然成立，仅仅是基于经验的总结，它们的实际效果一定程度上收到训练样本分布的影响。比如，有黑灰产大量借助“儿童文具”这个类目下的正常商品的“壳”发布违规内容，并且我们在采样白样本时“儿童文具”这个类目下的白样本采样数量刚好较少时，上述三种方法均有很大可能会把该类目下的正常白样本识别为噪声，同时不能够识别出伪装的黑样本，产生本末倒置的错误效果。毕竟，谁黑谁白（label的正确与否）对模型来说本来就分不清，最终的结果取决于谁占了更大的比例。这也正是黑灰产厉害的地方，通过样本数量来混淆模型视听的做法有点类似于DDos攻击。最终，我们把三种方法集成在一起使用，是集成学习的一种思路，三个臭皮匠，顶个诸葛亮。</p><p>基于样本相似度识别错误标签的方法，虽然想法比较原始，但实际效果还是不错的，噪声标签的检测比较准确。当然，识别效果很依赖于相似度模型本身的性能，将会在下一篇文章中介绍商品风险相似度模型。</p><h3 id="2-关键词规则简介"><a href="#2-关键词规则简介" class="headerlink" title="2. 关键词规则简介"></a>2. 关键词规则简介</h3><p>在介绍关键词规则挖掘方法之前，有必要介绍一下风控引擎支持的关键词规则的形式。</p><p>关键词规则一般以集合的形式使用，待检测文本只要被规则集合中的一条规则匹配，则判断为命中。单条规则以不限长度的字符串为原子匹配单位，姑且称之为“pattern”。单条规则可以只有单个pattern，也可以由通过‘&amp;’或者‘~’连接符连接的多个pattern组成。‘&amp;’连接符连接的左右两个pattern必须同时是待检测文本的子串；‘~’连接符表示排除的意思，其右边的pattern不能是待检测文本的子串。</p><p>举例说明，待检测文本“克星大型10个逮钢丝大号田抓老鼠夹子铁质野外捕鼠器圆形捉机械式”<br>匹配上的规则：圆形&amp;抓老鼠~内~窝~笼子~鼠神器<br>不匹配的规则：圆形&amp;抓老鼠~钢丝</p><h3 id="3-关键词规则挖掘方法"><a href="#3-关键词规则挖掘方法" class="headerlink" title="3. 关键词规则挖掘方法"></a>3. 关键词规则挖掘方法</h3><p>由于文本违规信息主要在商品标题中呈现，所以我们的挖掘语料黑样本选择自清洗过后的已处罚商品，白样本选择自历史审核白样本商品和在线商品。</p><p>前面说到关键词规则的准确率较低的一个原因是匹配的“主题漂移”问题，即虽然关键词规则在字面上匹配上了待检测文本，但是待检测文本的整体语义并不是关键词规则原本想表达的语义。在发生“主题漂移”的匹配案例中，我们发现很大比例是由于提取出关键词规则的商品所在类目跟之后关键词规则应用的商品类目不一致导致的。已有的关键词规则集大多只跟风险类目相关，往往没有严格限制规则集作用的目标商品类目。限定每个关键词规则作用的风险类目和商品类目可以很大程度上缓解主题漂移问题。我们在挖掘关键词规则时，会同时挖掘规则的作用商品类目。</p><p>“主题漂移”问题的另一个原因是由于在规则挖掘阶段对文本执行了分词处理，而在匹配阶段并不会对文本分词，这就导致匹配阶段可能会存在跨越分词边界的匹配。</p><blockquote><p>文本：新款 书画益智趣味早教训练粘贴纸多种手工思维入门聪明中性2岁<br>命中关键词: 教训~木~想~儿~子</p><p>文本：【百草味-年货坚果大礼包1532g/9袋】每日干果过年零食混合礼盒<br>命中关键词: 日干</p></blockquote><p>跨越分词边界的匹配由于语义转义会导致关键词规则准确率下降。因此我们设计了两阶段的关键词挖掘方案，第一阶段从语料中挖掘候选关键词，第二阶段识别并去除掉候选关键词中潜在错误风险较高的关键词。</p><h4 id="3-1-关键词规则挖掘方案一"><a href="#3-1-关键词规则挖掘方案一" class="headerlink" title="3.1 关键词规则挖掘方案一"></a>3.1 关键词规则挖掘方案一</h4><p>我们尝试的第一个方案没有考虑排除pattern，只考虑有单pattern或者多个pattern的情况。整体流程包含三大步：生成候选规则、粗筛过滤效果较差的规则、精选规则。</p><p>首先，在对商品标题分词和去除停用词后，通过Apriori关联规则挖掘算法挖掘风险类目与商品类目两个维度下由关键词组成的频繁1~3项集。这里没有挖掘更高阶项集主要是因为样本空间太大，算法时空复杂性过高。每一个频繁项集对应一条候选关键词规则。接着，统计每一个候选关键词规则的准确率已经在样本空间上匹配的白样本数量，根据阈值过滤掉效果较差的候选规则。</p><p>我们在完成第二步，候选规则的粗筛之后，为什么还需要一个精选的过程？第二步得到的候选规则集里的每条规则的准确率不都已经大于阈值了嘛。我观察到的现象是这些候选规则里有很多是接近“共线”的，就是说有些规则能够匹配上的黑样本集合是相似的，而白样本集合却各有各的不同，这就导致这些规则叠加在一起的时候，整体的准确率会比单个的准确率要低。另外，这些关键词规则在实际场景应用的时候面临的是一个开放且不断演变的环境，总会有新的在语料库中没有出现过的样本出现，它们可能会匹配上之前没有见过的白样本，而那些它们原本能够匹配上的黑样本也可能不再出现。所以，关键词规则集的规模并不是越大越好，相反，越大越脆弱。</p><p><img src="https://intranetproxy.alipay.com/skylark/lark/0/2019/png/24824/1565869789870-cc9b906c-0593-414b-8880-3661372be463.png?x-oss-process=image/resize,w_1492" alt="chart"></p><p>接下来面临的一个难题是选择哪些候选关键词规则组成最终的规则集。比较自然的想法是使用贪心算法，即每次都选择一个增益最大的候选规则加入规则集。假设 $t-1$ 时刻的规则集是$R_{t-1}$，$R_0=\emptyset$，规则集整体的效用值用函数$f(\cdot)$表示，则贪心算法每次根据下面的等式选择一个候选规则。<script type="math/tex">argmax_{r} f(R_{t-1} \cap r )-f(R_{t-1})</script></p><p>虽然贪心算法思路很简单，而且也只能得到一个次优的结果，但其实在我们的场景下贪心算法根本实现不了，原因就在于效用值函数的每次求值都会耗费巨大的算力和时间，当然根本原因还在于样本空间太大（近亿的黑样本，几十亿的白样本）。那能不能只在一个采样出的小规模评估集上求解呢？很明显，也是不行的。</p><p>最终我们选择使用GBDT算法来精选候选规则。具体的操作是GBDT算法的一种特殊实现，每一颗新生成的树的深度为1，这样的子模型也叫做决策树桩。特征由关键词规则加对应商品一级类目组成。GBDT算法在生成一颗新的子树的时候只需要做一个简单的判断，即选择哪个关键词规则及其关联商品类目即可。为什么选择GBDT算法呢？因为GBDT算法是一个加法模型，它在生成新的子树的时候优化的目标是最大化整体的效用值，跟我们的需求非常贴近。这个过程天然具有去除冗余的共线特征（相关性很高的特征）的效果，因为共线的特征在选择了其中一个之后，剩下的对整体效用值的贡献很小。这里我们把特征设计为最终需要的（关键词规则，商品一级类目）二元组，并且使用决策树桩作为子模型是一种讨巧的做法。</p><h4 id="3-2-关键词规则挖掘方案二"><a href="#3-2-关键词规则挖掘方案二" class="headerlink" title="3.2 关键词规则挖掘方案二"></a>3.2 关键词规则挖掘方案二</h4><p>有研究表明具备特征反向选择能力的模型比不具备特征反向选择能力的模型可以表达更加复杂的规则，往往效果也更好。上述方案一并没有反向选择特征的能力，也就是说不能通过排除某些关键词来提升规则的准确率。如何能够使得规则能够反向选择特征呢？</p><p>我们熟悉的决策树算法是具备反向选择特征的能力的，树的每个节点对应的左右两个分支就对应着某个特征是否被选中。那么，能不能直接把关键词作为特征，使用GBDT算法来训练模型，最终通过解析每个子树从根节点到叶子节点的路径来学习关键词规则呢？毕竟，这样得到的关键词规则也是包含了“排除”特征的。这里的一个关键问题是如果GBDT算法使用关键词作为特征并且直接用原始的样本集训练，会面临维数灾和计算效率的巨大挑战。</p><p>最终，我们参考论文《<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.2612&amp;rep=rep1&amp;type=pdf">Fast Effective Rule Induction</a>》中提出的IREP方法，做出适当的修改用来挖掘关键词规则。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">procedure IREP(Pos,Neg)</span><br><span class="line">begin</span><br><span class="line">  Ruleset &#x3D; Ø</span><br><span class="line">  while Pos !&#x3D; Ø do</span><br><span class="line">    Rule &#x3D; GrowRule(Pos,Neg) &#x2F;&#x2F; 生成一条新的关键词规则</span><br><span class="line">    if precision of Rule &lt; threshold then</span><br><span class="line">      return Ruleset</span><br><span class="line">    else</span><br><span class="line">      add Rule to Ruleset</span><br><span class="line">      remove examples covered by Rule from (Pos, Neg)</span><br><span class="line">    endif</span><br><span class="line">  endwhile</span><br><span class="line">  return Ruleset</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>在生成新规则这一步，每次选择一个关键词添加到当前规则中，根据选择的关键词是正向词还是负向词来决定是用‘&amp;’符号连接，还是用‘~’符号连接；循环迭代直到新规则的准确率大于阈值为止。这里还有一个剪枝的过程，如果有太多的负向词或正向词被选中，则直接放弃该规则，重新生成一个。另外，在选择关键词时需要过滤明显不合理的关键词，例如前一步已经选择了“节假日”加入规则，当前步就不能选择“节假日”的任意子串（如，“假日”）。</p><p>那么每次应该选择哪个关键词呢？这其实是一个古老的特征选择问题，有很多方法。参考《Feature Selection for Text Categorization on Imbalanced Data》，我们实现并测试了以下五种：卡方(CHI square)、基尼指数(gini index)、GiniTxt(基尼纯度的一种变种)【6】、优势率(odds ratio)、信息增益率、信息值(<a href="https://medium.com/@sundarstyles89/weight-of-evidence-and-information-value-using-python-6f05072e83eb">Information Value</a>, Weight of evidence的变种)。除了卡方和基尼指数的结果比较类似之外，不同的特征选择方法得到的结果差异还是挺大的。最终我们选择了卡方、优势率、信息增益率三种特征选择方法，同时挖掘候选关键词，并对候选关键词规则做去重和合并的处理。</p><div class="table-container"><table><thead><tr><th>　</th><th>黑样本数</th><th>白样本数</th></tr></thead><tbody><tr><td>包含词 $t$</td><td>A</td><td>B</td></tr><tr><td>不包含词 $t$</td><td>C</td><td>D</td></tr></tbody></table></div><p>假设某风险类目 $c_i$ 下的样本分布如上表所示，并且 $N=A+B+C+D$ 为总样本数，计算词 $t$ 与该风险类目的相关系数:</p><script type="math/tex; mode=display">CC(t,c_i)=\frac{\sqrt{N}[P(t,c_i)P(\overline t,\overline c_i)-P(t,\overline c_i)P(\overline t,c_i)]}{\sqrt{P(t)P(\overline t)P(c_i)P(\overline c_i)}}=\frac{\sqrt{N}(AD-BC)}{\sqrt{(A+B)(C+D)(A+C)(B+D)}}</script><p>相关系数为正数时表示词 $t$ 与风险类目 $c_i$ 正相关，是正向词；相关系数为负数时表示词 $t$ 与风险类目 $c_i$ 负相关，是负向词，作为关键词规则中的排除词。相关系数的平方就是卡方，即$CC^2=\chi^2$。卡方特征选择方法每次都选择使上述公式平方值最大的词作为特征。</p><p>信息增益的计算公式为：$IG(t,c_i)=\sum_{c \in \{c_i,\overline c_i\}}\sum_{t’ \in \{t,\overline t\}}P(t’,c)log\frac{P(t’,c)}{P(t’)\cdot P(c)}$</p><p>优势率的计算公式为：$OR(t,c_i)=log\frac{P(t|c_i)[1-P(t|\overline c_i)]}{[1-P(t|c_i)]P(t|\overline c_i)}$</p><p>值得注意的是，关键词规则的去重合并并不是按照字符串是否完全匹配进行，而是按照关键词规则的语义识别出两者之间是否存在‘蕴含’关系。如规则B能匹配的文本集合只能是规则A匹配的文本集合的子集，在规则A蕴含规则B，即为‘A-&gt;B’，此时规则B就没必要存在于最终的规则集中。</p><blockquote><p>规则蕴含关系举例：聊-&gt;陪聊；多&amp;肉-&gt;多肉；聊天-&gt;聊天~姐姐；聊天~c1_123-&gt;聊天~c1_123~c1_456；聊天~清高-&gt;聊天~清；电影~电视-&gt;电影~电视~剧；电影~高清-&gt;电影~高~清；娃-&gt;娃&amp;c1_123；娃&amp;c1_123-&gt;娃&amp;c1_123&amp;c1_456</p></blockquote><p>另外，由于规则集中的关键词规则彼此之间是‘或’的关系，待检测文本只要匹配其中一个就算匹配上了，所以形如“A~B”和“A~C”这样的两条规则不能同时存在于同一个规则集中，否则效果就等价于规则“A”，丢失了排除词的限定作用。可以选择保留其中之一，或者合并成“A~B~C”。</p><p>IREP规则挖掘算法可以理解为是一个广义加法模型（GAM，generalized additive model），预测函数为$F(x)=f_0(x)+f_1(x)+f_2(x)+\cdots+f_n(x)$，其中$f_i(x)$对应一条关键词规则，$x$是输入文本，$f_i(x)=1$表示关键词规则命中输入文本，反之，若$f_i(x)=0$表示关键词规则没有命中输入文本。采用前向分步算法(forward stagewise algorithm)来生成，每一步生成一个关键词规则，目标是使得总的经验误差最小。其学习过程非常类似于大名典典的GBDT算法，但能支持更大的数据规模。</p><p>我们是以风险类目和商品一级类目为单位执行挖掘算法，进一步限制了输入的样本数量，从而是算法能够做到每日更新。算法的每日更新能够一定程度上抵御对抗变异带来的准确率下降问题。</p><h4 id="3-3-识别并去除潜在错误率较高的候选关键词"><a href="#3-3-识别并去除潜在错误率较高的候选关键词" class="headerlink" title="3.3 识别并去除潜在错误率较高的候选关键词"></a>3.3 识别并去除潜在错误率较高的候选关键词</h4><p>为了一定程度上避免跨越分别边界匹配引起的“主推漂移”问题，我们需要识别并去除潜在错误率较高的候选关键词。在这个阶段，我们重新准备一批测试数据，选择最近一段时间风控引擎接受到的新发和编辑商品及其审核结果，加上同时期其他渠道（风控、举报等）收集到的违规商品作为测试数据集。保证测试数据的分布和线上真实情况一致。然后，在上述测试集上<strong>用尽可能和线上一致的方式匹配候选关键词</strong>，并统计每个候选关键词的匹配白样本数和准确率，最终去除掉准确率低于阈值或者匹配白样本数大于阈值的候选关键词。</p><h4 id="3-4-一点思考"><a href="#3-4-一点思考" class="headerlink" title="3.4 一点思考"></a>3.4 一点思考</h4><p>仔细观察方案二中使用的IREP算法，发现其很多地方跟GBDT算法很像。两种都是通过不断添加子模型来最大化整体模型的效用值。GBDT的子模型是一颗决策树；IREP算法的子模型是一条关键词规则，也可以认为是决策树的一条从根节点到叶子节点的路径。为什么IREP算法只需要一条路径而不是一棵树呢？因为我们最终需要的是规则，而不是决策树。一颗决策树有多条从根节点到叶子节点的路径，其中有些路径分类为正，有些路径分类为负。那些分类为负的路径我们不需要提取出来，因为规则匹配引擎会在所有规则都不能命中时默认判断结果为负。那些分类为正的路径，IREP算法每次只学习出其中的一条出来，其余的嘛就留给下一次学习了。从这个角度看，GBDT算法比IREP算法的效率要高，相比IREP算法其复用了多次特征选择的结果。但从最终效果的角度看，两者的学习过程并没有本质的区别。另外，IREP算法把每次新生成的规则覆盖的样本删除之后再用剩余的样本生成下一条规则，这个做法其实跟GBDT算法根据损失函数的梯度来生在新的决策树发挥的作用是类似的，都是为了使新生成的决策树或者规则的效用值增益最大。</p><p>方案一和方案二都跟GBDT算法有某些联系，这其实并不是偶然的。因为关键词规则匹配系统的执行过程跟GBDT算法的预测过程是非常类似的，可以认为关键词匹配引擎就是GBDT算法预测过程的一种特殊实现。所以，关键词规则的挖掘当然也应该用GBDT算法来实现。怎奈何GBDT算法本身支撑不了这么大的数据量和这么高维的离散特征。方案一和方案二都是对GBDT算法的简化和近似。方案一限定了规则最多只能由三个关键词组成，而方案二没有这一限定。</p><h2 id="四、总结与展望"><a href="#四、总结与展望" class="headerlink" title="四、总结与展望"></a>四、总结与展望</h2><p>通过学习形式更加复杂的关键词规则，可以一定程度上缓解【一词多义】、【主题漂移】与【敏感词滥用】的问题。通过限定关键词规则作用的风险类目和商品类目可以规避很多【主题漂移】的问题。通过关键词规则的每日更新可以一定程度上缓解【对抗变异】的问题。</p><p>不可否认的是，通过关键词规则来判断输入文本是否是某种类型的风险违规这一机制本身是有一些固有的缺陷的，比如没有办法去理解输入文本的语义，没有办法真正杜绝【主题漂移】问题。除此之外，关键词规则匹配引擎还有一些特殊的匹配逻辑，如跳字匹配，会导致规则挖掘时测试的准确率和线上真实准确率的不一致。问题和挑战依旧存在。在信息检索领域，搜索引擎至少需要召回和精排两个阶段才能返回比较让人满意的结果。同样，在风险判定问题中，关键词规则匹配只完成了第一步，也就是召回的过程。那么，类似于“精排”的第二步呢？</p><p>无论是关键词规则，还是目前的深度学习技术，都无法有效解决的一个问题就是风险的根因分析（不仅仅指可解释性），下一步该何去何从？</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li>【1】<a href="https://arxiv.org/abs/1911.00068">Confident Learning: Estimating Uncertainty in Dataset Labels</a></li><li>【2】AN EMPIRICAL STUDY OF EXAMPLE FORGETTING DURING DEEP NEURAL NETWORK LEARNING</li><li>【3】O2U-Net: A Simple Noisy Label Detection Approach for Deep Neural Networks</li><li>【4】<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.2612&amp;rep=rep1&amp;type=pdf">Fast Effective Rule Induction</a></li><li>【5】Feature Selection for Text Categorization on Imbalanced Data</li><li>【6】尚文倩 et al，文本分类中基于基尼指数的特征选择算法研究.</li><li>【7】<a href="https://medium.com/@sundarstyles89/weight-of-evidence-and-information-value-using-python-6f05072e83eb">Weight of evidence and Information Value using Python</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、背景概述&quot;&gt;&lt;a href=&quot;#一、背景概述&quot; class=&quot;headerlink&quot; title=&quot;一、背景概述&quot;&gt;&lt;/a&gt;一、背景概述&lt;/h2&gt;&lt;p&gt;合规服务业务是基于法律法规建立的信息安全保障机制，保障电商平台的合规经营。商品合规风险指商家未能遵循国家有关法律法规、监管要求或平台制定的经营规则，在平台发布了禁止或限制销售的商品或服务。从发布内容的维度看，违规风险内容主要分为危害国家安全、民生安全、公共安全和市场秩序四大块内容。其中，危害国家安全的违规商品内容包括非法政治、枪支弹药、管制器具、军警用品、暴恐分裂渗透等；危害民生安全的违规商品内容包括毒品、危险化学品、管制药品、管制医疗器械、保护动植物等；危害公共安全的违规商品内容包括色情、低俗、赌博、个人隐私、作弊造假等；违反市场秩序的违规商品内容包括诚信交易类、公序良俗类等。大类的风险类别共计30余种。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ftp.bmp.ovh/imgs/2020/02/a250bc02f66df2e4.jpg&quot; alt&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="内容安全" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8/"/>
    
    
    <category term="GBDT" scheme="http://xudongyang.coding.me/tags/GBDT/"/>
    
    <category term="规则学习" scheme="http://xudongyang.coding.me/tags/%E8%A7%84%E5%88%99%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="商品合规" scheme="http://xudongyang.coding.me/tags/%E5%95%86%E5%93%81%E5%90%88%E8%A7%84/"/>
    
    <category term="RuleLearning" scheme="http://xudongyang.coding.me/tags/RuleLearning/"/>
    
    <category term="数据清洗" scheme="http://xudongyang.coding.me/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"/>
    
  </entry>
  
  <entry>
    <title>相似检索在商品合规风险识别中的应用</title>
    <link href="http://xudongyang.coding.me/similarity-search/"/>
    <id>http://xudongyang.coding.me/similarity-search/</id>
    <published>2020-12-04T14:46:55.000Z</published>
    <updated>2020-12-07T06:39:29.112Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、背景概述"><a href="#一、背景概述" class="headerlink" title="一、背景概述"></a>一、背景概述</h2><p>合规服务业务是基于法律法规建立的信息安全保障机制，保障电商平台的合规经营。商品合规风险指商家未能遵循国家有关法律法规、监管要求或平台制定的经营规则，在平台发布了禁止或限制销售的商品或服务。从发布内容的维度看，违规风险内容主要分为危害国家安全、民生安全、公共安全和市场秩序四大块内容。其中，危害国家安全的违规商品内容包括非法政治、枪支弹药、管制器具、军警用品、暴恐分裂渗透等；危害民生安全的违规商品内容包括毒品、危险化学品、管制药品、管制医疗器械、保护动植物等；危害公共安全的违规商品内容包括色情、低俗、赌博、个人隐私、作弊造假等；违反市场秩序的违规商品内容包括诚信交易类、公序良俗类等。大类的风险类别共计30余种。</p><p><img src="https://ftp.bmp.ovh/imgs/2020/02/a250bc02f66df2e4.jpg" alt></p><p>坚守风险底线，为用户服务提供良好的制度保障，助力平台提供更简单、更友好的经营环境，保护消费者权益是商品合规业务的主要目标。在商品合规场景，内容维度的风险中文本违规占比约80%。通过商品标题文本的相似检索是发现新风险的有效手段之一。</p><a id="more"></a><h2 id="二、问题与挑战"><a href="#二、问题与挑战" class="headerlink" title="二、问题与挑战"></a>二、问题与挑战</h2><h3 id="1-审核标准复杂"><a href="#1-审核标准复杂" class="headerlink" title="1. 审核标准复杂"></a>1. 审核标准复杂</h3><p>大多数风险内容的判定需要专业的领域知识。比如，对保护动植物的判定就比较难，同样是鹦鹉或者乌龟，有些品种可能是保护动物，有些又可能不是。另外，国际法律、国家法律和省级法律对于保护动植物的范围圈定以及保护等级的规定都不尽相同。同时，虽然有些动植物被国家农业部列在保护动植物名录里，但出于商业目的，并未在平台保护，比如虫草、松茸等。保护动植物难以判定的另一关键原因是有很多我们日常生活中很难接触到的动植物，比如“砗磲”、“玳瑁”等，有很多动植物我们之前都没有听说过，对于它们是否属于保护动植物就更加缺乏认知了。其他的风险类目也有同样的问题，比如有些具有一定保健或治疗效果的化妆品、保健品、“卫消字号”的产品就很难从名称上判定是否属于管制药品。比如“众妥宝儿康霜剂乳膏软膏蚊虫叮咬皮肤止痒膏宝宝婴儿红屁屁婴幼儿”这款产品虽然药店也有卖，但是专业鉴定结果并不是管制药品，而是“卫消字号”的产品。</p><p>另外一方面，监管标准也在不断发生变化。每年均会有新的各类敏感事件发生，导致不同时期的标准会发生变化，比如，去年双11之前电子烟是可以在网络上销售的，但后来有个叫罗永浩的胖子大张旗鼓地说要在双11大卖电子烟，于是后来国家相关部门规定电子烟和香烟一样都不可以通过电商渠道销售。</p><p>同时，监管粒度也会细化或者抽象，与之相应地风险类目也会出现拆分或合并的情况。比如色情低俗会被拆分成两个类目，暴恐分裂渗透会从非法政治里独立出来作为一个新的管控风险类目，就像爆炸物会从危险化学品里拆分出来一样。监管标准或粒度的变化会导致与之相关的样本数目不足，会变成one-shot甚至zero-shot learning的问题。</p><h3 id="2-对抗变异严重"><a href="#2-对抗变异严重" class="headerlink" title="2. 对抗变异严重"></a>2. 对抗变异严重</h3><p>风险内容鉴定困难的另一原因是商家会隐晦地描述自己的产品或服务，试图把真实的信息隐藏起来，骗过机器审核算法。比如商品标题“中国剧院节目【<strong>崔</strong>凤鸣：岳府就<strong>亲</strong>、岳芝荆投<strong>水</strong>、进锣汉衣】”描述的商品实际上是在卖“催情水”（管制药品）；“<strong>g 他</strong>最新手工打造方式 <strong>a5</strong> 无风率 线上无后顾之忧 详情咨询”表达的实际内容是“gta5”（一种被管制的暴力血腥游戏）；“加我vxin fc2265 <strong>天然红</strong>高端吊坠 私人订制18k金镶嵌手链”描述的实际内容是“天然红珊瑚手链”（红珊瑚是保护动植物）；“景点避暑山庄收藏挂历 LED显示屏白<strong>荷画 烟</strong>墨画作烟灰色背景挂历”是在卖“荷花牌香烟”（香烟禁止在网络上销售）；再看“手机挂九游挂饰吊坠微信玉石玛瑙指环扣女款创意炸金花链短吊环”，真实意图隐藏得很好有没有？你能猜到这是在发布哪种类型的违规信息吗？（答案请继续往下看）</p><p>很显然，没有黑商家会毫不避讳直截了当地发布自己的违规信息，卖毒品的不会光明正大地说自己在卖毒品，发布色情内容的商家也不会开门见山地说自己在散播小黄片，也不会有人单刀直入地说自己在贩卖枪支弹药，更不可能有人会斩钉截铁地说要分裂国家主权（我感觉这句话可能会被机器算法识别为“非法政治”违规）。他们一定会绞尽脑汁 拐弯抹角 迂回曲折 闪烁其辞 旁敲侧击 指桑骂槐地搞出新花招来绕过现有的机器识别算法。这对审核算法的时效性提出了很高的要求，一般的分类模型很难主动识别出新的变异，模型重新训练升级部署的周期又比较长，在这方便会比较被动。而基于相似检索的算法方案则可以快速捕捉到新的变异内容。</p><p>对抗变异是黑内容试图“洗白”自己，与之相反的是平台上也存在一定比例的白内容试图“描黑”自己。这么做的动机当然是为了跟黑灰产抢流量了，黑灰产之所以存在是因为真实世界里存在这样的需求，有需求就会有流量。“描黑”自己其实跟标题党没什么区别，就是为了吸引眼球，获得更多的曝光机会。比如，有些卖内衣的商家会使用一些特别露骨的低俗词；更常见的是随意堆砌一些不相关的词汇。不管是“洗白”还是“描黑”，都给风险鉴定增加了很大的难度。</p><h3 id="3-数据噪声大"><a href="#3-数据噪声大" class="headerlink" title="3. 数据噪声大"></a>3. 数据噪声大</h3><p>标签数据对于相似模型至关重要，因为我们要的相似模型并不是常规意义上的语义相似度模型，而是能够判别风险类型的相似模型。通过前面的例子，我们可以看到一段商品文本可能会同时描述多重语义，而其中违规的语义通常比较隐晦，因此我们需要让模型能够关注违规语义，而忽略正常语义。从这个意义上讲，干净的标签信息是必不可少的。</p><p>缺乏干净的标签数据这个问题产生的原因就非常多了，列举一二如下：</p><ol><li>业务的违规风险类目标签是打在商品这个实体上的，而不是算法需要的商品标题这一维度上的。违规商品的违规内容可能出现在标题、副标题、详情、图片、视频、SKU等任意属性上，因此我们不知道在一个商品违规的前提下，商品标题本身是否违规。</li><li>商品被处罚可能仅仅是因为发布这个商品的商家的某些行为，而不是商品内容本身。经常发布违规内容的恶意商家发布的所有商品都有可能被判定违规，哪怕实际内容是正常的，比如，积分消耗完，被全店删除。我们发现了很多黑灰产借正常商品的壳发布违规商品的案例。</li><li>由于审核人员的失误，商品审核时被张冠李戴地打上了错误的风险标签。</li><li>管控标准发生了变化，比如19年双11前电子烟还不在管控范围内，现在已经全面禁售了。</li><li>标签本身的变化。风险类目体系存在拆分、合并和迁移的可能，但是历史被处罚商品不会重新关联上新的风险类目。我们还发现因为种种原因，不同层级的风险类目之间还存在重叠的现象，即不同类目都可以包含相同内容的商品。</li></ol><h3 id="4-样本空间大且开放"><a href="#4-样本空间大且开放" class="headerlink" title="4. 样本空间大且开放"></a>4. 样本空间大且开放</h3><p>样本空间大很好理解。近亿级别的处罚商品，几十亿的在线商品。大数据带来工程实现的复杂性和较长的迭代周期。同时，因为样本空间是开放的，用户随时可能发布任意内容的商品，这对算法的鲁棒性提出了很高的要求。</p><h2 id="三、技术方案"><a href="#三、技术方案" class="headerlink" title="三、技术方案"></a>三、技术方案</h2><h3 id="1-整体框架"><a href="#1-整体框架" class="headerlink" title="1. 整体框架"></a>1. 整体框架</h3><p>整体思路是根据新商品与已有违规商品的相似程度来判定新商品是否违规。所以要训练一个商品文本相似度模型。目前，学习相似度的深度学习范式主要有两种，如下图所示。<br><img src="https://ftp.bmp.ovh/imgs/2020/02/41546b67b08c4181.jpg" alt><br>第一种范式是首先通过深度神经网络模型提取输入的表示向量，再通过表示向量的简单距离函数（eg. inner product）计算两者的相似度。这种方式在提取表示向量的过程中只考虑当前输入，不考虑要与之计算相似度的另一个输入的信息，通常用孪生网络来实现。第二种范式是通过深度模型提取两个输入的交叉特征，得到匹配信号张量再聚合为匹配分数，该方式同时考虑两个输入的信息，因而一般情况下效果要更好，不足之处在于预测阶段需要两两计算相似度，复杂度较高。</p><p>由于新商品与已有违规商品的数量级都巨大，因此我们不可能全部两两组成对输入给模型预测是否相似，因此第二种范式并不适合用在风险召回阶段。本文主要关注第一种范式的建模，既模型单独提取各个输入的表示向量，这样已有违规商品的表示向量可以提前离线提取好，在线服务只需要提取输入新商品的表示向量，然后通过向量检索引擎查询top K个最相似的邻居，再跟进KNN算法判定分类结果即可。整体的框架概述如下。</p><p><img src="https://pic4.zhimg.com/v2-dc92ea142c1cf4dbeea0fe9759b6e53d_r.jpg" alt="framework"></p><h3 id="2-噪音标签数据清洗"><a href="#2-噪音标签数据清洗" class="headerlink" title="2. 噪音标签数据清洗"></a>2. 噪音标签数据清洗</h3><p>初略估计，噪音标签的比例高达44%（和外包人工审核不一致的比率），严重影响算法的效果。数据质量决定了业务效果的上限，而算法只能决定多大程度上逼近这个上限。因此，第一步需要清洗脏数据。</p><p>目前基于带噪标签数据的学习方法主要有两大类，一类是直接训练对噪声鲁棒的模型（noise-robust models），另一类方法首先识别出噪声数据，然后基于清洗后的数据训练模型。我们主要关注第二类方法，因为我们的目标是挖掘关键词规则集，由规则集构成的风险识别模型并不具备对噪声鲁棒的能力。尝试过的去噪方法简单介绍如下。</p><h4 id="a-基于Confidence-Learning识别错误标签"><a href="#a-基于Confidence-Learning识别错误标签" class="headerlink" title="a. 基于Confidence Learning识别错误标签"></a>a. 基于Confidence Learning识别错误标签</h4><p><a href="https://l7.curtisnorthcutt.com/confident-learning">Confidence Learning</a>是一种弱监督学习方法，它能够识别错误标签。Confidence Learning基于<a href="http://homepages.math.uic.edu/~lreyzin/papers/angluin88b.pdf">分类噪声过程假设（classification noise process )</a>，认为噪声标签是以类别为条件的，仅仅依赖于潜在的正确类别，而不依赖与数据。通过估计给定带噪标签与潜在正确标签之间的条件概率分别来识别错误标签。</p><p><img src="https://pic1.zhimg.com/v2-733811ce311a9bff5895ac21992e599e_r.jpg" alt="example"></p><p>Confidence Learning只依赖两个输入：模型的样本外预测概率和带噪标签。学习过程首先通过预测标签与标注标签的计数矩阵估计带噪标签与潜在正确标签之间的条件概率分布，然后根据该条件概率分布和样本预测概率来识别噪声标签。</p><h4 id="b-基于Forgetting-Events识别错误标签"><a href="#b-基于Forgetting-Events识别错误标签" class="headerlink" title="b. 基于Forgetting Events识别错误标签"></a>b. 基于Forgetting Events识别错误标签</h4><p>在模型训练过程中，某个样本已经被模型正确分类，随着模型参数的更新，该样本又被错误分类，这一过程被称之为该样本的一次遗忘事件（forgetting event）。根据论文《AN EMPIRICAL STUDY OF EXAMPLE FORGETTING DURING DEEP NEURAL NETWORK LEARNING》的研究，在模型训练过程中噪声样本往往会比正常样本经历更多的遗忘事件。基于这一启发式规则，我们可以记录下每个样本经历的遗忘事件总次数，进一步辨别出可能的噪声标签数据。</p><h4 id="c-基于训练过程的样本loss值识别错误标签"><a href="#c-基于训练过程的样本loss值识别错误标签" class="headerlink" title="c. 基于训练过程的样本loss值识别错误标签"></a>c. 基于训练过程的样本loss值识别错误标签</h4><p>基于训练过程中样本的loss值的相对大小来识别错误标签，这一方法是淘系技术部的同学在ICCV2019的论文《O2U-Net: A Simple Noisy Label Detection Approach for Deep Neural Networks》中提出的。</p><p>大致思路基于以下逻辑：在一次训练中，随着迭代轮次增加，网络逐渐从欠拟合逐渐过渡到过拟合状态，在训练的初期，模型精度的提升是非常明显的，因为网络很快学会了那部分“简单的”样本，因此这类样本的loss比较小，与之相反，那些“困难的”样本通常在训练的后期才逐渐被学会。观察训练过程发现，噪声样本通常是在训练的后期才被学会，因而在训练的早期，噪声样本的平均loss是远大于干净样本的，而在训练的后期，因为网络逐渐学会了所有样本，两类样本的loss区别不大。纵观整个训练过程，从欠拟合到过拟合，噪声样本loss的均值和方差都比干净样本要大。通过循环学习率策略，使网络在欠拟合和过拟合之间多次切换，并追踪不同阶段不同参数的模型对样本的loss，通过在时间维度上捕获多样性足够丰富的模型（类似集成学习，对满足多样性和准确性的多个模型进行ensemble），统计各个样本loss的均值和方差，均值和方差越大，样本属于噪声样本的概率也就越大。</p><h4 id="d-基于样本相似度识别错误标签"><a href="#d-基于样本相似度识别错误标签" class="headerlink" title="d. 基于样本相似度识别错误标签"></a>d. 基于样本相似度识别错误标签</h4><p>基于样本相似度识别错误标签的思路也很简单，首先要训练一个样本相似度模型，然后采样一批置信度较高的白样本，计算白样本与黑样本之间的相似度。识别出与白样本相似度大于阈值，且能多次匹配上白样本的黑样本集合。这些黑样本集合很可能就是噪声标签数据。</p><h4 id="e-基于业务理解及人工规则识别错误标签"><a href="#e-基于业务理解及人工规则识别错误标签" class="headerlink" title="e. 基于业务理解及人工规则识别错误标签"></a>e. 基于业务理解及人工规则识别错误标签</h4><p>通过数据分析，我们发现部分噪声标签的来源具有一定的规律，通过这些规律可以提取出一些简单有效的过滤规则，可以直接清除掉一定数量的噪声标签数据。</p><p>例如，一些黑灰产商家主要通过图片来传递违规内容信息，为了规避审查他们发布的商品标题可能是一些无意义的字母和数字，或者是伪装成正常的商品描述。其中，无意义的字母和数字可以通过简单的字符类型识别来定位，我们总共检测出十万量级的无意义标题。另外，通过查看各个风险类目下风险点的定义和数据样本，提炼出一些系统性标签错误的规律，比如“军警用品”违规类目下不当使用国旗、国徽、党旗、党徽的风险点下标题不含“国旗、国徽、党旗、党徽”文字的商品一般是图片违规；图片类“暴力血腥”风险点下标题文本一般没有问题；保护动植物“情节特别严重”风险点下有很多恶意会员店铺正常商品连带处罚；以及不规范展示类“管制刀具”和摄影录像设备（涉嫌“个人隐私”违规）等。这些风险类目下是黑样本商品通常可以直接过滤，或者添加关键词匹配约束后过滤。</p><h4 id="f-实践及思考"><a href="#f-实践及思考" class="headerlink" title="f. 实践及思考"></a>f. 实践及思考</h4><p>观察并分析数据，从数据中总结规律，通常是每个项目首先应该做的事情，并且值得投资更多时间和精力。然而，由于该过程比较繁琐，且显得没有技术含量，所以经常被我们忽略或轻视，最终导致事倍功半。回头总结数据清洗的实践，我们发现基于业务理解及人工规则识别错误标签是非常有效，能够过滤掉几十万到百万量级的噪声样本，并且能够修正部分错误标签，同时也能够给后续的学习过程提供不错的启发。</p><p>我们的实验结果表明基于Confidence Learning识别错误标签的方法，以及基于Forgetting Events识别错误标签的方法，还有基于训练过程的样本loss值识别错误标签的方法，在单独使用的时候效果均不是十分令人满意。虽然他们都能够识别出一定量的错误标签，但同时也会把一部分比较难学的黑样本错误地当成噪声标签，这部分的比例取决于阈值的设定。个人觉得这三种方法的前提假设都不是必然成立，仅仅是基于经验的总结，它们的实际效果一定程度上收到训练样本分布的影响。比如，有黑灰产大量借助“儿童文具”这个类目下的正常商品的“壳”发布违规内容，并且我们在采样白样本时“儿童文具”这个类目下的白样本采样数量刚好较少时，上述三种方法均有很大可能会把该类目下的正常白样本识别为噪声，同时不能够识别出伪装的黑样本，产生本末倒置的错误效果。毕竟，谁黑谁白（label的正确与否）对模型来说本来就分不清，最终的结果取决于谁占了更大的比例。这也正是黑灰产厉害的地方，通过样本数量来混淆模型视听的做法有点类似于DDos攻击。最终，我们把三种方法集成在一起使用，是集成学习的一种思路，三个臭皮匠，顶个诸葛亮。</p><p>基于样本相似度识别错误标签的方法，虽然想法比较原始，但实际效果还是不错的，噪声标签的检测比较准确。当然，识别效果很依赖于相似度模型本身的性能。</p><h3 id="3-类别相似度模型"><a href="#3-类别相似度模型" class="headerlink" title="3. 类别相似度模型"></a>3. 类别相似度模型</h3><p>首先要解释一下类别相似度与语义相似度的区别。假设每段文本都表达了多重语义，那么语义相似度模型会判定两段语义重合度较高的文本是相似的，而类别相似度模型则要关注两段文本是否都提及了某种特定类型的语义，而不在乎这两段文本整体的语义重合度。举例说明如下：</p><ol><li>手机挂九游挂饰吊坠微信玉石玛瑙指环扣女款创意炸金花链短吊环</li><li>玉石菩提手机扣指环挂绳短款手机挂饰挂件吊坠手机链短男女指环扣</li><li>炸金花透视辅助 详情私聊</li><li>c 美诗美童田慧新款炸金花背心透视成人男款拉丁练习舞服 zq n01</li></ol><p>语义相似度模型可能会判定文本1与文本2更相似，而类别相似度模型则会判定文本1与文本3更相似，因为它们有相同的风险标签：作弊造假。同样，类别相似度模型也会判定文本1和文本4是相似的，而语义相似度模型则可能会判定它俩不相似。</p><p>我们最终的目标是学习一个能够表示文本标签信息的embedding向量。学习到的向量空间需要能够很好地区分不同的风险类别，也就是说，相同类别的风险文本映射到向量空间中相近的位置，不同类别的风险在向量空间中的距离较远。</p><p>语义相似度关注整体语义，要求学习到的embedding向量能够尽可能还原原始输入；而类别相似度仅关注局部语义，既是否在预定义的标签维度上相似。定位不同，则解题思路也不同。语义相似度对应representation learning，而标签相似度对应的解决方案是metric learning。虽然两种技术思路有很大比例的交叉重叠，但是细微的不同可能会对业务效果产生蝴蝶效应般的影响。在风控领域，我们通常不管监管对象表达了多少正常的语义，我们只对监管对象是否触发了某种类型的违规敏感。我们的模型需要识别出隐藏在多种正常语义之下的违规风险语义。</p><h4 id="3-1-文本Encoder"><a href="#3-1-文本Encoder" class="headerlink" title="3.1 文本Encoder"></a>3.1 文本Encoder</h4><p>模型的设计借鉴了深度度量学习（Deep Metric Learning）的思想，目标是学习一个映射函数$f(x, \theta)$，该函数能够把输入映射到一个固定维度的embedding空间，使得输入在该embedding空间中的距离由彼此之间的标签相似度决定。函数$f(x, \theta)$可以是任意结构的深度神经网络。具体地，我们希望相同类的输入映射到embedding空间中距离较近的位置，不同类的输入在embedding空间中的距离也较远。</p><p><img src="https://intranetproxy.alipay.com/skylark/lark/0/2019/png/24824/1571068097540-7c2aa109-f341-4e78-b0c4-f43031e66fe5.png" alt></p><p>模型结构的选择需要考虑两方面的因素：<br>• 足够强大的特征提取能力，能够学习到较好的representation<br>• 速度足够快，在inference阶段Response Time足够短</p><p>基于此，对NLP领域的3大特征提取器（CNN、RNN、Transformer）逐一分析后选择了Transformer作为模型的building block。单层CNN缺乏长距离特征依赖的建模能力，而在商品合规领域长距离组合特征依赖是一类较常见的问题。例如：“<strong>v</strong> 美洲象皮 鞋子内翻式<strong>皮</strong>鞋<strong>n</strong>休闲翻低帮帆美国鞋n男鞋”，需要提取“vpn美国”这样的特征；“【<strong>崔</strong>凤鸣：岳府就<strong>亲</strong>、岳芝荆投<strong>水</strong>、进锣汉衣】”，需要提取出“崔亲水（催情水）”这样的特征。RNN由于顺序依赖的问题不能很好地并行计算，速度比较慢；同时商品标题文本是由高度SEO优化的关键词堆砌组成的，整体上也不具备自然语言的顺序特性。Transformer的self-attention机制能够较好地解决长距离依赖的问题，可以提取不受位置约束的组合特征，同时可以很好的并行计算，速度也较快。</p><p>综上，最终选择了小尺寸的Albert模型作为文本特征提取器。使用小尺寸的albert是出于效果和计算性能的考虑，希望模型在线使用时inference时间足够短，经测试速度比bert_base快4倍。</p><h4 id="3-2-Softmax-loss-vs-Triplet-loss"><a href="#3-2-Softmax-loss-vs-Triplet-loss" class="headerlink" title="3.2 Softmax loss vs Triplet loss"></a>3.2 Softmax loss vs Triplet loss</h4><p>损失函数指导模型如何学习。Triplet loss是Metric Learning领域经典的损失函数，最初用在人脸识别领域。该loss函数要求样本由三元组(anchor, positive, negative)组成，其中positive的样本与anchor样本有相同的类标签，且与negative的样本有不同的类标签。如下图所示：<br><img src="https://omoindrot.github.io/assets/triplet_loss/triplet_loss.png" alt><br>Triplet loss要求negative样本与anchor样本之间的距离比positive样本与anchor之间的距离至少大margin，定义如下：</p><script type="math/tex; mode=display">\mathcal{L} = max(d(a, p) - d(a, n) + margin, 0)</script><p>最近的研究表明，通过为分类设计的softmax loss训练得到的embedding向量在需要计算样本距离的任务中表现也很好，例如可以用大规模softmax分类来训练人脸识别模型。进一步的研究表明，<strong>softmax loss与平滑版的triplet loss是等价的</strong>[5]。网络最后一个全连接层的权重为每个类赋予了一个类中心embedding向量，而网络最后一个隐层的值即为样本的embedding向量。Softmax loss相当于是定义在（原始样本，样本类中心，另一个类的类中兴）三元组上的triplet loss，因此要求原始样本与其对应的类中心的距离比与另外任意一个类中心的距离都要小。要得到好的embedding表示，我的观察是<strong>softmax loss适用于类内方差较小且有大量类别的场景</strong>，比如人脸识别。然而，大规模softmax分类（如千万量级的类别）在工程实现上是非常困难的，受制于gpu显存大小的限制，需要实现数据并行加模型并行的分布式训练模型，可能在国内只有阿里这样为数不多的大公司才有能力实现这样的训练平台吧。相比softmax loss，triplet loss可以方便地训练大规模数据集，不受显存大小的限制；triplet loss的缺点是过于关注局部，导致对样本的构建要求很高且收敛时间长。</p><h4 id="3-3-Hierarchical-Triplet-Loss"><a href="#3-3-Hierarchical-Triplet-Loss" class="headerlink" title="3.3 Hierarchical Triplet Loss"></a>3.3 Hierarchical Triplet Loss</h4><p>在实际业务场景中，层次类目结构是很常见的，比如商品类目体系和风险类目体系都是层级的树状结构。标签的层级结构反应了数据的内在分布，充分利用标签的结构信息可以改进模型的效果，也可以改善triplet loss在挖掘困难样本时的盲目性。</p><p>我们使用商品类目作为白样本的标签，使用风险类目作为黑样本的标签，为了方便商品类目和风险类目都抽象成3层，商品类目取一级类目、二级类目和末级类目三个层级，同样地风险类目取三级类目、映射类目（介于三级和末级之间）、末级类目三个层级，如下图所示。</p><p><img src="https://ftp.bmp.ovh/imgs/2020/02/d4fd9facb428f775.png" alt></p><p>层级triplet loss的定义如下：</p><script type="math/tex; mode=display">\mathcal{L_M} = \frac{1}{Z_M}\sum_{T^z \in T^M} \left[ \middle\|x_a^z-x_p^z\middle\|+ \middle\|x_a^z-x_n^z\middle\| + \alpha_z \right]_+</script><p>其中，$M$是mini batch内的所有样本，$T^z=(x_a^z,x_p^z,x_n^z)$是从mini batch构建的一个三元组，$T^M$是mini batch构成的所有三元组的集合。Hierarchical triplet loss中的margin不是一个固定的值，而是根据正负样本的层级差异构建出的动态的值，具体地，<script type="math/tex">\alpha_z=\beta+d_{H(y_a,y_n)}</script></p><p>要使用triplet loss，在构建训练样本时，mini batch要遵循“C way K shot”的方式，确保同一mini batch内的样本能够构建出数量足够多的有效triplet。具体地，我们在构建训练样本时，由64个实例组成一组，每组实例仅包含两个一级层级标签，其中一个白样本一级层级，一个黑样本一级层级。每个一级层级标签下包含2个二级层级标签，每个二级层级标签下包含4个三级层级标签，每个三级层级标签下包含4个随机挑选的实例。一个mini batch通常需要有几组这样的样本包构成，我们在训练模型时使用8组构建成一个mini batch，也就是每个mini batch包含512个样本。</p><h4 id="3-4-模型结构"><a href="#3-4-模型结构" class="headerlink" title="3.4 模型结构"></a>3.4 模型结构</h4><p><img src="https://ftp.bmp.ovh/imgs/2020/02/8003408ddf59d12a.png" alt></p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ul><li>【1】<a href="https://arxiv.org/abs/1911.00068">Confident Learning: Estimating Uncertainty in Dataset Labels</a></li><li>【2】AN EMPIRICAL STUDY OF EXAMPLE FORGETTING DURING DEEP NEURAL NETWORK LEARNING</li><li>【3】O2U-Net: A Simple Noisy Label Detection Approach for Deep Neural Networks</li><li>【4】<a href="https://arxiv.org/pdf/1909.11942.pdf">A Lite Bert For Self-Supervised Learning Language Representations</a></li><li>【5】SoftTriple Loss: Deep Metric Learning Without Triplet Sampling</li><li>【6】<a href="https://arxiv.org/abs/1810.06951">Deep Metric Learning with Hierarchical Triplet Loss</a></li><li>【7】HIERARCHY-AWARE LOSS FUNCTION ON A TREE STRUCTURED LABEL SPACE FOR AUDIO EVENT DETECTION</li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、背景概述&quot;&gt;&lt;a href=&quot;#一、背景概述&quot; class=&quot;headerlink&quot; title=&quot;一、背景概述&quot;&gt;&lt;/a&gt;一、背景概述&lt;/h2&gt;&lt;p&gt;合规服务业务是基于法律法规建立的信息安全保障机制，保障电商平台的合规经营。商品合规风险指商家未能遵循国家有关法律法规、监管要求或平台制定的经营规则，在平台发布了禁止或限制销售的商品或服务。从发布内容的维度看，违规风险内容主要分为危害国家安全、民生安全、公共安全和市场秩序四大块内容。其中，危害国家安全的违规商品内容包括非法政治、枪支弹药、管制器具、军警用品、暴恐分裂渗透等；危害民生安全的违规商品内容包括毒品、危险化学品、管制药品、管制医疗器械、保护动植物等；危害公共安全的违规商品内容包括色情、低俗、赌博、个人隐私、作弊造假等；违反市场秩序的违规商品内容包括诚信交易类、公序良俗类等。大类的风险类别共计30余种。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ftp.bmp.ovh/imgs/2020/02/a250bc02f66df2e4.jpg&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;坚守风险底线，为用户服务提供良好的制度保障，助力平台提供更简单、更友好的经营环境，保护消费者权益是商品合规业务的主要目标。在商品合规场景，内容维度的风险中文本违规占比约80%。通过商品标题文本的相似检索是发现新风险的有效手段之一。&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="内容安全" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8/"/>
    
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="度量学习" scheme="http://xudongyang.coding.me/tags/%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="语义相似度" scheme="http://xudongyang.coding.me/tags/%E8%AF%AD%E4%B9%89%E7%9B%B8%E4%BC%BC%E5%BA%A6/"/>
    
    <category term="商品合规" scheme="http://xudongyang.coding.me/tags/%E5%95%86%E5%93%81%E5%90%88%E8%A7%84/"/>
    
    <category term="数据清洗" scheme="http://xudongyang.coding.me/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"/>
    
  </entry>
  
  <entry>
    <title>深度学习语义相似度系列：表示学习</title>
    <link href="http://xudongyang.coding.me/represent-learning/"/>
    <id>http://xudongyang.coding.me/represent-learning/</id>
    <published>2020-12-03T12:45:20.000Z</published>
    <updated>2020-12-04T08:17:21.931Z</updated>
    
    <content type="html"><![CDATA[<p>深度学习语义相似度模型旨在学习输入$x$的一个好的特征表示，使得该特征表示能够捕捉到输入的本质结构，且能够促进后续的学习任务，如分类或聚类任务。一般地，我们用深度网络的某个中间层输出作为学习到的特征表示，基于该特征表示可以较方便地得到后续的分类结果，过程如下式所示，其中 $z=f(x,\theta) \in R^d$ 即为学习到的特征表示。</p><script type="math/tex; mode=display">\require{AMScd}\begin{CD}x @>f(x,\theta)>> z(\theta) @>g(z)>> y\end{CD}</script><p>那么什么样的特征表示才是一个好的表示呢？其实，这个问题是和具体任务相关的，不同任务对特征表示的要求是不一样的，因而，我们不能期待在一个任务中有效的特征表示在另一个不同领域的任务上也同样有效。抛开具体任务不谈，原则上，我们期望特征表示既具有一定的信息量（informative），能够充分还原原始输入；又具有一定的区分性（discriminative），能够有效区别开不同类别的输入。从信息论的角度来说，期望能够在最小化原始输入与特征表示的互信息的同时最大化特征表示与目标类别的互信息，形式化如下：</p><script type="math/tex; mode=display">max_{\theta \in \Theta} I(z(\theta), y)- \beta I(x, z(\theta))</script><p>其中，$\beta&gt;0$，用来调节信息量与区分性的权重。</p><a id="more"></a><h2 id="1-语义相似度-vs-类别相似度"><a href="#1-语义相似度-vs-类别相似度" class="headerlink" title="1. 语义相似度 vs 类别相似度"></a>1. 语义相似度 vs 类别相似度</h2><p>首先要解释一下标签相似度与语义相似度的区别。假设每段文本都表达了多重语义，那么语义相似度模型会判定两段语义重合度较高的文本是相似的，而标签相似度模型则要关注两段文本是否都提及了某种特定类型的语义，而不在乎这两段文本整体的语义重合度。举例说明如下：</p><ol><li>手机挂九游挂饰吊坠微信玉石玛瑙指环扣女款创意炸金花链短吊环</li><li>玉石菩提手机扣指环挂绳短款手机挂饰挂件吊坠手机链短男女指环扣</li><li>炸金花透视辅助 详情私聊</li><li>c 美诗美童田慧新款炸金花背心透视成人男款拉丁练习舞服 zq n01</li></ol><p>语义相似度模型可能会判定文本1与文本2更相似，而标签相似度模型则会判定文本1与文本3更相似，因为它们有相同的风险标签：作弊造假。同样，标签相似度模型也会判定文本1和文本4是相似的，而语义相似度模型则可能会判定它俩不相似。</p><p>我们最终的目标是学习一个能够表示文本标签信息的embedding向量。学习到的向量空间需要能够很好地区分不同的风险类别，也就是说，相同类别的风险文本映射到向量空间中相近的位置，不同类别的风险在向量空间中的距离较远。</p><p>语义相似度关注整体语义，要求学习到的embedding向量能够尽可能还原原始输入；而标签相似度仅关注局部语义，既是否在预定义的标签维度上相似。定位不同，则解题思路也不同。语义相似度对应representation learning，而标签相似度对应的解决方案是metric learning。虽然两种技术思路有很大比例的交叉重叠，但是细微的不同可能会对业务效果产生蝴蝶效应般的影响。在风控领域，我们通常不管监管对象表达了多少正常的语义，我们只对监管对象是否触发了某种类型的违规敏感。我们的模型需要识别出隐藏在多种正常语义之下的违规风险语义。</p><h2 id="2-类别标签-vs-成对标签"><a href="#2-类别标签-vs-成对标签" class="headerlink" title="2. 类别标签 vs 成对标签"></a>2. 类别标签 vs 成对标签</h2><p>提供给相似度模型学习的样本标签通常有两种类型，分别是成对标签（pair-wise labels）与类别标签（class-level labels）。例如，做人脸识别时，若样本是一对人脸图像，标签为是否为同一人的0/1标签，则这样的标签称之为成对标签。广义上讲，三元组、四元组标签都属于成对标签。同样是人脸识别场景，若样本为一个人脸图像，标签为该人脸的id（建模为一个超级大规模的分类模型），则这样的标签体系称之为类别标签。</p><p>通常情况下，类别标签使用分类损失函数，如softmax cross entropy loss或其变种，来优化样本特征表示与类别权重向量之间的相似度。成对标签使用某种度量损失函数来优化样本之间的相似度。具体可使用的损失函数可以参考这篇文章《<a href="https://zhuanlan.zhihu.com/p/82199561">深度度量学习中的损失函数</a>》。这两种损失函数本质上并没有根本区别，它们都在尝试最小化类间相似度（between-class similarity）的同时最大化类内相似度(within-class similarity)。</p><h2 id="3-Softmax-loss-vs-Triplet-loss"><a href="#3-Softmax-loss-vs-Triplet-loss" class="headerlink" title="3. Softmax loss vs Triplet loss"></a>3. Softmax loss vs Triplet loss</h2><p>损失函数指导模型如何学习。Triplet loss是Metric Learning领域经典的损失函数，最初用在人脸识别领域。该loss函数要求样本由三元组(anchor, positive, negative)组成，其中positive的样本与anchor样本有相同的类标签，且与negative的样本有不同的类标签。如下图所示：</p><p><img src="https://pic4.zhimg.com/80/v2-032618a79106f1668b4013908cefbd4f_1440w.jpg" alt></p><p>Triplet loss要求negative样本与anchor样本之间的距离比positive样本与anchor之间的距离至少大margin，定义如下：</p><script type="math/tex; mode=display">\mathcal{L} = max(d(a, p) - d(a, n) + margin, 0)</script><p>最近的研究表明，通过为分类设计的softmax loss训练得到的embedding向量在需要计算样本距离的任务中表现也很好，例如可以用大规模softmax分类来训练人脸识别模型。进一步的研究表明，softmax loss与平滑版的triplet loss是等价的。网络最后一个全连接层的权重为每个类赋予了一个类中心embedding向量，而网络最后一个隐层的值即为样本的embedding向量。Softmax loss相当于是定义在（原始样本，样本类中心，另一个类的类中兴）三元组上的triplet loss，因此要求原始样本与其对应的类中心的距离比与另外任意一个类中心的距离都要小。要得到好的embedding表示，我的观察是softmax loss适用于类内方差较小且有大量类别的场景，比如人脸识别。然而，大规模softmax分类（如千万量级的类别）在工程实现上是非常困难的，受制于gpu显存大小的限制，需要实现数据并行加模型并行的分布式训练模型。相比softmax loss，triplet loss可以方便地训练大规模数据集，不受显存大小的限制；triplet loss的缺点是过于关注局部，导致对样本的构建要求很高且收敛时间长。</p><h2 id="4-Circle-Loss"><a href="#4-Circle-Loss" class="headerlink" title="4. Circle Loss"></a>4. Circle Loss</h2><p>除了《深度度量学习中的损失函数》中提到的损失函数，还可以使用最近提出的circle loss，该损失函数在多个场景下被验证效果很好。</p><p>大多数的损失函数，包括triplet loss 和softmax loss损失函数，都是使类间相似性 $s_n$ 和类内相似性 $s_p$ 嵌入到一个相似性对，并且去最小化$(s_n-s_p)$。这样的优化方式是不够灵活的，因为其对每一个单一相似性分数的惩罚强度是相等的。Circle loss提出如果一个相似性得分远离最优的中心，那么其应该被更多的关注(即惩罚)。基于这个目的，circle loss重新加权那些欠优化的相似性得分。</p><p>Circle loss对类别标签和成对标签使用统一的视角。已知在特征空间的一个单个样例 $x$，假设有 $K$ 个类内相似性得分$ \{s_p^i\}(i=1,2,\cdots,K)$， $L$ 个类间相似性得分$ \{s_n^j\}(j=1,2,\cdots,L) $。</p><p>一个统一视角的表示学习损失函数为</p><script type="math/tex; mode=display">\begin{align*} L_{uni} &= log[1 + \sum_{i=1}^K \sum_{j=1}^L exp(\gamma(s_n^j - s_p^i + m))] \\ &= log[1+\sum_{j=1}^L exp(\gamma(s_n^j + m)) \sum_{i=1}^K exp(\gamma(- s_p^i))] \end{align*}</script><p>对上式简单的修改可以得到triplet loss和softmax loss。</p><h3 id="自适应加权-Self-placed-Weighting"><a href="#自适应加权-Self-placed-Weighting" class="headerlink" title="自适应加权(Self-placed Weighting)"></a>自适应加权(Self-placed Weighting)</h3><p>考虑一种更灵活的优化策略去允许每个相似性得分根据其优化状态去选择优化权重。首先忽略掉公式[公式]中阈值(margin) [公式] ，将其转换为Circle loss:</p><script type="math/tex; mode=display">\begin{align*} L_{circle} &= log[1 + \sum_{i=1}^K \sum_{j=1}^L exp(\gamma(\alpha_n^j s_n^j - \alpha_p^i s_p^i))] \\ &= log[1+\sum_{j=1}^L exp(\gamma\alpha_n^js_n^j) \sum_{i=1}^K exp(-\gamma \alpha_p^i s_p^i)] \end{align*}</script><p>在训练期间 $ (\alpha_n^j s_n^j - \alpha_p^i s_p^i) $ 反向传播时对 $s_n^j(s_p^i)$ 的梯度分别乘上 $\alpha_n(\alpha_p)$ 。假设 $s_p^i$ 最优的状态是$O_p$ ， $s_n^j$ 最优的状态是 $O_n$ ，其中( $O_n &lt; O_p$ )。当一个相似性分数远离他的最优点时(即 $s_n^j$ 远离 $O_n$, $s_p^i$ 远离$O_p$)，这时其应该获得更大的权重因子，以便于更好优化使相似性分数趋近于最优值。所以 $\alpha_n^j$ 和 $\alpha_p^i$ 定义为：</p><script type="math/tex; mode=display">\begin{cases}  \alpha_p^i = [O_p-s_p^i]_+ \\ \alpha_n^j = [s_n^j - O_n]_+ \end{cases}</script><p>其中，$[\cdot]_+=max(0,\cdot)$，表示在0截断，确保函数值为非负数。</p><p>Circle loss中的自适应加权，类似于focal loss。</p><h3 id="类内和类间的阈值-With-in-class-and-Between-class-Margins"><a href="#类内和类间的阈值-With-in-class-and-Between-class-Margins" class="headerlink" title="类内和类间的阈值(With-in class and Between-class Margins)"></a>类内和类间的阈值(With-in class and Between-class Margins)</h3><p>在以往的损失函数中通过添加一个阈值 $m$ 去优化 $(s_n-s_p)$ ，因为 $s_n$ 和 $-s_p$ 是对称的，在 $s_n$ 处添加一个正的 $m$ 等价于在 $s_p$ 处添加一个负的 $m$。在Circle loss中 $s_n$ 和 $s_p$ 是不对称的。所以其对 $s_n$ 和 $s_p$ 分别需要一个阈值(margin)，用公式表示如下：</p><script type="math/tex; mode=display">L_{circle}=log[1 + \sum_{j=1}^L exp(\gamma \alpha_n^j(s_n^j-\Delta_n)) \sum_{i=1}^K exp(-\gamma \alpha_p^i(s_p^i - \Delta_p))]</script><p>其中，$\Delta_n$和$\Delta_p$分别为类间和类内的阈值。</p><p>为了减少超参数，设置 $ O_p=1+m, O_n=-m, \Delta_p=1-m, \Delta_n=m $。</p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><p>本文总结了表示学习领域的一些基本概念和常用的损失函数。包括Circle loss在内的常用损失函数的源码可以关注微信工资号：“算法工程师的进阶之路”，回 复 “损失函数”获取。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;深度学习语义相似度模型旨在学习输入$x$的一个好的特征表示，使得该特征表示能够捕捉到输入的本质结构，且能够促进后续的学习任务，如分类或聚类任务。一般地，我们用深度网络的某个中间层输出作为学习到的特征表示，基于该特征表示可以较方便地得到后续的分类结果，过程如下式所示，其中 $z=f(x,\theta) \in R^d$ 即为学习到的特征表示。&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\require{AMScd}
\begin{CD}
x @&gt;f(x,\theta)&gt;&gt; z(\theta) @&gt;g(z)&gt;&gt; y
\end{CD}&lt;/script&gt;&lt;p&gt;那么什么样的特征表示才是一个好的表示呢？其实，这个问题是和具体任务相关的，不同任务对特征表示的要求是不一样的，因而，我们不能期待在一个任务中有效的特征表示在另一个不同领域的任务上也同样有效。抛开具体任务不谈，原则上，我们期望特征表示既具有一定的信息量（informative），能够充分还原原始输入；又具有一定的区分性（discriminative），能够有效区别开不同类别的输入。从信息论的角度来说，期望能够在最小化原始输入与特征表示的互信息的同时最大化特征表示与目标类别的互信息，形式化如下：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;max_{\theta \in \Theta} I(z(\theta), y)- \beta I(x, z(\theta))&lt;/script&gt;&lt;p&gt;其中，$\beta&amp;gt;0$，用来调节信息量与区分性的权重。&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="语义相似度" scheme="http://xudongyang.coding.me/tags/%E8%AF%AD%E4%B9%89%E7%9B%B8%E4%BC%BC%E5%BA%A6/"/>
    
    <category term="NLP" scheme="http://xudongyang.coding.me/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>深度学习语义相似度系列：Ranking Similarity</title>
    <link href="http://xudongyang.coding.me/dsmm/"/>
    <id>http://xudongyang.coding.me/dsmm/</id>
    <published>2020-05-17T04:31:56.000Z</published>
    <updated>2020-12-04T08:17:21.870Z</updated>
    
    <content type="html"><![CDATA[<p>我们在基于深度学习的语义相似度模型系列文章的开篇《<a href="https://zhuanlan.zhihu.com/p/141360938">深度学习语义相似度系列：概论</a>》中介绍了两种语义相似度的学习范式，其中第一种范式的重点是表示学习，也就是为输入对象学习一个低维稠密的embedding向量，使得基于此embedding向量计算的相似度能够很好地反映原始对象之间的相似性。本文主要介绍一种在第一范式下的相似度学习模型的设计。</p><h2 id="相似度度量建模"><a href="#相似度度量建模" class="headerlink" title="相似度度量建模"></a>相似度度量建模</h2><p>一般而言，相似度度量可以建模为回归问题，也可以建模为分类问题，甚至可以建模为排序问题。取决于我们有什么格式的标签数据。</p><a id="more"></a><h3 id="回归相似性学习"><a href="#回归相似性学习" class="headerlink" title="回归相似性学习"></a>回归相似性学习</h3><p>给定一对输入 $(x_{i}^{1},x_{i}^{2})$ 以及它们的相似性度量值 $y_{i}\in R$. 回归相似性学习的目标是在三元组$(x_{i}^{1},x_{i}^{2},y_{i})$训练数据集上学习一个近似函数 $f(x_{i}^{1},x_{i}^{2})\sim y_{i}$。这通常通过最小化一个带正则项的损失函数来达成目标 $\min _{W}\sum _{i}loss(w;x_{i}^{1},x_{i}^{2},y_{i})+reg(w)$。</p><h3 id="分类相似性学习"><a href="#分类相似性学习" class="headerlink" title="分类相似性学习"></a>分类相似性学习</h3><p>假设我们拥有的训练数据为一组成对的相似对象$(x_{i},x_{i}^{+})$集合和不相似对象$(x_{i},x_{i}^{-})$集合，训练数据可以等价地描述为对于每一个成对的输入对象$(x_{i}^{1},x_{i}^{2})$，关联一个二值标签$y_{i}\in \{0,1\}$，标签表示输入的两个对象是否相似。分类相似性学习的目标是学习一个分类器来预测相似度。</p><h3 id="排序相似性学习"><a href="#排序相似性学习" class="headerlink" title="排序相似性学习"></a>排序相似性学习</h3><p>相似度度量建模为回归或者分类问题虽然简单，但很多时候我们没有合适的带有标签的监督数据可用，而且人工标注的代价又很高。这时我们可以考虑把相似性度量问题建模为排序问题。</p><p>具体地，假设我们有一个由三元组$(x_{i},x_{i}^{+},x_{i}^{-})$构成的数据集，其中每个三元组代表了一个预先定义好的偏序关系：$x_{i}$与$x_{i}^{+}$的相似度大于于$x_{i}^{-}$的相似度。排序相似性学习的目标是学习一个相似性度量函数$f$，使得对于一个新的三元组有$f(x,x^{+})&gt;f(x,x^{-})$成立。</p><p>排序相似性学习相比回归相似性学习和分类相似性学习而言，其对监督信号的假设更弱。通常，我们可以更容易地获得偏序关系，比如很多电商平台会在商品详情页页面推荐一些与当前被浏览的商品相似的商品，这这些推荐商品列表中有些会被用户点击，另一些却不会，那么这些被点击的商品相对于没有被点击的商品就构成了很多组偏序关系：当前浏览商品与被点击的商品之间的相似度大于与没有被点击商品之间的相似性。</p><p>当然，无论采用哪一种建模方法，在深度模型学习到决策函数的同时，我们都可以同时得到输入对象的表示向量。</p><h2 id="无监督学习偏序关系，构建模型训练数据"><a href="#无监督学习偏序关系，构建模型训练数据" class="headerlink" title="无监督学习偏序关系，构建模型训练数据"></a>无监督学习偏序关系，构建模型训练数据</h2><p>假设在电商业务场景中，我们的目标是要判断任意两个商品的相似度。首先，我们需要构建训练数据。假设我们决定把相似度判定问题建模为上述排序相似性学习问题，则我们需要有一批商品相似度偏序关系数据。</p><p>在推荐系统中，早有人研究过如何度量商品之间的相似性，比如基于商品点击二部图数据，通过余弦相似度、SimRank++算法、Swing算法等无监督方法计算。</p><p><img src="/dsmm/swing.jpg" alt="swing"></p><p>既然我们可以通过无监督算法计算商品相似度，为什么还需要一个相似性度量模型？本质原因是基于点击二部图计算的商品相似度覆盖率不足，即我们只能计算曝光率较高的热门商品之间的相似度。由于马太效应，电商平台上通常还存在大量的长尾商品未能得到充分的曝光，因而这些商品也未能积累到充分的用户行为数据。对于这些商品，我们无法通过无监督的方式计算其相似度，因而需要一个模型能够把相似度度量推广到任意两个商品上。</p><p>在热门商品上通过无监督方式计算的商品相似性数据可以用来构建相似度模型的训练数据。有了训练数据，我们就可以学习相似性模型了。</p><h2 id="排序相似性模型"><a href="#排序相似性模型" class="headerlink" title="排序相似性模型"></a>排序相似性模型</h2><p>下面我们通过对DSSM模型做一些改造来显式建模相似度偏序关系。</p><p>DSSM模型是微软与2013年提出来的深度语义匹配模型，最初是在检索系统中用来计算查询与文档之间的相关性。模型结构如下图所示：</p><p><img src="http://kubicode.me/img/Study-With-Deep-Structured-Semantic-Model/dssm_arch.png" alt></p><p>DSSM模型的输入由一个查询$Q$，一个相关文档$D^+$，若干个不相关文档$\{D_i^-\}$组成，其中相关文档来自于查询$Q$下被点击的文档，不相关文档采样自查询$Q$的展示文档列表中没有被点击的文档。</p><p>DSSM模型是一个多塔结构，每个塔的结构都相同，参数也共享，是一个典型的孪生网络。每个子网络负责把输入文本转换为特定大小的语义向量，具体子网络的结构有很多变种，有MLP，也有CNN或者RNN等结构。在得到输入文本的语义向量后，模型计算Query和各个Doc之间的语义相似性：</p><script type="math/tex; mode=display">R(Q,D)=cosine(y_Q,y_D)=\frac{y_Q^T y_D}{||y_Q||}</script><p>接着，通过softmax函数可以把Query与正样本$D^+$的语义相似性转化为一个后验概率：</p><script type="math/tex; mode=display">P(D^+|Q)=\frac{exp\left(\gamma R(Q,D^+)\right)}{\sum_{D'} exp\left(\gamma R(Q,D')\right)}</script><p>在训练阶段，通过极大似然估计，我们最小化损失函数：</p><script type="math/tex; mode=display">\begin{equation} Loss=-log\prod_{(Q,D^+)} P(D^+|Q) \label{eq:loss} \end{equation}</script><p>这样的损失函数是在要求模型学会一个知识，就是Query与正样本$D^+$的语义相似性大于Query与任意负样本$D_i^-$的语义相似性，即 $similarity(Q,D^+)&gt;similarity(Q,D_i^-)$。</p><p>个人觉得DSSM模型能否成功应用于其他业务场景，跟负样本的选择有很大的关系。随机采样负样本通常不是一个好的策略，是因为随机采样的负样本与Query之间的相似度通常很低，因而要让模型学会$similarity(Q,D^+)&gt;similarity(Q,D_i^-)$就很容易。如果模型在训练阶段只见过比较容易的样本，那么在应用阶段就很难正确预测比较难的样本。然而，在实际业务场景中，我们通常需要模型能够正确预测比较困难的样本，比如在检索系统的排序阶段，我们已经通过相关性模型在召回阶段过滤掉了大量不相关的文档，剩下需要排序的文档与Query都有某种程度的相关性，这时候我们希望模型能够区分哪些文档与Query更相关。这就是为什么DSSM模型的每个训练样本中若干个不相关文档$\{D_i^-\}$采样自查询$Q$的展示文档列表中没有被点击的文档，而不是随机采样一批文档。</p><p>当我们用DSSM模型来训练商品语义相似度时，该如何构建训练样本呢？通过无监督的方法我们已经有了一批商品相似数据。针对一个锚定的商品Anchor，通过相似数据可以找到一个相似的正样本，记为Positive，如果再随机采样若干个商品作为负样本，记为{Negative}，那么我们就构建了形如DSSM模型的训练样本，是否可以开始训练模型了呢？</p><p>通常情况下，这样构建的训练样本用来训练模型，效果都不能让人满意，原因正如我上面分析的那样，就是在训练阶段，正负样本太容易区分，也就是说偏序关系$similarity(Anchor,Positive)&gt;similarity(Anchor,Negative)$很容易被模型学会。然而，在应用阶段，需要计算相似度的商品分布跟训练时的分布明显不同，我们希望模型能够在一堆都比较相似的商品中识别出谁与目标商品更相似，而不是从一堆大多数商品都与目标商品不相似的商品中识别出哪几个商品是相似的。上升到理论角度，<strong>通过上述方式构建的训练样本分布与应用阶段的样本分布是不一致的，违背了机器学习的独立同分布假设，因而效果不佳就是很自然的事情了</strong>。</p><p>那么该如何构建有效是训练样本呢？所幸的是，通过无监督方法我们不仅仅学习到了商品对之间的相似度，我们还得到了与一个目标商品相似的商品列表，列表中的每个商品都可以度量其与目标商品的相似度。我们可以从相似商品列表中采样训练样本: $\langle A,H,L,N_1,N_2,N_3,\cdots \rangle$，其中$A$表示目标商品；$H$表示与目标商品有较高相似度的商品；$L$表示与目标商品也相似，但是相似程度不如$H$的商品；$N_i$是随机参样的商品，作为负样本。相似度偏序关系$similarity(A,H)&gt;similarity(A,L)$，建模了较困难的相似关系；$similarity(A,H)&gt;similarity(A,N_i)$建模了较容易的相似关系，这样构建的样本是无偏的。</p><p>改造之后的模型结构如下图所示：<br><img src="/dsmm/rank_sim.jpg" alt="model"></p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>我们当然还是可以继续使用公式$\eqref{eq:loss}$定义的损失函数，只需要让训练样本中的商品L也当成是其中一个负样本即可。商品L只是起到了增加样本困难度的作用。</p><p>当然有很多基于softmax函数的魔改loss函数，我们都可以拿过来用。这里介绍一个基于支持向量的间隔softmax损失函数（Support vector guided margin softmax loss），定义如下图所示：</p><p><img src="/dsmm/softmax_loss.jpg" alt="softmax_loss"></p><p>出发点是要使得商品$A$与商品$H$之间的相似性至少比商品$A$与商品$L$之间的相似性高出至少$m$，即$similarity(A,H)&gt;similarity(A,L)+m$；同时商品$A$与商品$H$之间的相似性至少比商品A与商品$N_i$的相似性高出至少$m+m_2$，即$similarity(A,H)&gt;similarity(A,N_i)+m+m2$。</p><p>另外，该损失函数同样要求商品H与目标商品之间的相似度比其他所有商品跟目标商品的相似度都要高，当这一要求未能被满足时，该损失函数通过一个额外的惩罚系数$t$迫使模型更加关注相似度关系未能被满足的样本。具体原理，可参看论文《Support Vector Guided Softmax Loss for Face Recognition》。</p><p>当样本、模型、损失函数都合理定义好之后，就可以开始训练模型了。为了方便各位读者，这里提供一下模型训练的<a href="https://github.com/yangxudong/deeplearning/tree/master/semantic_similarity/CDSMM">tensorflow 源代码</a>，文本特征提取使用CNN网络。如果觉得本文对您有帮助，请帮忙点个赞！</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://en.wikipedia.org/wiki/Similarity_learning">Similarity_learning</a></li><li>Support Vector Guided Softmax Loss for Face Recognition</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;我们在基于深度学习的语义相似度模型系列文章的开篇《&lt;a href=&quot;https://zhuanlan.zhihu.com/p/141360938&quot;&gt;深度学习语义相似度系列：概论&lt;/a&gt;》中介绍了两种语义相似度的学习范式，其中第一种范式的重点是表示学习，也就是为输入对象学习一个低维稠密的embedding向量，使得基于此embedding向量计算的相似度能够很好地反映原始对象之间的相似性。本文主要介绍一种在第一范式下的相似度学习模型的设计。&lt;/p&gt;
&lt;h2 id=&quot;相似度度量建模&quot;&gt;&lt;a href=&quot;#相似度度量建模&quot; class=&quot;headerlink&quot; title=&quot;相似度度量建模&quot;&gt;&lt;/a&gt;相似度度量建模&lt;/h2&gt;&lt;p&gt;一般而言，相似度度量可以建模为回归问题，也可以建模为分类问题，甚至可以建模为排序问题。取决于我们有什么格式的标签数据。&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="语义相似度" scheme="http://xudongyang.coding.me/tags/%E8%AF%AD%E4%B9%89%E7%9B%B8%E4%BC%BC%E5%BA%A6/"/>
    
    <category term="NLP" scheme="http://xudongyang.coding.me/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>深度学习语义相似度系列：概述</title>
    <link href="http://xudongyang.coding.me/deep-similarity/"/>
    <id>http://xudongyang.coding.me/deep-similarity/</id>
    <published>2020-05-16T03:48:50.000Z</published>
    <updated>2020-12-04T08:17:21.868Z</updated>
    
    <content type="html"><![CDATA[<p>语义相似度有很多重要的应用场景，比如在检索系统中用来做语义召回，或者作为精排的特征。基于文本语义相似度模型做相似检索可以辅助文本分类，能够弥补分类模型更新迭代周期长的问题。在智能问答系统中，文本语义相似度模型也能发挥很大的作用。</p><p>目前，学习相似度的深度学习范式主要有两种，如下图所示。<br><img src="https://ftp.bmp.ovh/imgs/2020/02/41546b67b08c4181.jpg" alt></p><a id="more"></a><p>第一种范式是首先通过深度神经网络模型提取输入的表示向量，再通过表示向量的简单距离函数（eg. inner product，欧式距离等）计算两者的相似度。这种方式在提取表示向量的过程中只考虑当前输入，不考虑要与之计算相似度的另一个输入的信息，通常用孪生网络来实现。属于这一类的常用模型包括DSSM、ARC-I、CNTN等。</p><p>第二种范式是通过深度模型提取两个输入的交叉特征，得到匹配信号张量，再聚合为匹配分数，该方式同时考虑两个输入的信息，因而一般情况下效果相比第一种范式要更好，不足之处在于预测阶段需要两两计算相似度，计算空间很高，因而不适合用来做大规模召回，只能用在精排阶段。ARC-II、MatchPyramid、Match-SRNN、Duet等模型都属于这一类型。</p><p>目前NLP领域的热门深度模型BERT、XLNET及其变体，我一般把它们看作是通用的文本特征提取器，根据输入和损失函数的不同定义，既可以应用在第一种范式中，也可以应用在第二种范式中。</p><p>为了更好地理解语义相似度模型在真实业务场景中的应用，下面我们用一个真实的业务场景来举例。这个业务场景就是电商平台的禁限售商品自动识别。</p><p>在一个电商平台做大做强之后，用户和流量水涨船高，一些不法分子发现有利可图，便会在平台上发布大量违规商品，为自己的非法产品引流和变现。商品合规风险指商家未能遵循国家有关法律法规、监管要求或平台制定的经营规则，在平台发布了禁止或限制销售的商品或服务。从发布内容的维度看，违规风险内容主要分为危害国家安全、民生安全、公共安全和市场秩序四大块内容。其中，危害国家安全的违规商品内容包括非法政治、枪支弹药、管制器具、军警用品、暴恐分裂渗透等；危害民生安全的违规商品内容包括毒品、危险化学品、管制药品、管制医疗器械、保护动植物等；危害公共安全的违规商品内容包括色情、低俗、赌博、个人隐私、作弊造假等；违反市场秩序的违规商品内容包括诚信交易类、公序良俗类等。</p><p>坚守风险底线，为用户服务提供良好的制度保障，助力平台提供更简单、更友好的经营环境，保护消费者权益是电商平台商品合规业务的主要目标。</p><p>禁限售商品的识别通常有多种方法，比如关键词规则匹配、风险分类模型、近邻匹配模型等等。一个典型的禁限售商品自动识别体系如下图所示：</p><p><img src="/deep-similarity/prohibit.jpg" alt="pic"></p><p>其中，近邻匹配模型是通过商品语义相似度的方法，计算新发布商品是否与已有违规商品库中的某些违规商品类似，若找到相似度很高的违规商品，则判断新发布商品也疑似违规。整个过程，其实就是k近邻分类。</p><p><img src="/deep-similarity/knn.jpg" alt="pic2"></p><p>K近邻分类能否成功有一个重要的关键点，就是如何计算两个对象的距离，或者说相似度。相似度计算既要准确度高，又要速度快。</p><p>由于新商品与已有违规商品的数量级都巨大，因此我们不可能全部两两组成对输入给模型预测是否相似，因此第二种范式并不适合用在风险召回阶段。第一种范式就比较适合用来做快速召回。这是因为K近邻算法的样本库可以提前提取好特征，也就是说我们可以提前计算好违规商品的表示向量。新商品需要分类时，只需要实时提取好当前查询商品的特征向量，再通过向量检索引擎查询top K个最相似的邻居，最后根据KNN算法判定分类结果即可。</p><p>向量检索引擎可以解决相似度计算速度要快的问题，另一个待解决的问题则是相似度计算准确度要高。这完全取决于模型提取的特征向量的表示能力。表示学习是深度学习的一个重要的研究子领域。从本系列文章的下一篇开始，我们将会一些常用的相似度模型，相似度度量的损失函数，以及一些实践经验。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;语义相似度有很多重要的应用场景，比如在检索系统中用来做语义召回，或者作为精排的特征。基于文本语义相似度模型做相似检索可以辅助文本分类，能够弥补分类模型更新迭代周期长的问题。在智能问答系统中，文本语义相似度模型也能发挥很大的作用。&lt;/p&gt;
&lt;p&gt;目前，学习相似度的深度学习范式主要有两种，如下图所示。&lt;br&gt;&lt;img src=&quot;https://ftp.bmp.ovh/imgs/2020/02/41546b67b08c4181.jpg&quot; alt&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="语义相似度" scheme="http://xudongyang.coding.me/tags/%E8%AF%AD%E4%B9%89%E7%9B%B8%E4%BC%BC%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>基于行列式点过程的推荐多样性提升算法的直观理解</title>
    <link href="http://xudongyang.coding.me/fast-dpp-map/"/>
    <id>http://xudongyang.coding.me/fast-dpp-map/</id>
    <published>2019-11-30T02:26:08.000Z</published>
    <updated>2020-12-04T08:17:21.879Z</updated>
    
    <content type="html"><![CDATA[<p>多样性和相关性是衡量推荐系统的常用的指标，这两个指标同时影响着推荐系统的商业目标和用户体验。Hulu在NIPS 2018 会议上发表的论文《<a href="http://papers.nips.cc/paper/7805-fast-greedy-map-inference-for-determinantal-point-process-to-improve-recommendation-diversity.pdf">Fast Greedy MAP Inference for Determinantal Point Process to Improve Recommendation Diversity</a>》中，提出了基于行列式点过程的推荐多样性提升算法，虽然网上可以找到很多解读文章，但个人觉得解释得不是很直观和易懂。本文尝试给出一种更加简单和容易理解的解读，并且给出算法的实现代码，是对自己理解过程的一次总结，也希望能够帮助到读者。</p><p>我们有一个待推荐的候选商品集合$Z=\lbrace 1,2,…,M \rbrace$，针对一个给定的用户，推荐系统需要选择商品集合$Z$中的$N$个商品展现给用户，同时希望展现给用户的商品列表满足一定相关性和多样性。这就是我们要解决的问题，那么首先我们必须弄清楚如何衡量相关性和多样性。<br><a id="more"></a></p><h2 id="如何量化推荐列表的多样性和相关性"><a href="#如何量化推荐列表的多样性和相关性" class="headerlink" title="如何量化推荐列表的多样性和相关性"></a>如何量化推荐列表的多样性和相关性</h2><p>相关性很好理解，就是推荐给用户的商品必须符合用户的兴趣，满足用户的购物需求。用户会用点击行为来表达兴趣，用下单行为来满足购物需求。用户的点击和购买行为就是系统收集到的样本，基于这些样本推荐系统的从业者一直以来都在做的点击率和转化率预估，其实就是对相关性的一种衡量和量化。给定用户 $u$ 和候选商品集合 $C_u$，定义向量 $r_u$ 为相关性度量值，其中 $r_i$ 表示用户与商品 $i$ 的相关程度，具体地，可以用用户对该商品的预估点击转化率（$pCTCVR$）来刻画。关于如何预估点击转化率，可以参考《<a href="https://zhuanlan.zhihu.com/p/37562283">CVR预估的新思路：完整空间多任务模型</a>》这篇文章。</p><p>推荐多样性（diversity）衡量单个推荐列表中物品之间的差异程度，通过计算在同一个推荐 list 中两两 Item 之间的相似度的平均值来进行衡量。那么如何量化推荐列表的多样性呢？要量化推荐列表的多样性，我们首先要能够计算列表中任意两个商品之间的相似性（similarity）。计算两个对象之间的相似性有很多方法，这里我们假设用特征向量的余弦相似度的方法来计算。商品在表示成特征向量之后，两个特征向量之间的夹角越小，说明这两个向量越相似，也就是对应的两个商品越相似。</p><p>推荐列表中的商品彼此之间的相似度越低，推荐列表的多样性也就越高。我们用一个定义在商品集合的相似度矩阵上的函数 $f(S)\in R$ 来表示商品集合的多样性。函数的输入是商品集合的相似度矩阵，矩阵的每个元素 $S_{ij}=cosine(x_i, x_j)$ 是商品对 $\langle i,j \rangle$ 的相似度度量；函数的输出是衡量商品集合多样性程度的一个标量。那么，什么样的函数可以满足这样的定义呢？</p><p>一个很好的选择就是矩阵 $S$ 的行列式 $det(S)$。这是因为矩阵可以看着是一组向量的集合，而矩阵的行列式的物理意义为矩阵中的各个向量张成的平行多面体体积的平方。这些向量彼此之间越不相似，向量间的夹角就会越大，张成的平行多面体的体积也就越大，<strong>矩阵的行列式也就越大，对应的商品集合的多样性也就越高</strong>。当这些向量彼此正交的时候，多样性达到最高。可以通过一个二维平面上的例子直观地理解一下这背后的逻辑。</p><p><img src="/fast-dpp-map/det.jpeg" alt></p><p>现在我们可以分别度量相关性和多样性了，接下来的问题就是能否在同一个过程中同时度量相关性和多样性。答案当然是肯定的，具体地，我们引入一个叫做核矩阵(kernel matrix)的概念，用核矩阵的行列式来同时度量商品集合的多样性和相关性。那么核矩阵是如何定义的呢？怎么构建核矩阵才能有机融合相关性和多样性呢？</p><p>核矩阵是由$n$维欧氏空间中$k$个向量的内积组成的矩阵，可被称之为Gram矩阵。所以，核矩阵是一个半正定(positive semidefinite, PSD)矩阵。关于半正定矩阵的定义，可以参考“<a href="https://www.cnblogs.com/marsggbo/p/11461155.html">如何理解正定矩阵和半正定矩阵</a>”。</p><blockquote><p>给定一个大小为 $n \times n$ 的实对称矩阵 $A$，若对于任意长度为 $n$ 的非零向量 $x$，有 $ x^T Ax$恒成立，则矩阵 $A$ 是一个<strong>半正定矩阵</strong>。</p></blockquote><p>因为核矩阵 $L$是一个半正定矩阵，所以可以被分解为 $L=B^T B$，其中 $B$ 的每一列(column)为候选集中商品的表示向量，具体地$B$ 的每一个列向量可以构建为相关性分数 $r_i \ge 0$ 与归一化后的商品特征向量 $f_i \in R^D (||f_i||_2=1)$ 的乘积。因此，核矩阵中的元素可以被写成：</p><script type="math/tex; mode=display">L_{ij} = \langle B_i,B_j \rangle = \langle r_i f_i, r_j f_j \rangle = r_i r_j \langle f_i, f_j \rangle</script><p>其中，$\langle f_i, f_j \rangle = S_{ij}$ 是商品 $i$ 与商品 $j$ 之间的相似度的度量。所以，核矩阵可以被进一步写为:</p><script type="math/tex; mode=display">L = Diag(r_u) \cdot S \cdot Diag(r_u)</script><p>其中，$Diag(r_u)$ 是对角阵（diagonal matrix），它的对角向量（diagonal vector）是相关性度量向量$r_u$。</p><p>假设系统筛选出的推荐给用户的商品子集为 $R_u$，$L_{R_u}$表示被商品子集$R_u$索引的核矩阵的子矩阵，则商品子集 $R_u$ 的相关性和多样性可以用下式度量：</p><script type="math/tex; mode=display">log det(L_{R_u}) = \sum\limits_{i \in R_u} log(r_{u,i}^2) + log det(S_{R_u})</script><p>其中，$det(\cdot)$ 表示矩阵的行列式。上式等号右边的两项分别度量推荐列表的相关性和多样性；等式把相关性度量和多样性度量有机地融合在一起。</p><h2 id="如何选择能够最大化相关性和多样性的商品子集"><a href="#如何选择能够最大化相关性和多样性的商品子集" class="headerlink" title="如何选择能够最大化相关性和多样性的商品子集"></a>如何选择能够最大化相关性和多样性的商品子集</h2><p>前一小节解释了如何度量推荐列表的相关性和多样性，但并未解释如何从候选商品集合中选择商品组成最终的推荐列表。商品列表选择的过程其实就是从所有的候选商品子集中选择一个能使上述量化值最大的子集，而这个选择的过程需要借助行列式点过程来实现。</p><p>DPP（Determinantal Point Process）行列式点过程，是一种性能较高的概率模型，其将复杂的概率计算转换成简单的行列式计算，通过核矩阵的行列式计算每一个子集的概率。该概率可以理解为用户对推荐列表满意的概率，受到相关性与多样性两个因素的影响。具体地，对于一个离散的集合$Z=\lbrace 1,2,…,M \rbrace$，一个DPP $P$ 是定义在该集合的所有子集$2^Z$上的一个概率度量。当 $P$ 会为空集给出非零概率时，存在一个矩阵 $L∈R^{M×M}$，对于所有子集$Y⊆Z$，$Y$的概率为：</p><script type="math/tex; mode=display">P(Y) \propto det(L_Y)</script><p>其中，$L$ 是一个实数型(real)、半正定(positive semidefinite)的kernel matrix，它通过 $Z$ 的元素进行索引。</p><p>为了描述的方便，给出一些符合定义：</p><ul><li>集合使用大写字母表示，比如：$Z$。</li><li>向量和矩阵分别通过粗体小写字母和粗体大写字母表示。</li><li>$(\cdot)^{\top}$ 表示向量或矩阵的转置。</li><li>$⟨x,y⟩$是向量$x$和$y$的内积。</li><li>给定子集$X$和$Y$，$L_{X,Y}$是 $L$ 的sub-matrix，通过行中的$X$和列中的$Y$索引。</li></ul><p>出于简洁，我们假设:</p><ul><li>$L_{X,X} = L_X, L_{X,\lbrace i \rbrace}=L_{X,i}$，</li><li>以及$L_{\lbrace i \rbrace, X} = L_{i,X}$。</li><li>$det(L)$是$L$的行列式，惯例上令$det(L_\emptyset)=1$。</li></ul><p>推荐列表就是从候选商品集合中选择能够最大化后验概率的商品子集，这一筛选过程就是行列式点过程的最大后验概率推断MAP（maximum a posteriori inference）。</p><script type="math/tex; mode=display">Y_{map} = \underset{y \subseteq Z}{argmax} \ det(L_Y)</script><p>行列式点过程的MAP求解是一个复杂的过程，Hulu的论文中提出了一种改进的贪心算法能够快速求解，该算法的时间复杂度为 $O(N^2 M)$，$N$为返回的商品列表中商品的个数。</p><p>这一求解过程简单来说就是每次从候选集中贪心地选择一个能使边际收益（ marginal gain）最大的商品加入到最终的结果子集中，直到满足停止条件为止，即每次选择商品 $j$ 添加到结果集中 $Y_g$中，$Y_g$初始化为空集，商品 $j$ 需要满足下面的等式：</p><script type="math/tex; mode=display">j = \underset{i \in Z \backslash Y_g}{argmax} \ log det(Y_g \cup \lbrace i \rbrace) - log det(Y_g) \tag{1}</script><p>其中行列式$det(L_{Y_g})$直接求解复杂度较高，需要有巧妙的方法简化计算过程。假设$det(L_{Y_g})&gt;0$，$L_{Y_g}$的柯列斯基分解(Cholesky decomposition)如下：</p><script type="math/tex; mode=display">L_{Y_g} = V V^{\top}</script><p>其中$V$是一个可逆下三角矩阵。对于任意$i \in Z \backslash Y_g$，$L_{Y_g \cup \lbrace i \rbrace}$的柯列斯基分解(Cholesky decomposition)可以定为：</p><script type="math/tex; mode=display">L_{Y_g \cup \lbrace i \rbrace} = \begin{bmatrix}    L_{Y_g} & L_{Y_{g,i}} \\    L_{i,Y_g} & L_{ii} \\    \end{bmatrix} = \begin{bmatrix}    V & 0 \\    c_i & d_i \\    \end{bmatrix} \begin{bmatrix}    V & 0 \\    c_i & d_i \\    \end{bmatrix}^{\top} \tag{2}</script><p>其中，等式右边右上角的子矩阵为0向量，是因为$V$是一个下三角矩阵。根据矩阵乘法公式，行向量$c_i$和标量$d_i≥0$满足：</p><p>\begin{align}<br>V{c_i^{\top}} &amp;= L_{Y_{g,i}} \tag{3} \\<br>d_i^2 &amp;= L_{ii} - | c_i |_2^2 \tag{4}<br>\end{align}</p><p>另外，根据等式(2), 可以得到：</p><script type="math/tex; mode=display">det(L_{Y_g \cup \lbrace i \rbrace}) = det(VV^{\top}) \cdot d_i^2 = det(L_{Y_g}) \cdot d_i^2 \tag{5}</script><p>因此，等式(1)可以简化为：</p><script type="math/tex; mode=display">j = \underset{i \in Z \backslash Y_g}{argmax} \ log(d_i^2) \tag{6}</script><p>一旦等式(6)被求解，根据等式(2)，$L_{Y_g \cup \lbrace i \rbrace}$的Cholesky decomposition变成是：</p><script type="math/tex; mode=display">L_{Y_g \cup \lbrace j \rbrace} = \begin{bmatrix}    V & 0 \\    c_j & d_j \\    \end{bmatrix} \begin{bmatrix}    V & 0 \\    c_j & d_j \\    \end{bmatrix}^{\top}  \tag{7}</script><p>其中，$c_j$ 和 $d_j$ 是已经计算出来了的。当一个新item被添加到$Y_g$之后，$L_{Y_g}$的Cholesky因子可以被有效更新。</p><p>对于每个item $i$，$c_i$ 和 $d_i$ 可以被增量更新。在等式(6)被求解后，将 $c_i’$ 和 $d_i’$ 定义为新的需求求解的向量和标量，其中 $i \in Z \backslash (Y_g \cup \lbrace j \rbrace)$。根据等式(3)和等式(7)，我们有：</p><script type="math/tex; mode=display">\begin{bmatrix}V & 0 \\c_i & d_i \\\end{bmatrix} c_i'^T = L_{Y_g \cup \lbrace j \rbrace, i} = \begin{bmatrix}L_{Y_{g,i}} \\L_{ji} \\\end{bmatrix} \tag{8}</script><p>通过将等式(3)和等式(8)组合，我们可以对 $c_i$ 和 $d^2_i$ 进行更新，有：</p><script type="math/tex; mode=display">c_i' = \begin{bmatrix} c_i & (L_{ji}- \langle c_j,c_i\rangle) / d_j \end{bmatrix} \doteq  \begin{bmatrix} c_i & e_i \end{bmatrix}</script><p>等式(4)意味着：</p><script type="math/tex; mode=display">d_i'^2 = L_{ii} - \| c_i' \|_2^2 = L_{ii} - \| c_i \|_2^2 - e_i^2 = d_i^2 - e_i^2 \tag{9}</script><p>最初，$Y_g = \emptyset$, 等式(5)意味着: $d_i^2 = det(L_{ii}) = L_{ii}$。完整算法描述如下：</p><p><img src="/fast-dpp-map/fast-dpp-map.jpg" alt></p><p>其中，停止条件（stopping criteria）为$d_j^2 &lt; 1$或者$|Y_g| &gt; N$。</p><h2 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h2><p>Python代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def dpp(kernel_matrix, max_length, epsilon&#x3D;1E-10):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    fast implementation of the greedy algorithm</span><br><span class="line">    :param kernel_matrix: 2-d array</span><br><span class="line">    :param max_length: positive int</span><br><span class="line">    :param epsilon: small positive scalar</span><br><span class="line">    :return: list</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    item_size &#x3D; kernel_matrix.shape[0]</span><br><span class="line">    cis &#x3D; np.zeros((max_length, item_size))</span><br><span class="line">    di2s &#x3D; np.copy(np.diag(kernel_matrix))</span><br><span class="line">    selected_items &#x3D; list()</span><br><span class="line">    selected_item &#x3D; np.argmax(di2s)</span><br><span class="line">    selected_items.append(selected_item)</span><br><span class="line">    while len(selected_items) &lt; max_length:</span><br><span class="line">        k &#x3D; len(selected_items) - 1</span><br><span class="line">        ci_optimal &#x3D; cis[:k, selected_item]</span><br><span class="line">        di_optimal &#x3D; math.sqrt(di2s[selected_item])</span><br><span class="line">        elements &#x3D; kernel_matrix[selected_item, :]</span><br><span class="line">        eis &#x3D; (elements - np.dot(ci_optimal, cis[:k, :])) &#x2F; di_optimal</span><br><span class="line">        cis[k, :] &#x3D; eis</span><br><span class="line">        di2s -&#x3D; np.square(eis)</span><br><span class="line">        selected_item &#x3D; np.argmax(di2s)</span><br><span class="line">        if di2s[selected_item] &lt; epsilon:</span><br><span class="line">            break</span><br><span class="line">        selected_items.append(selected_item)</span><br><span class="line">    return selected_items</span><br></pre></td></tr></table></figure></p><p>测试代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">from dpp import *</span><br><span class="line"></span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">item_size &#x3D; 5000</span><br><span class="line">feature_dimension &#x3D; 5000</span><br><span class="line">max_length &#x3D; 1000</span><br><span class="line"></span><br><span class="line">scores &#x3D; np.exp(0.01 * np.random.randn(item_size) + 0.2)</span><br><span class="line">feature_vectors &#x3D; np.random.randn(item_size, feature_dimension)</span><br><span class="line"></span><br><span class="line">feature_vectors &#x2F;&#x3D; np.linalg.norm(feature_vectors, axis&#x3D;1, keepdims&#x3D;True)</span><br><span class="line">similarities &#x3D; np.dot(feature_vectors, feature_vectors.T)</span><br><span class="line">kernel_matrix &#x3D; scores.reshape((item_size, 1)) * similarities * scores.reshape((1, item_size))</span><br><span class="line"></span><br><span class="line">print &#39;kernel matrix generated!&#39;</span><br><span class="line"></span><br><span class="line">t &#x3D; time.time()</span><br><span class="line">result &#x3D; dpp(kernel_matrix, max_length)</span><br><span class="line">print &#39;algorithm running time: &#39; + &#39;\t&#39; + &quot;&#123;0:.4e&#125;&quot;.format(time.time() - t)</span><br></pre></td></tr></table></figure></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://blog.csdn.net/yz930618/article/details/84862751">《基于行列式点过程的推荐多样性提升算法》原理详解</a></li><li><a href="http://www.doc88.com/p-8089116412071.html">行列式点过程</a></li><li><a href="http://d0evi1.com/fast-map-dpp/">论文解读</a>、<a href="https://vimeo.com/240776466">作者报告视频</a></li><li><a href="https://dspace.mit.edu/bitstream/handle/1721.1/103671/953457802-MIT.pdf?sequence=1">Learning and Enforcing Diversity with Determinantal Point Processes</a></li></ol><h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/35753281">Contextual Bandit算法在推荐系统中的实现及应用</a></li><li><a href="https://zhuanlan.zhihu.com/p/35512064">商品人气分模型</a></li><li><a href="https://zhuanlan.zhihu.com/p/36051733">电商平台商家流量分配机制算法</a></li><li><a href="https://yangxudong.github.io">个人博客</a>，会不定期更新</li><li><a href="https://zhuanlan.zhihu.com/p/35465875">主流CTR预估模型的演化及对比</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;多样性和相关性是衡量推荐系统的常用的指标，这两个指标同时影响着推荐系统的商业目标和用户体验。Hulu在NIPS 2018 会议上发表的论文《&lt;a href=&quot;http://papers.nips.cc/paper/7805-fast-greedy-map-inference-for-determinantal-point-process-to-improve-recommendation-diversity.pdf&quot;&gt;Fast Greedy MAP Inference for Determinantal Point Process to Improve Recommendation Diversity&lt;/a&gt;》中，提出了基于行列式点过程的推荐多样性提升算法，虽然网上可以找到很多解读文章，但个人觉得解释得不是很直观和易懂。本文尝试给出一种更加简单和容易理解的解读，并且给出算法的实现代码，是对自己理解过程的一次总结，也希望能够帮助到读者。&lt;/p&gt;
&lt;p&gt;我们有一个待推荐的候选商品集合$Z=\lbrace 1,2,…,M \rbrace$，针对一个给定的用户，推荐系统需要选择商品集合$Z$中的$N$个商品展现给用户，同时希望展现给用户的商品列表满足一定相关性和多样性。这就是我们要解决的问题，那么首先我们必须弄清楚如何衡量相关性和多样性。&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="推荐系统" scheme="http://xudongyang.coding.me/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="推荐算法" scheme="http://xudongyang.coding.me/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
    <category term="多样性" scheme="http://xudongyang.coding.me/tags/%E5%A4%9A%E6%A0%B7%E6%80%A7/"/>
    
    <category term="行列式点过程" scheme="http://xudongyang.coding.me/tags/%E8%A1%8C%E5%88%97%E5%BC%8F%E7%82%B9%E8%BF%87%E7%A8%8B/"/>
    
    <category term="DPP" scheme="http://xudongyang.coding.me/tags/DPP/"/>
    
  </entry>
  
  <entry>
    <title>深度度量学习中的损失函数</title>
    <link href="http://xudongyang.coding.me/deep-metric-learning/"/>
    <id>http://xudongyang.coding.me/deep-metric-learning/</id>
    <published>2019-09-11T09:18:55.000Z</published>
    <updated>2020-12-04T14:52:03.954Z</updated>
    
    <content type="html"><![CDATA[<p>度量学习（metric learning）研究如何在一个特定的任务上学习一个距离函数，使得该距离函数能够帮助基于近邻的算法（kNN、k-means等）取得较好的性能。深度度量学习（deep metric learning）是度量学习的一种方法，它的目标是学习一个从原始特征到低维稠密的向量空间（称之为嵌入空间，embedding space）的映射，使得同类对象在嵌入空间上使用常用的距离函数（欧氏距离、cosine距离等）计算的距离比较近，而不同类的对象之间的距离则比较远。深度度量学习在计算机视觉领域取得了非常多的成功的应用，比如人脸识别、人脸验证、图像检索、签名验证、行人重识别等。</p><p>损失函数在深度度量学习中起到了非常重要的作用。很多深度度量学习的损失函数构建在样本对(pair)或者样本三元组(triplet)之上，因而样本空间的量级（$O(N^2)$或者$O(N^3)$）非常大。一般而言，模型在训练过程中很难穷举学习所有的样本对；并且大多数样本对或者样本三元组的信息量是很小的，尤其在模型训练的后期，这些样本对或者样本三元组上梯度值几乎为0。若不做任何针对性的优化，学习算法的收敛速度会很慢，且易陷入局部最优。</p><p>困难样本挖掘是加快学习算法的收敛速度，并改进学习效果的一种重要手段。它通常和特定的损失函数一起使用，以期望达到最好的效果。困难样本挖掘可以理解为在学习过程中给每一个样本对动态赋予一个权重。在学习不同样本对时给它们不同的权重，如果某个样本对包含的信息比较多或比较难学习，那么它就需要比较大的权重。信息量较少的样本对则会被赋予较小的权重。若某些样本对被赋予的权重为0，则意味着在计算梯度时不考虑这些样本对，相当于这些样本对被丢弃了。</p><p>不同的损失函数在设计时，对于样本对的赋权是不同的，或者说与这些损失函数配合使用的困难样本挖掘方法是不同的。下面列举一些常用的深度度量学习中使用的损失函数，同时了解一下它们是如何来给做困难样本挖掘的。<br><a id="more"></a></p><h2 id="损失函数-Loss-functions"><a href="#损失函数-Loss-functions" class="headerlink" title="损失函数(Loss functions)"></a>损失函数(Loss functions)</h2><h3 id="1-Contrastive-loss"><a href="#1-Contrastive-loss" class="headerlink" title="1. Contrastive loss"></a>1. Contrastive loss</h3><p>Contrastive loss的输入是两个样本组成的样本对，label为该样本对是否属于同一类。</p><script type="math/tex; mode=display">L(x_i,x_j;f)={\bf 1}\{y_i=y_j\}  \|f_i-f_j\|_2^2 + {\bf 1}\{y_i \neq y_j\} max(0, m-\|f_i-f_j\|_2)^2</script><p>其中，$f_i$是函数$f(x_i)$的简写，表示输入$x_i$映射之后的embedding向量；${\bf 1}\{ \cdot \}$是指示函数，在输入为true时返回1，否则返回0；$m$是预先设定的超参数，表示不同类样本之间的距离应超过该margin值。</p><p><img src="/deep-metric-learning/contrastive-loss.jpg" alt="contrastive loss"></p><p>最原始的contrastive loss只考虑了输入样本对本身的相似性。</p><h3 id="2-Triplet-loss"><a href="#2-Triplet-loss" class="headerlink" title="2. Triplet loss"></a>2. Triplet loss</h3><p>Triplet loss的输入由一个三元组组成，每个三元组包含一个query、一个与query属于同一类的正样本、一个与query属于不同类的负样本。</p><script type="math/tex; mode=display">L(x,x^+,x^-;f)=max \left(0, \|f-f^+\|_2^2 -\|f-f^-\|_2^2 + m \right)</script><p>Triplet loss要求query到负样本的距离与query到正样本的距离之差要大于$m$。</p><p>Contrastive loss和triplet loss都很常用，一般来说，Triplet-Loss的效果比Contrastive Loss的效果要好，因为他考虑了正负样本与锚点的距离关系。然而，这两种loss函数如果单独使用则会遭遇收敛速度慢的问题。在学习过程的后期，大多数样本都能满足损失函数的约束条件，这些样本对应进一步学习的贡献很小。因此，这两种损失函数都需要配合hard sample mining的学习策略一起使用，例如FaceNet提出的simi-hard negative sample mining方法。</p><p><img src="/deep-metric-learning/triplet-loss.jpg" alt="triplet loss"></p><h3 id="3-N-pair-ms-loss"><a href="#3-N-pair-ms-loss" class="headerlink" title="3. N-pair-ms loss"></a>3. N-pair-ms loss</h3><p>Triplet loss在学习参数的更新过程中，只比较了一个负样本，而忽略了其他类的负样本。因而，只能促进query的embedding向量与选中的一个负样本保持较大的距离，但却不能保证与其他未被选择的负样本也保持较大的距离。</p><p>N-pair-ms loss对Triplet loss的上述问题进行了改进，不同于Triplet Loss使用单个的正负样本，N-pair-ms loss损失函数利用了数据之间的结构信息来学习到更有区别性的表示，其在每次参数更新的过程中同时考虑了query样本与其他多个不同类的负样本之间的关系，促使query与其他所有类之间都保持距离，这样能够加快模型的收敛速度。N-pair-ms loss的每个训练样本由$N+1$元组组成，即$\{x, x^+, x_1, \cdots, x_{N-1} \}$，其中$x^+$是相对于$x$而言的正样本，$\{x_i\}_{i=1}^{N-1}$是负样本。$N+1$元组一般不会提前构建好，而是在训练的过程中，从同一个mini batch中构建出来。</p><script type="math/tex; mode=display">L(x,x^+,\{x_i\}_{i=1}^{N-1};f)=log\left(1+\sum_{i=1}^{N-1}exp(f^Tf_i - f^Tf^+) \right)</script><p>其中，$f(\cdot;\theta)$是由深度神经网络定义的embedding kernel.</p><h3 id="4-Lifted-Struct-loss"><a href="#4-Lifted-Struct-loss" class="headerlink" title="4. Lifted Struct loss"></a>4. Lifted Struct loss</h3><p>Lifted Struct loss基于训练集（mini batch）中所有的正负样本对来计算loss，其定义如下：</p><script type="math/tex; mode=display">\begin{align}L &= \frac{1}{2 \lvert \hat{P} \rvert} \sum_{(i, j) \in \hat{P}} \max (0, L_{i, j})^2 \\L_{i, j} &= \max ( \max_{(i, k) \in \hat{N}} \alpha - D_{i, k}, \max_{(j, l) \in \hat{N}} \alpha - D_{j, l} ) + D_{i, j}\end{align}</script><p>其中，$\hat{P}$是正样本对（pair的左变量和右边量来自同一个类）的集合；$\hat{N}$是负样本对的集合；$D_{i,j}$是样本对$\{i,j\}$的距离。</p><p>仔细分析该loss function，发现对于每一个正样本对$\{i,j\}$，模型分别挖掘其左变量$i$和右边量$j$对应的最困难的负样本，独立地找到距离左变量最近的负样本，假设为$k$；同时找到距离右边量最近的负样本，假设为$l$。接着通过比较$D_{i,k}$和$D_{j,l}$，找出其中较小的距离对应的负样本，假设为$n$。最后，计算三元组$\{i,j,n\}$确定的triplet loss函数。如下图所示：</p><p><img src="http://lijiancheng0614.github.io/2016/03/17/2016_03_17_Deep_Metric_Learning/fig4.png" alt></p><p>Hard negative edge is mined with respect to each left and right example per each positive pairs. In this illustration with 6 examples in the batch, both x3 and x4 independently compares against all other negative edges and mines the hardest negative edge.</p><p>Lifted Struct loss与triplet loss的不同之处就在于，triplet loss的样本三元组是提前确定好的，而Lifted Struct loss是为每一个正样本对动态构建最困难的三元组，在构建的过程中考虑了（mini batch中)所有的负样本。</p><p>由于上述定义的Lifted Struct loss函数是不光滑的函数，嵌套的max函数在实际中容易导致网络陷入较差的局部最优，因此可以改写为一个光滑的上界函数来避免词问题。</p><script type="math/tex; mode=display">\begin{align}\tilde{L}_{i, j} &= \log ( \sum_{(i, k) \in N} \exp \{\alpha - D_{i, k}\} + \sum_{(j, l) \in N} \exp \{\alpha - D_{j, l}\} ) + D_{i, j} \\\tilde{L} &= \frac{1}{2 \lvert P \rvert} \sum_{(i, j) \in P} \max (0, \tilde{L}_{i, j})^2\end{align}</script><p><img src="/deep-metric-learning/lifted-structure.jpg" alt="triplet loss"></p><h3 id="5-Proxy-NCA-loss"><a href="#5-Proxy-NCA-loss" class="headerlink" title="5. Proxy NCA loss"></a>5. Proxy NCA loss</h3><p>这个方法提出的目的是去解决采样的问题。假设W代表着训练集中的一小部分数据，在采样时通过选择与W中距离最近的一个样本u作为代理(proxy), 即：<script type="math/tex">p(u)=argmin_{w \in W}d(u,w)</script></p><p>基于选择的proxy, NCA损失为：</p><script type="math/tex; mode=display">L(a,u,)=-log\left( \frac{exp(-d(a,p(u)))}{\sum_{z \in Z}exp(-d(a,p(z)))}  \right)</script><h3 id="6-Ranked-list-loss"><a href="#6-Ranked-list-loss" class="headerlink" title="6. Ranked list loss"></a>6. Ranked list loss</h3><p>上述的损失函数都存在如下的两点局限性：</p><ol><li>这些损失函数虽然都提出了加入更多的负样本来获得结构化的信息，但是使用的负样本仅仅是一小部分；</li><li>另外这些损失函数没有考虑类内的数据分布，都追求将同一个class压缩到一个点上。</li></ol><p>Ranked List Loss对着两个问题提出了改进。</p><p>假设$X=\{(x_i, y_i)\}_{i=1}^N$表示训练集，其中每一组元素$(x_i, y_i)$表示成对的样本与其标签，总共包括$C$个类别，即，$y_i \in [i,2,\cdots,C]$, $\{x_i^c\}_{i=1}^{N_c}$表示属于类别$c$的所有样本，$N_c$表示相应类别的样本数量。</p><p>我们的目标是学习到一个函数$f$使得正样本对之间的相似度高于负样本之间的相似度。为了将正负样本区分开，Ranked List Loss希望负样本之间的距离大于某个阈值$α$，并且正样本之间的距离小于$α-m$，即正负样本之间至少有$m$的间隔。基于此，提出了pairwise margin loss：</p><script type="math/tex; mode=display">L_m(x_i, x_j;f)=(1-y_{ij})[α-d_{ij}]_+ + y_{ij}[d_{ij}-(α-m)]_+</script><p>其中，当$y_i=y_j$时，$y_{ij}=1$，否则$y_{ij}=0$；$d_{ij}$表示$f(x_i), f(x_j)$之间的欧式距离，$[\cdot]_+$是hinge函数。</p><p>对样本进行合适采样可以加快模型的收敛速率和提高模型性能。Ranked List Loss使用的采样策略很简单，就是损失函数不为0的样本，具体来说，对于正样本，损失函数不为0意味着它们与anchor之间的距离大于$α-m$, 类似的，对于负样本，损失函数不为0意味着它们与anchor之间的距离小于$α$，相当于使得同一类别位于一个半径为$α-m$大小的超球体内。</p><p><img src="/deep-metric-learning/rll-loss.jpg" alt="losses"></p><p>给定一个anchor $x_i^c$, 基于相似度对其他样本进行排序，在这个排序结果中，有$N_{c}-1$ 个正样本，用$P_{c,i}=\{x_j^c|j \neq i\}$表示。同样地，有$\sum_{k \neq c}N_k$个负样本，用$N_{c,i}=\{x_j^k|k \neq c\}$表示。于每个anchor $x_i^c$, 我们希望使得它与正样本集$P_{c,i}$的距离越近越好，并且与负样本集$N_{c,i}$之间存在着$m$的间隔，同时，我们还希望使得anchor与负样本的距离大于边界$α$。在执行困难样本挖掘后，得到困难的正样本集合为 <script type="math/tex">P_{c,i}^{*}=\{x_j^c | j \neq i,d_{ij}>(\alpha-m)\}</script> ，困难的负样本集合为 <script type="math/tex">N_{c,i}^{*}=\{x_j^k | k \neq c, d_{ij}<\alpha\}</script> 。</p><p>因此，对于正样本我们使用的损失函数为：</p><script type="math/tex; mode=display">L_P(x_i^c;f)=\frac{1}{|P_{c,i}^*|}\sum_{x_j^c \in P_{c,j}^*}L_m(x_i^c,x_j^c;f)</script><p>对于负样本集，考虑到它的样本数量比较大，对每个负样本使用加权的方式：</p><script type="math/tex; mode=display">L_N(x_i^c;f)=\sum_{x_j^k \in N_{c,i}^*} \frac{w_{ij}}{ \sum_{x_j^k \in P_{c,j}^*} w_{ij}} L_m(x_i^c,x_j^k;f)</script><p>其中，$w_{ij}=exp(T \cdot (\alpha-d_{ij})$，$T$是超参数。</p><p>最终，整个损失为：</p><script type="math/tex; mode=display">L_{RLL}(x_i^c;f)=L_P(x_i^c;f)+\lambda L_N(x_i^c;f)</script><p>通常情况下，设置$\lambda=1$。</p><p>Ranked list loss的整体流程图如下：</p><p><img src="/deep-metric-learning/rll-flow.png" alt="losses"></p><p>上述几种loss函数的对比如下图所示：</p><p><img src="/deep-metric-learning/loss-list.jpg" alt="losses"></p><p>其中，蓝色圆形表示anchor(query)样本，不同的形状表示来自不同类的样本。</p><h3 id="7-Multi-Similarity-loss"><a href="#7-Multi-Similarity-loss" class="headerlink" title="7. Multi-Similarity loss"></a>7. Multi-Similarity loss</h3><p>前面说过，困难样本挖掘可以理解为在学习过程中给每一个样本对动态赋予一个权重。给样本赋权的核心在于判断样本的局部分布，即它们之间的相似性，局部样本之间的分布和相互关系并不仅仅取决于当前两个样本之间的距离或相似性，还取决于当前样本对与其周围样本对之间的关系。</p><p>因此，对于每一个样本对，我们不仅需要考虑样本对本身的自相似性，同时还要考虑它与其它样本对的相对相似性。其中相对相似性又可以分为正相对相似性 (正样本)、负相对相似性（负样本）两种相似性。</p><ol><li>自相似性：根据样本对自身计算出的相似性，这是一种最常用也是最重要的相似性。例如，当一个负样本对的余弦相似性较大时，意味着很难把该样本对所对应的两种类别区分开来，这样的样本对对模型来说是困难的，也是有信息量的，对于模型学习更有区分度的特征很有帮助。另一方面，自相似性很难完整地描述embedding空间的样本分布情况。</li><li>正相对相似性：不仅考虑当前样本对自身的相似性，还考虑局部邻域内正样本对之间的相对关系。</li><li>负相对相似性：不仅考虑当前样本对自身的相似性，还考虑局部邻域内负样本对之间的相对关系。</li></ol><p><img src="/deep-metric-learning/similarity.jpg" alt></p><p>各种损失函数都在给样本加权以确定「拉或推」的力度，那么使用什么样的函数来加权就非常重要了，在学习不同样本对时给它们不同的权重，如果某个样本包含的信息比较多或比较难学习，那么它就需要比较大的权重。不同的损失函数在设计时，对于样本对的赋权是不同的，往往会涉及到上述三种相似性的其中一种或多种的计算。以一个负样本对为例，上文提到的几个loss函数涉及到的相似性计算类型如下表所示。</p><div class="table-container"><table><thead><tr><th></th><th>contrastive</th><th>triplet</th><th>n-pair-ms</th><th>Lifted Struct loss</th><th>proxy NCA</th><th>Ranked List Loss</th><th>MS</th></tr></thead><tbody><tr><td>自相似性</td><td>✓</td><td>✗</td><td>✗</td><td>✗</td><td>✗</td><td>✗</td><td>✓</td></tr><tr><td>正相对相似性</td><td>✗</td><td>✓</td><td>✗</td><td>✗</td><td>✓</td><td>✗</td><td>✓</td></tr><tr><td>负相对相似性</td><td>✗</td><td>✗</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr></tbody></table></div><p>Multi-Similarity Loss（MS loss） 综合考虑了三种相似性，它们能概括目前大多数基于样本对的损失函数。MS Loss 通过采样和加权两次迭代，实现更加高效的样本训练。它通过定义自相似性和相对相似性，在训练过程中更加全面地考虑了局部样本分布，从而能更高效精确的对重要样本对进行采用和加权。</p><p>对于一个给定的负样本对$\{x_i,x_j\} \in N_i$，MS loss给它赋予的权重为：</p><script type="math/tex; mode=display">w_{ij}^-=\frac{1}{e^{\beta(\lambda-S_{ij})} +\sum_{k \in N_i}e^{\beta(S_{ik}-S_{ij})} }</script><p>类似地，对于一个给定的负样本对$\{x_i,x_j\} \in P_i$，MS loss给它赋予的权重为：</p><script type="math/tex; mode=display">w_{ij}^+=\frac{1}{e^{-\alpha(\lambda-S_{ij})} +\sum_{k \in P_i}e^{-\alpha(S_{ik}-S_{ij})} }</script><p>最终，MS loss的定义为：</p><script type="math/tex; mode=display">L_{MS}=\frac{1}{m} \sum_{i=1}^m \left\{\frac{1}{\alpha}log[1+\sum_{k \in P_i}e^{-\alpha(S_{ik}-\lambda)}] + \frac{1}{\beta}log[1+\sum_{k \in N_i}e^{\beta(S_{ik}-\lambda)}] \right\}</script><p>$L_{MS}$相对于$S_{ij}$求得的梯度刚好为上述样本权重。</p><p><img src="/deep-metric-learning/ms-loss.jpg" alt></p><p>MS Loss 在大部分图像检索基准数据库上都有很好的性能，且相比最新的方法也有较大的优势。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;度量学习（metric learning）研究如何在一个特定的任务上学习一个距离函数，使得该距离函数能够帮助基于近邻的算法（kNN、k-means等）取得较好的性能。深度度量学习（deep metric learning）是度量学习的一种方法，它的目标是学习一个从原始特征到低维稠密的向量空间（称之为嵌入空间，embedding space）的映射，使得同类对象在嵌入空间上使用常用的距离函数（欧氏距离、cosine距离等）计算的距离比较近，而不同类的对象之间的距离则比较远。深度度量学习在计算机视觉领域取得了非常多的成功的应用，比如人脸识别、人脸验证、图像检索、签名验证、行人重识别等。&lt;/p&gt;
&lt;p&gt;损失函数在深度度量学习中起到了非常重要的作用。很多深度度量学习的损失函数构建在样本对(pair)或者样本三元组(triplet)之上，因而样本空间的量级（$O(N^2)$或者$O(N^3)$）非常大。一般而言，模型在训练过程中很难穷举学习所有的样本对；并且大多数样本对或者样本三元组的信息量是很小的，尤其在模型训练的后期，这些样本对或者样本三元组上梯度值几乎为0。若不做任何针对性的优化，学习算法的收敛速度会很慢，且易陷入局部最优。&lt;/p&gt;
&lt;p&gt;困难样本挖掘是加快学习算法的收敛速度，并改进学习效果的一种重要手段。它通常和特定的损失函数一起使用，以期望达到最好的效果。困难样本挖掘可以理解为在学习过程中给每一个样本对动态赋予一个权重。在学习不同样本对时给它们不同的权重，如果某个样本对包含的信息比较多或比较难学习，那么它就需要比较大的权重。信息量较少的样本对则会被赋予较小的权重。若某些样本对被赋予的权重为0，则意味着在计算梯度时不考虑这些样本对，相当于这些样本对被丢弃了。&lt;/p&gt;
&lt;p&gt;不同的损失函数在设计时，对于样本对的赋权是不同的，或者说与这些损失函数配合使用的困难样本挖掘方法是不同的。下面列举一些常用的深度度量学习中使用的损失函数，同时了解一下它们是如何来给做困难样本挖掘的。&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="度量学习" scheme="http://xudongyang.coding.me/tags/%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="embedding" scheme="http://xudongyang.coding.me/tags/embedding/"/>
    
    <category term="相似度" scheme="http://xudongyang.coding.me/tags/%E7%9B%B8%E4%BC%BC%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>如何度量两个排序列表的相似性？</title>
    <link href="http://xudongyang.coding.me/rank-distance/"/>
    <id>http://xudongyang.coding.me/rank-distance/</id>
    <published>2019-04-22T02:35:38.000Z</published>
    <updated>2020-12-04T08:17:21.916Z</updated>
    
    <content type="html"><![CDATA[<p>在某些情况下，我们需要度量两个排序列表的距离，或者说相似程度。比如，在信息检索领域，我们可能需要计算在某个查询条件下系统给出的文档的排序列表与一个预先定义好的“完美”排序列表的接近程度。或者我们可能需要比较不同搜索引擎的结果。又或者，在推荐系统中，我们需要监控某次算法迭代（A/B测试）中，新算法针对某个用户给出的推荐列表与旧算法给出的推荐列表的差异程度，以便决定是否要触发自动报警。</p><p>在信息检索领域，我们常用MAP、MRR、NDCG来评估排序算法的好坏，然而这些指标依赖人工标注的query与document的相关性档位（relevance level）。当没有此标注数据，或者我们要评估的排序列表跟相关性无关，并且我们刚好有一个待比较的基准列表时，该如何评估它们之间的距离呢？how to measure the similarity between two rank list?</p><p>定义这样一个排序列表之间比较的指标，我们期待它能满足以下几个方面：</p><ul><li>丰富度（Richness）<ul><li>能够支持元素加权、位置加权等</li><li>Support element weights, position weights, etc.</li></ul></li><li>简洁性（Simplicity）<ul><li>易于理解</li><li>Be simple to understand</li></ul></li><li>普适性（Generalization）<ul><li>也能支持不考虑权重的情况 </li><li>Collapse to a natural metric with no weights are present</li><li>Should behave similar to other approaches</li><li>Allows us to select a metric best suited to the problem</li></ul></li><li>满足距离定义的基本属性（Satisfy Basic Properties）<ul><li>Scale free, invariant under relabeling, triangle inequality…</li></ul></li></ul><p>排序列表距离度量大致可以分为两大类方法: (1) 基于排序之间的相互关系（Ranked Correlation）；(2) 基于集合的度量（Set Based Measure）。</p><a id="more"></a><h2 id="一、Rank-Correlation"><a href="#一、Rank-Correlation" class="headerlink" title="一、Rank Correlation"></a>一、Rank Correlation</h2><p>基于Rank correlation的距离度量方法本质上是量化任意两个不同元素在两个待比较的排序列表中的相对位置，例如，两者保持相同顺序的概率等。</p><h3 id="1-肯德尔等级相关系数（Kendall-Tau）"><a href="#1-肯德尔等级相关系数（Kendall-Tau）" class="headerlink" title="1. 肯德尔等级相关系数（Kendall Tau）"></a>1. 肯德尔等级相关系数（Kendall Tau）</h3><p>我们可以用逆序对数量来量化两个排序列表的不一致程度。</p><blockquote><p>设 A 为一个有 n 个数字的有序集 (n&gt;1)，其中所有数字各不相同。如果存在正整数 i, j 使得 1 ≤ i &lt; j ≤ n 而且 A[i] &gt; A[j]，则 <A[i], a[j]> 这个有序对称为 A 的一个逆序对，也称作逆序数。</A[i],></p></blockquote><p>逆序数有时候也叫做肯德尔等级相关系数。直接用逆序数来度量量列表之间的距离有个问题，就是不同长度的列表scale不一致。然而，多数情况下，我们希望用一个统一的量纲来度量列表距离。</p><p><img src="/rank-distance/tau.jpg" alt></p><p>现在我们常把肯德尔等级相关系数定义为统一量纲的版本，即两个列表正序对的概率减去逆序对的概率，比如，计算元素A在列表1中排在元素B前面，那么在列表2中元素A依然排在元素B前面的概率，具体值可以通过下面的公式计算：</p><script type="math/tex; mode=display">\tau = P(C)-P(D)=\frac{C}{N}-\frac{D}{N}=\frac{C-D}{N}</script><p>其中，$N$是总的元素对数量，当列表有$n$个元素时，$N=\frac{1}{2}n(n-1)$；$C$是在两个列表中相对顺序保持一致的元素对数量；$D$是在两个列表中相对顺序不一致的元素对数量。</p><p>有时候列表中元素的重要性是不同的，交换两个重要的元素之间的相对位置比交换两个不那么重要的元素之间的相对位置影响要大很多。那么，如何在度量列表排序相似度的时候，考虑元素的权重呢？</p><p>一种方法是把权重为$w$的元素理解为有$w$个权重为1的元素连在一起构成一个整体，如下图：</p><p><img src="/rank-distance/tau_weight.jpg" alt></p><h3 id="2-Spearman’s-Footrule"><a href="#2-Spearman’s-Footrule" class="headerlink" title="2. Spearman’s Footrule"></a>2. Spearman’s Footrule</h3><p>Spearman’s Footrule是两个排序列表之间的绝对距离，类似于文本编辑距离，度量把一个列表修改为另一个列表最少需要移动各个元素的距离的总和。</p><p>例如，假设<code>A=[1,2,3];B=[2,1,3]</code>,则A和B的Footrule距离为$d_{AB}=|1-2|+|2-1|+|3-3|=2$。</p><p>Footrule距离可以理解为在$n$为空间上把其中一个点沿着坐标轴的方向移动到另外一个点最少需要移动的距离之和。</p><p><img src="/rank-distance/footrule.jpg" alt></p><p>Spearman’s Footrule距离度量也可以考虑元素权重，可以参考与Kendall Tau一致的方法。</p><p><img src="/rank-distance/footrule_weight.jpg" alt></p><h2 id="二、Set-Based-Measure"><a href="#二、Set-Based-Measure" class="headerlink" title="二、Set Based Measure"></a>二、Set Based Measure</h2><p>基于集合的方法通过在计算两个不同排序列表在不同深度时对应集合的交集大小来计算排序列表的相似度。假设我们有两个列表：</p><blockquote><p>A: [a, b, c, d, e]<br>B: [b, a, c, d, e]</p></blockquote><p>依次计算它们前k个元素组成的两个集合的交集，以及交集大小相对于当前深度的比例。</p><div class="table-container"><table><thead><tr><th>深度</th><th>列表A的前k个元素</th><th>列表B的前k个元素</th><th>交集</th><th>比例</th></tr></thead><tbody><tr><td>1</td><td>a</td><td>b</td><td>{}</td><td>0/1=0</td></tr><tr><td>2</td><td>a,b</td><td>b,a</td><td>{a,b}</td><td>2/2 = 1</td></tr><tr><td>3</td><td>a,b,c</td><td>b,a,c</td><td>{a,b,c}</td><td>3/3 = 1</td></tr><tr><td>4</td><td>a,b,c,d</td><td>b,a,c,d</td><td>{a,b,c,d}</td><td>4/4 = 1</td></tr><tr><td>5</td><td>a,b,c,d,e</td><td>b,a,c,d,e</td><td>{a,b,c,d,e}</td><td>5/5 = 1</td></tr></tbody></table></div><p>一旦计算出不同深度的交集比例后，我们就可以通过交集比例的分布来量化两个列表的相似程度，最简单的方式就是直接计算交集比例的平均值。在上面的例子中，当列表长度为5时，列表A和B的相似度为 4/5=0.8。</p><p>一般情况下，排序越靠前的位置的元素的权重越高。比如搜索引擎的结果，我们一般只关注排在最前面的文档的相对顺序，而排在后面的文档一般不太关注。在中国互联网公司实力排行榜上我们通常也只会关注那些Top的公司的相对顺序，而不太关心几百名之后的公司如何排名。因此，我们希望在比较两个排序列表的相似性时，能够考虑不同位置的元素的权重，尤其是关注top元素的相对位置权重。</p><p>假设我们另外有一列表<code>C: [a, b, c, e, d]</code>，与列表A比较后发现，列表C是通过交换列表A的最好两个元素的位置得到的；而列表B是通过交换列表A的前2个元素的位置得到的。基于Set Based Measure，我们发现列表C与列表A的相似度为(1+1+1+0.75+1)/5=0.95，大于列表B与列表A的相似度（0.8），这正是我们所期望的。</p><p>综上，Set Based Measure天然带有top-weighteness属性。</p><ul><li>RBO(Rank Biased Overlap)</li></ul><p>Rank Biased Overlap 距离度量方法进一步拓展了上述Set Based的方法。上述Naive的Set Based Measure方法计算出的距离是没有上界的，随着列表长度的不断增加，有可能距离值会无穷大。为了解决这个问题，RBO给每个深度的交集比例定义了一个权重系数，最后计算结果时是加权和，而不是原来的平均值。</p><p>当然，不是任意的权重值分布都能保证距离收敛。RBO选择了几何序列来保证这一点，具体地，RBO在无限长度的列表上计算两个排序列表的步骤如下：</p><p>假设$S$和$T$为两个无限长度的排序列表，$S_i$为列表$S$的第$i$个元素，$S_{c:d}=\{ S_i : c \leq i \leq d \}$表示列表中从位置$c$到位置$d$的所有元素组成的集合。在深度为$d$时，列表S和T的交集为：</p><script type="math/tex; mode=display">I_d=S_{1:d} \cap T_{1:d}</script><p>交集的元素个数称之为列表S和T在深度为d时的交叠（overlap），该overlap相对于深度$d$的比值称之为列表S和T的一致度（agreement）。</p><script type="math/tex; mode=display">A_d=\frac{|I_d|}{d}=\frac{|S_{1:d} \cap T_{1:d}|}{d}</script><p>之前介绍的Naive Set Based Measure实际上是在计算平均交叠，即$AO(S,T,k)=\frac{1}{k} \sum_{d=1}^{k} A_d$，其中$k$是需要计算的深度。</p><p>RBO不再简单地计算平均交叠，而是给每个深度的一致度一个权重$w_d$，再计算加权和:</p><script type="math/tex; mode=display">SIM(S,T,w)=\sum_{d=1}^{\infty} w_d \cdot A_d</script><p>定义权重$w_d=(1-p)\cdot p^{d-1}$，则$\sum_d w_d = 1$，因为当$0&lt;p&lt;1$时，几何级数$p^{d-1}$收敛到$\frac{1}{1-p}$，即<script type="math/tex">\sum_{d=1}^{\infty} p^{d-1} = \frac{1}{1-p}</script></p><p>根据定义，$A_d$是小于1的，则有$0 \leq SIM \leq \sum_d w_d &lt; 1$。</p><p>至此，RBO距离度量方法可以定义为：</p><script type="math/tex; mode=display">RBO(S,T,p)=(1-p)\sum_{d=1}^{\infty}p^{d-1} \cdot A_d</script><p>其中$p$是一个可以预先定下来的参数。可以看到RBO指标是有界的，值在0~1的范围之间，并且RBO指标还带有top-weighteness属性。</p><p>RBO指标有很好的性质，非常适合用来度量两个排序列表的相似度，强烈推荐！</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://ragrawal.wordpress.com/2013/01/18/comparing-ranked-list/">Comparing Ranked List</a></li><li><a href="http://codalism.com/research/papers/wmz10_tois.pdf">A Similarity Measure for Indefinite Rankings</a></li><li><a href="http://ciir-publications.cs.umass.edu/pdf/IR-649.pdf">Rank Correlation and Distance Between Rankings</a></li><li><a href="https://weirping.github.io/blog/Metrics-in-IR.html">信息检索评价指标(nDCG,MRR,MAP)</a></li><li><a href="http://theory.stanford.edu/~sergei/slides/www10-metrics.pdf">Generalized Distances Between Rankings - Stanford CS Theory</a></li><li><a href="https://arxiv.org/abs/1207.2541">A New Weighted Spearman’s Footrule as A Measure of The Distance Between Two Rankings</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;在某些情况下，我们需要度量两个排序列表的距离，或者说相似程度。比如，在信息检索领域，我们可能需要计算在某个查询条件下系统给出的文档的排序列表与一个预先定义好的“完美”排序列表的接近程度。或者我们可能需要比较不同搜索引擎的结果。又或者，在推荐系统中，我们需要监控某次算法迭代（A/B测试）中，新算法针对某个用户给出的推荐列表与旧算法给出的推荐列表的差异程度，以便决定是否要触发自动报警。&lt;/p&gt;
&lt;p&gt;在信息检索领域，我们常用MAP、MRR、NDCG来评估排序算法的好坏，然而这些指标依赖人工标注的query与document的相关性档位（relevance level）。当没有此标注数据，或者我们要评估的排序列表跟相关性无关，并且我们刚好有一个待比较的基准列表时，该如何评估它们之间的距离呢？how to measure the similarity between two rank list?&lt;/p&gt;
&lt;p&gt;定义这样一个排序列表之间比较的指标，我们期待它能满足以下几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;丰富度（Richness）&lt;ul&gt;
&lt;li&gt;能够支持元素加权、位置加权等&lt;/li&gt;
&lt;li&gt;Support element weights, position weights, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;简洁性（Simplicity）&lt;ul&gt;
&lt;li&gt;易于理解&lt;/li&gt;
&lt;li&gt;Be simple to understand&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;普适性（Generalization）&lt;ul&gt;
&lt;li&gt;也能支持不考虑权重的情况 &lt;/li&gt;
&lt;li&gt;Collapse to a natural metric with no weights are present&lt;/li&gt;
&lt;li&gt;Should behave similar to other approaches&lt;/li&gt;
&lt;li&gt;Allows us to select a metric best suited to the problem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;满足距离定义的基本属性（Satisfy Basic Properties）&lt;ul&gt;
&lt;li&gt;Scale free, invariant under relabeling, triangle inequality…&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;排序列表距离度量大致可以分为两大类方法: (1) 基于排序之间的相互关系（Ranked Correlation）；(2) 基于集合的度量（Set Based Measure）。&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="等级相关" scheme="http://xudongyang.coding.me/tags/%E7%AD%89%E7%BA%A7%E7%9B%B8%E5%85%B3/"/>
    
    <category term="距离度量" scheme="http://xudongyang.coding.me/tags/%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F/"/>
    
    <category term="排序" scheme="http://xudongyang.coding.me/tags/%E6%8E%92%E5%BA%8F/"/>
    
    <category term="相似性" scheme="http://xudongyang.coding.me/tags/%E7%9B%B8%E4%BC%BC%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>一文说清楚Tensorflow分布式训练必备知识</title>
    <link href="http://xudongyang.coding.me/distributed-tensorflow/"/>
    <id>http://xudongyang.coding.me/distributed-tensorflow/</id>
    <published>2019-03-22T03:18:29.000Z</published>
    <updated>2020-12-04T08:17:21.869Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Methods that scale with computation are the future of AI.<br>—Rich Sutton, 强化学习之父</p></blockquote><p>大数据时代的互联网应用产生了大量的数据，这些数据就好比是石油，里面蕴含了大量知识等待被挖掘。深度学习就是挖掘数据中隐藏知识的利器，在许多领域都取得了非常成功的应用。然而，大量的数据使得模型的训练变得复杂，使用多台设备分布式训练成了必备的选择。</p><p>Tensorflow是目前比较流行的深度学习框架，本文着重介绍tensorflow框架是如何支持分布式训练的。<br><a id="more"></a> </p><h2 id="分布式训练策略"><a href="#分布式训练策略" class="headerlink" title="分布式训练策略"></a>分布式训练策略</h2><h3 id="模型并行"><a href="#模型并行" class="headerlink" title="模型并行"></a>模型并行</h3><p>所谓模型并行指的是将模型部署到很多设备上（设备可能分布在不同机器上，下同）运行，比如多个机器的GPUs。当神经网络模型很大时，由于显存限制，它是难以完整地跑在单个GPU上，这个时候就需要把模型分割成更小的部分，不同部分跑在不同的设备上，例如将网络不同的层运行在不同的设备上。</p><p>由于模型分割开的各个部分之间有相互依赖关系，因此计算效率不高。所以在模型大小不算太大的情况下一般不使用模型并行。</p><p>在tensorflow的术语中，模型并行称之为”in-graph replication”。</p><h3 id="数据并行"><a href="#数据并行" class="headerlink" title="数据并行"></a>数据并行</h3><p>数据并行在多个设备上放置相同的模型，各个设备采用不同的训练样本对模型训练。每个Worker拥有模型的完整副本并且进行各自单独的训练。</p><p><img src="https://d3ansictanv2wj.cloudfront.net/figure1-1cd2c0441cf54f2237e3d8720180cb45.png" alt></p><p>相比较模型并行，数据并行方式能够支持更大的训练规模，提供更好的扩展性，因此数据并行是深度学习最常采用的分布式训练策略。</p><p>在tensorflow的术语中，数据并行称之为”between-graph replication”。</p><h2 id="分布式并行模式"><a href="#分布式并行模式" class="headerlink" title="分布式并行模式"></a>分布式并行模式</h2><p>深度学习模型的训练是一个迭代的过程。在每一轮迭代中，前向传播算法会根据当前参数的取值计算出在一小部分训练数据上的预测值，然后反向传播算法再根据损失函数计算参数的梯度并更新参数。在并行化地训练深度学习模型时，不同设备（GPU或CPU）可以在不同训练数据上运行这个迭代的过程，而不同并行模式的区别在于不同的参数更新方式。</p><p>深度学习模型训练流程图<br> <img src="https://user-gold-cdn.xitu.io/2017/4/10/7eda6fce5eec9cbce366426fcecbe56f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="深度学习模型训练流程图"></p><p>数据并行可以是同步的（synchronous），也可以是异步的（asynchronous）。</p><h3 id="异步训练"><a href="#异步训练" class="headerlink" title="异步训练"></a>异步训练</h3><p>异步训练中，各个设备完成一个mini-batch训练之后，不需要等待其它节点，直接去更新模型的参数。从下图中可以看到，在每一轮迭代时，不同设备会读取参数最新的取值，但因为不同设备读取参数取值的时间不一样，所以得到的值也有可能不一样。根据当前参数的取值和随机获取的一小部分训练数据，不同设备各自运行反向传播的过程并独立地更新参数。可以简单地认为异步模式就是单机模式复制了多份，每一份使用不同的训练数据进行训练。</p><p><img src="https://user-gold-cdn.xitu.io/2017/4/10/0b3dc701f60001d2454b268469245cb8?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="异步模式深度学习模型训练流程图"></p><p>异步训练总体会训练速度会快很多，但是异步训练的一个很严重的问题是梯度失效问题（stale gradients），刚开始所有设备采用相同的参数来训练，但是异步情况下，某个设备完成一步训练后，可能发现模型参数已经被其它设备更新过了，此时这个设备计算出的梯度就过期了。由于梯度失效问题，异步训练可能陷入次优解（sub-optimal training performance）。图10-3中给出了一个具体的样例来说明异步模式的问题。其中黑色曲线展示了模型的损失函数，黑色小球表示了在t0时刻参数所对应的损失函数的大小。假设两个设备d0和d1在时间t0同时读取了参数的取值，那么设备d0和d1计算出来的梯度都会将小黑球向左移动。假设在时间t1设备d0已经完成了反向传播的计算并更新了参数，修改后的参数处于图10-3中小灰球的位置。然而这时的设备d1并不知道参数已经被更新了，所以在时间t2时，设备d1会继续将小球向左移动，使得小球的位置达到图10-3中小白球的地方。从图10-3中可以看到，当参数被调整到小白球的位置时，将无法达到最优点。</p><p><img src="https://user-gold-cdn.xitu.io/2017/4/10/90617a718625f2f6005e6627dc2c1837?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt></p><p>在tensorflow中异步训练是默认的并行训练模式。</p><h3 id="同步训练"><a href="#同步训练" class="headerlink" title="同步训练"></a>同步训练</h3><p>所谓同步指的是所有的设备都是采用相同的模型参数来训练，等待所有设备的mini-batch训练完成后，收集它们的梯度后执行模型的一次参数更新。在同步模式下，所有的设备同时读取参数的取值，并且当反向传播算法完成之后同步更新参数的取值。单个设备不会单独对参数进行更新，而会等待所有设备都完成反向传播之后再统一更新参数 。</p><p><img src="https://user-gold-cdn.xitu.io/2017/4/10/0d89e28d77235fa27c522b9d03c940ba?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="同步模式深度学习模型训练流程图"></p><p>同步模式相当于通过聚合多个设备上的mini-batch形成一个更大的batch来训练模型，<strong>相对于异步模式，在同步模型下根据并行的worker数量线性增加学习速率会取得不错的效果</strong>。如果使用tensorflow estimator接口来分布式训练模型的话，在同步模式下需要适当减少训练步数（相对于采用异步模式来说），否则需要花费较长的训练时间。Tensorflow estimator接口唯一支持的停止训练的条件就全局训练步数达到指定的max_steps。</p><p>Tensorflow提供了<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/train/SyncReplicasOptimizer">tf.train.SyncReplicasOptimizer</a>类用于执行同步训练。通过使用SyncReplicasOptimzer，你可以很方便的构造一个同步训练的分布式任务。把异步训练改造成同步训练只需要两步：</p><ol><li>在原来的Optimizer上封装SyncReplicasOptimizer，将参数更新改为同步模式；<br><code>optimizer = tf.train.SyncReplicasOptimizer(optimizer, replicas_to_aggregate=num_workers)</code></li><li>在MonitoredTrainingSession或者EstimatorSpec的hook中增加sync_replicas_hook：<br><code>sync_replicas_hook = optimizer.make_session_run_hook(is_chief, num_tokens=0)</code></li></ol><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>下图可以一目了然地看出同步训练与异步训练之间的区别。<br><img src="https://d3ansictanv2wj.cloudfront.net/figure2-f3599b8db486355f7427b3bb860692c3.png" alt></p><p>同步训练看起来很不错，但是实际上需要各个设备的计算能力要均衡，而且要求集群的通信也要均衡，类似于木桶效应，一个拖油瓶会严重拖慢训练进度，所以同步训练方式相对来说训练速度会慢一些。</p><p>虽然异步模式理论上存在缺陷，但因为训练深度学习模型时使用的随机梯度下降本身就是梯度下降的一个近似解法，而且即使是梯度下降也无法保证达到全局最优值。在实际应用中，在相同时间内使用异步模式训练的模型不一定比同步模式差。所以这两种训练模式在实践中都有非常广泛的应用。</p><h2 id="分布式训练架构"><a href="#分布式训练架构" class="headerlink" title="分布式训练架构"></a>分布式训练架构</h2><h3 id="Parameter-Server架构"><a href="#Parameter-Server架构" class="headerlink" title="Parameter Server架构"></a>Parameter Server架构</h3><p>Parameter server架构（PS架构）是深度学习最常采用的分布式训练架构。在PS架构中，集群中的节点被分为两类：parameter server和worker。其中parameter server存放模型的参数，而worker负责计算参数的梯度。在每个迭代过程，worker从parameter sever中获得参数，然后将计算的梯度返回给parameter server，parameter server聚合从worker传回的梯度，然后更新参数，并将新的参数广播给worker。</p><p><img src="https://gw.alipayobjects.com/zos/skylark/a242d040-441b-4bb2-af22-2d40f95102cf/2018/png/c3d9d865-211f-4880-98c2-a7505ccb6a1d.png" alt></p><h3 id="Ring-AllReduce架构"><a href="#Ring-AllReduce架构" class="headerlink" title="Ring AllReduce架构"></a>Ring AllReduce架构</h3><p>PS架构中，当worker数量较多时，ps节点的网络带宽将成为系统的瓶颈。</p><p>Ring AllReduce架构中各个设备都是worker，没有中心节点来聚合所有worker计算的梯度。Ring AllReduce算法将 device 放置在一个逻辑环路（logical ring）中。每个 device 从上行的device 接收数据，并向下行的 deivce 发送数据，因此可以充分利用每个 device 的上下行带宽。</p><p><img src="https://d3ansictanv2wj.cloudfront.net/figure4-7564694e76d08e091ce453f681515e59.png" alt="Ring-allreduce architecture for synchronous stochastic gradient descent"></p><p>使用 Ring Allreduce 算法进行某个稠密梯度的平均值的基本过程如下：</p><ol><li>将每个设备上的梯度 tensor 切分成长度大致相等的 num_devices 个分片；</li><li>ScatterReduce 阶段：通过 num_devices - 1 轮通信和相加，在每个 device 上都计算出一个 tensor 分片的和；</li><li>AllGather 阶段：通过 num_devices - 1 轮通信和覆盖，将上个阶段计算出的每个 tensor 分片的和广播到其他 device；</li><li>在每个设备上合并分片，得到梯度和，然后除以 num_devices，得到平均梯度；</li></ol><p>以 4 个 device上的梯度求和过程为例：</p><p>ScatterReduce 阶段：<br><img src="https://private-alipayobjects.alipay.com/alipay-rmsdeploy-image/skylark/png/1869bb5b-29ce-4ca8-9461-e23ad3a7bb45.png" alt><br>经过 num_devices - 1 轮后，每个 device 上都有一个 tensor 分片进得到了这个分片各个 device 上的和；</p><p>AllGather 阶段：<br><img src="https://private-alipayobjects.alipay.com/alipay-rmsdeploy-image/skylark/png/5f715f8d-9eed-481f-a969-13c78d50529c.png" alt></p><p>经过 num_devices - 1 轮后，每个 device 上都每个 tensor 分片都得到了这个分片各个 device 上的和；</p><p>由上例可以看出，通信数据量的上限不会随分布式规模变大而变大一次 Ring Allreduce 中总的通信数据量是：</p><script type="math/tex; mode=display">2 \cdot \frac{num\_devices - 1}{num\_devices} \cdot {tensor\_size} \approx 2 \cdot tensor\_size</script><p>相比PS架构，Ring Allreduce架构是带宽优化的，因为集群中每个节点的带宽都被充分利用。此外，在深度学习训练过程中，计算梯度采用BP算法，其特点是后面层的梯度先被计算，而前面层的梯度慢于前面层，Ring-allreduce架构可以充分利用这个特点，在前面层梯度计算的同时进行后面层梯度的传递，从而进一步减少训练时间。Ring Allreduce的训练速度基本上线性正比于GPUs数目（worker数）。</p><p>2017年2月百度在PaddlePaddle平台上首次引入了<a href="https://github.com/baidu-research/baidu-allreduce">ring-allreduce</a>的架构，随后将其提交到tensorflow的contrib package中。同年8月，Uber为tensorflow平台开源了一个更加易用和高效的ring allreduce分布式训练库<a href="https://github.com/uber/horovod">Horovod</a>。最后，tensorflow官方终于也在1.11版本中支持了allreduce的分布式训练策略<a href="https://github.com/logicalclocks/hops-examples/tree/master/tensorflow/notebooks/Distributed_Training/collective_allreduce_strategy">CollectiveAllReduceStrategy</a>，其跟estimator配合使用非常方便，只需要构造<code>tf.estimator.RunConfig</code>对象时传入CollectiveAllReduceStrategy参数即可。</p><p><img src="https://hopshadoop47880376.files.wordpress.com/2018/10/null9.png" alt></p><h2 id="分布式tensorflow"><a href="#分布式tensorflow" class="headerlink" title="分布式tensorflow"></a>分布式tensorflow</h2><p>推荐使用 TensorFlow Estimator API 来编写分布式训练代码，理由如下：</p><ul><li>开发方便，比起low level的api开发起来更加容易</li><li>可以方便地和其他的高阶API结合使用，比如Dataset、FeatureColumns、Head等</li><li>模型函数model_fn的开发可以使用任意的low level函数，依然很灵活</li><li>单机和分布式代码一致，且不需要考虑底层的硬件设施</li><li>可以比较方便地和一些分布式调度框架（e.g. xlearning）结合使用</li></ul><p>要让tensorflow分布式运行，首先我们需要定义一个由参与分布式计算的机器组成的集群，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cluster &#x3D; &#123;&#39;chief&#39;: [&#39;host0:2222&#39;],</span><br><span class="line">            &#39;ps&#39;: [&#39;host1:2222&#39;, &#39;host2:2222&#39;],</span><br><span class="line">            &#39;worker&#39;: [&#39;host3:2222&#39;, &#39;host4:2222&#39;, &#39;host5:2222&#39;]&#125;</span><br></pre></td></tr></table></figure><br>集群中一般有多个worker，需要指定其中一个worker为主节点（cheif），chief节点会执行一些额外的工作，比如模型导出之类的。在PS分布式架构环境中，还需要定义ps节点。</p><p>要运行分布式Estimator模型，只需要设置好<code>TF_CONFIG</code>环境变量即可，可参考如下代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Example of non-chief node:</span><br><span class="line">os.environ[&#39;TF_CONFIG&#39;] &#x3D; json.dumps(</span><br><span class="line">    &#123;&#39;cluster&#39;: cluster,</span><br><span class="line">     &#39;task&#39;: &#123;&#39;type&#39;: &#39;worker&#39;, &#39;index&#39;: 1&#125;&#125;)</span><br><span class="line"></span><br><span class="line"># Example of chief node:     </span><br><span class="line">os.environ[&#39;TF_CONFIG&#39;] &#x3D; json.dumps(</span><br><span class="line">    &#123;&#39;cluster&#39;: cluster,</span><br><span class="line">     &#39;task&#39;: &#123;&#39;type&#39;: &#39;chief&#39;, &#39;index&#39;: 0&#125;&#125;)</span><br><span class="line"></span><br><span class="line"># Example of evaluator node (evaluator is not part of training cluster)     </span><br><span class="line">os.environ[&#39;TF_CONFIG&#39;] &#x3D; json.dumps(</span><br><span class="line">    &#123;&#39;cluster&#39;: cluster,</span><br><span class="line">     &#39;task&#39;: &#123;&#39;type&#39;: &#39;evaluator&#39;, &#39;index&#39;: 0&#125;&#125;)</span><br></pre></td></tr></table></figure><br>定义好上述环境变量后，调用<code>tf.estimator.train_and_evaluate</code>即可开始分布式训练和评估，其他部分的代码跟开发单机的程序是一样的，可以参考下面的资料：</p><ol><li><a href="https://zhuanlan.zhihu.com/p/38470806">基于Tensorflow高阶API构建大规模分布式深度学习模型系列: 开篇</a></li><li><a href="https://zhuanlan.zhihu.com/p/38421397">基于Tensorflow高阶API构建大规模分布式深度学习模型系列: 基于Dataset API处理Input pipeline</a></li><li><a href="https://zhuanlan.zhihu.com/p/41473323">基于Tensorflow高阶API构建大规模分布式深度学习模型系列: 自定义Estimator（以文本分类CNN模型为例）</a></li><li><a href="https://zhuanlan.zhihu.com/p/41663141">基于Tensorflow高阶API构建大规模分布式深度学习模型系列: 特征工程 Feature Column</a></li><li><a href="https://zhuanlan.zhihu.com/p/42214716">基于Tensorflow高阶API构建大规模分布式深度学习模型系列: CVR预估案例之ESMM模型</a></li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://www.oreilly.com/ideas/distributed-tensorflow">Distributed TensorFlow</a></li><li><a href="https://www.logicalclocks.com/goodbye-horovod-hello-tensorflow-collectiveallreduce/">Goodbye Horovod, Hello CollectiveAllReduce</a></li><li><a href="https://cloud.google.com/solutions/partners/quantiphi-distributed-training-using-tensorflow">Overview: Distributed training using TensorFlow Estimator APIs</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Methods that scale with computation are the future of AI.&lt;br&gt;—Rich Sutton, 强化学习之父&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大数据时代的互联网应用产生了大量的数据，这些数据就好比是石油，里面蕴含了大量知识等待被挖掘。深度学习就是挖掘数据中隐藏知识的利器，在许多领域都取得了非常成功的应用。然而，大量的数据使得模型的训练变得复杂，使用多台设备分布式训练成了必备的选择。&lt;/p&gt;
&lt;p&gt;Tensorflow是目前比较流行的深度学习框架，本文着重介绍tensorflow框架是如何支持分布式训练的。&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="tensorflow" scheme="http://xudongyang.coding.me/tags/tensorflow/"/>
    
    <category term="deep learning" scheme="http://xudongyang.coding.me/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>深度CTR预估模型中的特征自动组合机制演化简史</title>
    <link href="http://xudongyang.coding.me/xdeepfm/"/>
    <id>http://xudongyang.coding.me/xdeepfm/</id>
    <published>2018-12-20T08:46:41.000Z</published>
    <updated>2020-12-04T14:54:00.564Z</updated>
    
    <content type="html"><![CDATA[<p>众所周知，深度学习在计算机视觉、语音识别、自然语言处理等领域最先取得突破并成为主流方法。但是，深度学习为什么是在这些领域而不是其他领域最先成功呢？我想一个原因就是图像、语音、文本数据在空间和时间上具有一定的内在关联性。比如，图像中会有大量的像素与周围的像素比较类似；文本数据中语言会受到语法规则的限制。CNN对于空间特征有很好的学习能力，正如RNN对于时序特征有强大的表示能力一样，因此CNN和RNN在上述领域各领风骚好多年。</p><p>在Web-scale的搜索、推荐和广告系统中，特征数据具有高维、稀疏、多类别的特点，一般情况下缺少类图像、语音、文本领域的时空关联性。因此，如何构建合适的网络结构以便在信息检索、推荐系统和计算广告领域取得良好的特征表示能力，进一步提升最终的业务效果成了学术界和工业界共同关注的问题。</p><p>本文在跟踪了最近主流的互联网业务中大量使用的排序模型的基础上，总结出了深度CTR、CVR预估模型发展演化的三条主线，跟大家分享。</p><ol><li>第一条主脉络是以FM家族为代表的深度模型，它们的共同特点是自动学习从原始特征交叉组合新的高阶特征。</li><li>第二条主脉络是一类使用attention机制处理时序特征的深度模型，以DIN、DIEN等模型为代表。</li><li>第三条主脉络是以迁移学习、多任务学习为基础的联合训练模型或pre-train机制，以<a href="https://zhuanlan.zhihu.com/p/37562283">ESMM</a>、DUPN等模型为代表。</li></ol><p>其中前两条主脉络虽然出发点不同，但个人认为也有一些共通之处，比如attention机制是不是可以在某种程度上理解为一种特殊形式的组合特征。第三条主脉络属于流程或框架层面的创建。本文的主要目标是理清楚第一条主线中各个经典的深度模型的发展演化脉络，包括它们的优缺点和共通之处。<br><a id="more"></a></p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>构建好的特征对于机器学习任务来说至关重要，它关系到模型的学习难易程度及泛化性能。好的特征是相互独立的有区分性且易于理解的特征，具体地可以参考《<a href="https://yangxudong.github.io/good-feature/">何为优秀的机器学习特征</a>》。</p><p>交叉组合原始特征构成新的特征是一种常用且有效的特征构建方法。哪些特征需要被交叉组合以便生成新的有效特征？需要多少阶的交叉组合？这些问题在深度学习流行之前需要算法工程师依靠经验来解决。人工构建组合特征特别耗时耗力，在样本数据生成的速度和数量巨大的互联网时代，依靠人的经验和技能识别出所有潜在有效的特征组合模式几乎是不可能的。一些有效的组合特征甚至没有在样本数据中出现过。</p><p>那么，能否自动构建有效的交叉组合特征？答案是肯定的。在深度学习之前，一些有益的尝试是把特征组合的任务交给子模型来学习，最经典的方法就是Facebook在2014年的论文中介绍的通过GBDT（Gradient Boost Decision Tree）模型解决LR模型的特征组合问题。该方法思路很简单，特征工程分为两部分，一部分特征用于训练一个GBDT模型，把GBDT模型每颗树的叶子节点编号作为新的特征，加入到原始特征集中，再训练最终的LR模型。详细介绍可以查看我之前的一篇博文：《<a href="https://zhuanlan.zhihu.com/p/35465875">主流CTR预估模型的演化及对比</a>》。此类解决方案在特征工程阶段就引入了机器学习模型，虽然可以部分解决问题，但还是过于麻烦，不够灵活。</p><p>要避免上述麻烦，自然而然就是要引入端到端学习的思路，即用一个统一的模型同时完成特征组合和目标拟合的任务。因子分解机(Factorization Machines, FM)模型是第一个从原始特征出发，端到端学习的例子。然而，FM毕竟还是一个浅层模型，经典的FM模型只能做二阶的特征交叉，模型学习复杂组合特征的能力偏弱。尽管如此，FM提出了一种很好的自动学习交叉组合特征的思路，随后融入FM模型思路的深度学习模型便如雨后春笋般应运而生，典型的代表有FNN、PNN、DeepFM、DCN、xDeepFM等。关于这些模型的介绍和对比，在我之前的两篇博文中也有详细介绍，感兴趣的读者可以查阅《<a href="https://zhuanlan.zhihu.com/p/35465875">主流CTR预估模型的演化及对比</a>》、《<a href="https://zhuanlan.zhihu.com/p/43364598">玩转企业级Deep&amp;Cross Network模型你只差一步</a>》。</p><p>本文的其余内容将会对这些模型做一个详细的复盘，同时对该主线的集大成者xDeepFM模型做一个详细的介绍，其中包括一些自己对模型的理解，实际的使用心得，以及某些模型实现时的一些trick。文章的最后还会提供某些模型的源代码链接。</p><h2 id="特征组合的演化路线"><a href="#特征组合的演化路线" class="headerlink" title="特征组合的演化路线"></a>特征组合的演化路线</h2><p>从<strong>FM</strong>模型说起，FM通过特征对之间的隐变量内积来提取特征组合，其函数形式如下：</p><script type="math/tex; mode=display">y=w_0 + \sum_{i=1}^{n}w_i x_i + \sum_{i=1}^{n}\sum_{j=i+1}^n \langle v_i,v_j \rangle x_i x_j</script><p>对于每个原始特征，FM都会学习一个隐向量。模型通过穷举所有的特征对（pair）并逐一检测特征对的效用值的方法来自动识别出有效的特征组合。特征对的效用值通过该特征对涉及的两个原始特征的隐向量的内积来计算。</p><p>可以看出FM最多只能识别出二阶的特征组合，模型有一定的局限性。<strong>FNN</strong>模型最先提出了一种增强FM模型的思路，就是用FM模型学习到的隐向量初始化深度神经网络模型（MLP），再由MLP完成最终学习。</p><p>MLP（plain-DNN）因其特殊的结构天然就具有学习高阶特征组合的能力，它可以在一定的条件下以任意精度逼近任意函数。然而，plain-DNN以一种隐式的方式建模特征之间的交互关系，我们无法确定它学习到了多少阶的交叉关系。高维稀疏的原始特征在输入给DNN之前一般都会经过embedding处理，每一个域（类别）的原始特征都会被映射到一个低维稠密的实数向量，称之为embedding向量。FM模型中的隐向量也可以理解为embedding向量。Embedding向量中的元素用术语bit表示，可以看出plain-DNN的高阶特征交互建模是元素级的（bit-wise），也就是说同一个域对应的embedding向量中的元素也会相互影响。这与FM显式构建特征交叉关系的方式是不一样的，FM类方法是以向量级（vector-wise）的方式来构建高阶交叉关系。经验上，vector-wise的方式构建的特征交叉关系比bit-wise的方式更容易学习。</p><p>虽然两种建模交叉特征的方式有一些区别，但两者并不是相互排斥的，如果能把两者集合起来，便会相得益彰。<strong>PNN</strong>模型最先提出了一种融合bit-wise和vector-wise交叉特征的方法，其通过在网络的embedding层与全连接层之间加了一层Product Layer来完成特征组合。PNN与FM相比，舍弃了低阶特征，也就是线性的部分，这在一定程度上使得模型不太容易记住一些数据中的规律。<strong>WDL（Wide &amp; Deep Learning）</strong>模型混合了宽度模型与深度模型，其宽度部分保留了低价特征，偏重记忆；深度部分引入了bit-wise的特征交叉能力。WDL模型的一大缺点是宽度部分的输入依旧依赖于大量的人工特征工程。</p><p>能不能在融合bit-wise和vector-wise交叉特征的基础上，同时还能保留低阶特征(linear part)呢？当然是可以的。<strong>DeepFM</strong>模型融合了FM和WDL模型，其FM部分实现了低阶特征和vector-wise的二阶交叉特征建模，其Deep部分使模型具有了bit-wise的高阶交叉特征建模的能力。具体地，DeepFM包含两部分：神经网络部分与因子分解机部分，这两部分共享同样的输入。对于给定特征$i$，向量$w_i$用于表征一阶特征的重要性，隐变量$V_i$用于表示该特征与其他特征的相互影响。在FM部分，$V_i$用于表征二阶特征，同时在神经网络部分用于构建高阶特征。所有的参数共同参与训练。DeepFM的预测结果可以写为</p><script type="math/tex; mode=display">\hat{y}=sigmoid(y_{FM}+y_{DNN})</script><p>其中$\hat{y}∈(0,1)$是预测的点击率，$y_{FM}$与$y_{DNN}$分是FM部分与DNN部分。</p><script type="math/tex; mode=display">y_{FM}=\langle w,x \rangle + \sum_{i=1}^d \sum_{j=i+1}^d \langle V_i,V_j \rangle x_i x_j</script><p>其中$w∈R^d,V_i∈R^k$ 。加法部分反映了一阶特征的重要性，而内积部分反应了二阶特征的影响。</p><script type="math/tex; mode=display">y_{DNN}=\sigma(W^{H+1} \cdot a^H + b^{H+1})</script><p>其中H是隐层的层数。</p><p><img src="https://yangxudong.github.io/ctr-models/dnn-models.png" alt></p><p>FM、DeepFM和Inner-PNN都是通过原始特征隐向量的内积来构建vector-wise的二阶交叉特征，这种方式有两个主要的缺点：</p><ol><li>必须要穷举出所有的特征对，即任意两个field之间都会形成特征组合关系，而过多的组合关系可能会引入无效的交叉特征，给模型引入过多的噪音，从而导致性能下降。</li><li>二阶交叉特征有时候是不够的，好的特征可能需要更高阶的组合。虽然DNN部分可以部分弥补这个不足，但bit-wise的交叉关系是晦涩难懂、不确定并且不容易学习的。</li></ol><p>那么，<strong>有没有可能引入更高阶的vector-wise的交叉特征，同时又能控制模型的复杂度，避免产生过多的无效交叉特征呢？</strong>让我们先来思考一个问题。二阶交叉特征通过穷举所有的原始特征对得到，那么通过穷举的方法得到更高阶的交叉特征，必然会产生组合爆炸的维数灾难，导致网络参数过于庞大而无法学习，同时也会产生很多的无效交叉特征。让我们把这个问题称之为<strong>维数灾难挑战</strong>。</p><p>解决维数灾难挑战不可避免的就是要引入某种“压缩”机制，就是要把高阶的组合特征向量的维数降到一个合理的范围，同时在这个过程中尽量多的保留有效的交叉特征，去除无效的交叉特征。让我们谨记，所有构建高阶交叉特征的模型必然要引入特定的“压缩”机制，在学习建模高阶交叉特征的模型时我们脑中要始终绷紧一根弦，那就是这种压缩机制是如何实现的？这种压缩机制的效率和效果如何？</p><p>解决维数灾难挑战，<a href="https://zhuanlan.zhihu.com/p/43364598">Deep &amp; Cross Network(DCN)</a>模型交出一份让人比较满意的答卷，让我们来看看它是如何做到的。</p><p><strong>DCN</strong>模型以一个嵌入和堆叠层(embedding and stacking layer)开始，接着并列连一个cross network和一个deep network，接着通过一个combination layer将两个network的输出进行组合。交叉网络（cross network）的核心思想是以有效的方式应用显式特征交叉。交叉网络由交叉层组成，每个层具有以下公式：</p><script type="math/tex; mode=display">x_{l+1} = x_0 x_l^T w_l + b_l + x_l = f(x_l, w_l, b_l) + x_l</script><p>其中:</p><ul><li>$x_l,x_{l+1}$是列向量（column vectors），分别表示来自第$l$层和第($l+1$)层cross layers的输出；</li><li>$w_l, b_l \in R^d$是第$l$层layer的weight和bias参数。</li></ul><p>在完成一个特征交叉f后，每个cross layer会将它的输入加回去，对应的mapping function $f：R^d \rightarrow R^d$，刚好等于残差$x_{l+1} - x_l$，这里借鉴了残差网络的思想。</p><p><img src="https://yangxudong.github.io/dcn/dcn.png" alt></p><p><strong>特征的高阶交叉（high-degree interaction）</strong>：cross network的独特结构使得交叉特征的阶（the degress of cross features）随着layer的深度而增长。对于第$l$层layer，它的最高多项式阶（在输入$x_0$上）是$l+1$。 实际上，cross network由这些交叉项$x_1^{\alpha_1} x_2^{\alpha_2} … x_d^{\alpha_d}$组成，对应的阶从$1$到$l+1$。</p><p><strong>复杂度分析</strong>：假设$L_c$表示cross layers的数目，$d$表示输入$x_0$的维度。那么，在该cross network中涉及的参数数目为：$d \times L_c \times 2$。</p><p>一个cross network的时间和空间复杂度对于输入维度是线性关系。因而，比起它的deep部分，一个cross network引入的复杂度微不足道，DCN的整体复杂度与传统的DNN在同一水平线上。如此高效（efficiency）是受益于$x_0 x_l^T$的rank-one特性(两个向量的叉积)，它可以使我们生成所有的交叉项，无需计算或存储整个matrix。</p><p>关于DCN模型的实现，有一个重要的技巧可以节省大量的内存空间和训练时间，就是在计算cross layer的时候需要利用矩阵乘法的结合律，优先计算$x_l^T w$，而不是$x_0 x_l^T$，这是因为$x_l^T w$的计算结果是一个标量，几乎不占用存储空间，具体请参考《<a href="https://zhuanlan.zhihu.com/p/43364598">玩转企业级Deep&amp;Cross Network模型你只差一步</a>》。</p><p>亲爱的读者们，你们脑中的那根弦还在吗？DCN是如何有效压缩高维特征空间的呢？其实，对于cross layer可以换一种理解方式：假设$\tilde{x} \in R^d$是一个cross layer的输入，cross layer首先构建$d^2$个关于$x_i \tilde{x}_j$的pairwise交叉，接着以一种内存高效的方式将它们投影到维度$d$上。如果采用全连接Layer那样直接投影的方式会带来3次方的开销。Cross layer提供了一种有效的解决方式，将开销减小到维度$d$的量级上：考虑到$x_p = x_0 \tilde{x}^T w$等价于：</p><script type="math/tex; mode=display">x_p^T = [x_1\tilde{x}_1 ... x_1\tilde{x}_d ... x_d\tilde{x}_1 ... x_d\tilde{x}_d] \left[\begin{array}{ccc}  w&0&...&0\\  0&w&...&0\\  \vdots&\vdots&\ddots&\vdots\\  0&0&...&w\end{array}\right]</script><p>其中，行向量包含了所有$d^2$个关于$x_i \tilde{x}_j$的pairwise交叉，投影矩阵具有一个块对角化结构，其中$w \in R^d$是一个列向量。现在我们了解了DCN模型的“压缩”机制，即每个cross layer都把$d^2$维度的特征空间投影到$d$维的空间上。</p><p>DCN模型中使用的这种“压缩”机制是完美的吗，有没有什么局限性？实际上这种“压缩”方式把特征交互关系限定在一种特殊的形式上。我们再来看看cross layer的计算公式，为了简化，以便说明问题，下面去掉偏置项。</p><script type="math/tex; mode=display">x_k = x_0x_{k-1}^Tw_k+x_{k-1}</script><p>对于$x_1$，有如下公式:</p><script type="math/tex; mode=display">x_1 = x_0x_0^Tw_k+x_0</script><p>合并可得到：</p><script type="math/tex; mode=display">x_1 = x_0（x_0^Tw_k+1）= \alpha^1x_0</script><p>其中$\alpha^1=x_0^Tw_k+1$ 是一个关于$x_0$的线性回归函数，也就是一个标量。</p><p>根据数学归纳法，当$k=i$ 时，上式成立；当$k=i+1$ 时，我们可以得到</p><script type="math/tex; mode=display">x_{i+1}=x_0x_i^Tw_{i+1}=x_0((\alpha^ix_0)w_{i+1})+\alpha^ix_0=\alpha^{i+1}x_0</script><p>实际上，$\alpha^{i+1}$又是一个标量。因此Cross Network的输出就相当于$x_0$不断乘以一个数，当然这个数是和$x_0$高度相关的。</p><p>因此，我们可以总结出DCN模型的两个主要的不足：</p><ol><li>CrossNet的输出被限定在一种特殊的形式上</li><li>特征交叉还是以bit-wise的方式构建的</li></ol><p>让我们回到最初的那个问题，<strong>有没有可能引入更高阶的vector-wise的交叉特征，同时又能控制模型的复杂度，避免产生过多的无效交叉特征呢？</strong></p><h2 id="极深因子分解机模型（xDeepFM）"><a href="#极深因子分解机模型（xDeepFM）" class="headerlink" title="极深因子分解机模型（xDeepFM）"></a>极深因子分解机模型（xDeepFM）</h2><p><a href="https://arxiv.org/abs/1803.05170">xDeepFM</a>模型是自动构建交叉特征且能够端到端学习的集大成者，它很好的回答了上一小节末提出的问题。让我们来看看它是如何做到的。</p><p>为了实现自动学习显式的高阶特征交互，同时使得交互发生在向量级上，xDeepFM首先提出了一种新的名为<strong>压缩交互网络</strong>（Compressed Interaction Network，简称CIN）的模型。</p><p>CIN的输入是所有field的embedding向量构成的矩阵$X^0 \in R^{m \times  D}$，该矩阵的第$i$行对应第$i$个field的embedding向量，假设共有$m$个field，每个field的embedding向量的维度为$D$。CIN网络也是一个多层的网络，它的第$k$层的输出也是一个矩阵，记为$X^k \in R^{H_k \times  D}$，该矩阵的行数为 $H_k$，表示第$k$层共有$H_k$个特征（embedding）向量，其中$H_0=m$。</p><p>CIN中第$k$层的输出$X^k$由第$k-1$层的输出$X^{k-1}$和输入$X^0$经过一个比较复杂的运算得到，具体地，矩阵$X^k$中的第$h$行的计算公式如下：</p><script type="math/tex; mode=display">X_{h,*}^k = \sum_{i=1}^{H_{k-1}}\sum_{j=1}^m{W_{ij}^{k,h}(X_{i,*}^{k-1} \circ X_{j,*}^0)}</script><p>其中，$\circ$ 表示哈达玛积，即两个矩阵或向量对应元素相乘得到相同大小的矩阵或向量，示例如：$\langle a_1,a_2,a_3 \rangle \circ \langle b_1,b_2,b_3\rangle =\langle a_1b_1,a_2b_2,a_3b_3 \rangle$。</p><p>上述计算公式可能不是很好理解，论文作者给出了另一种更加方便理解的视角。在计算$X^{k+1}$时，定义一个中间变量$Z^{k+1} \in R^{H_k \times m \times D}$，$Z^{k+1}$是一个数据立方体，由D个数据矩阵堆叠而成，其中每个数据矩阵是由$X^k$的一个列向量与$X^0$的一个列向量的外积运算（Outer product）而得，如下图所示。$Z^{k+1}$的生成过程实际上是由$X^k$与$X^0$沿着各自embedding向量的方向计算外积的过程。</p><p><img src="https://www.msra.cn/wp-content/uploads/2018/08/kdd-2018-xdeepfm-2.png" alt></p><p>$Z^{k+1}$可以被看作是一个宽度为$m$、高度为$H_k$、通道数为D的图像，在这个虚拟的图像上施加一些卷积操作即得到$X^{k+1}$。$W^{k,h}$是其中一个卷积核，总共有$H_{k+1}$个不同的卷积核，因而借用CNN网络中的概念，$X^{k+1}$可以看作是由$H_{k+1}$个feature map堆叠而成，如下图所示。</p><p><img src="https://www.msra.cn/wp-content/uploads/2018/08/kdd-2018-xdeepfm-3.png" alt></p><p>正是通过卷积操作，CIN把第$k+1$层由$H_k \times m$个向量压缩到了$H_{k+1}$个向量，起到了防止维数灾难的效果。</p><p>CIN的宏观框架如下图所示，它的特点是，最终学习出的特征交互的阶数是由网络的层数决定的，每一层隐层都通过一个池化操作连接到输出层，从而保证了输出单元可以见到不同阶数的特征交互模式。同时不难看出，CIN的结构与循环神经网络RNN是很类似的，即每一层的状态是由前一层隐层的值与一个额外的输入数据计算所得。不同的是，CIN中不同层的参数是不一样的，而在RNN中是相同的；RNN中每次额外的输入数据是不一样的，而CIN中额外的输入数据是固定的，始终是$X^0$。</p><p><img src="/xdeepfm/CIN.png" alt></p><p>有了基础结构CIN之后，借鉴Wide&amp;Deep和DeepFM等模型的设计，将CIN与线性回归单元、全连接神经网络单元组合在一起，得到最终的模型并命名为极深因子分解机xDeepFM，其结构如下图所示。同时包含多种不同的结构成分可以提升模型的表达能力。</p><p><img src="https://www.msra.cn/wp-content/uploads/2018/08/kdd-2018-xdeepfm-5.png" alt></p><p>集成的CIN和DNN两个模块能够帮助模型同时以显式和隐式的方式学习高阶的特征交互，而集成的线性模块和深度神经模块也让模型兼具记忆与泛化的学习能力。值得一提的是，为了提高模型的通用性，xDeepFM中不同的模块共享相同的输入数据。而在具体的应用场景下，不同的模块也可以接入各自不同的输入数据，例如，线性模块中依旧可以接入很多根据先验知识提取的交叉特征来提高记忆能力，而在CIN或者DNN中，为了减少模型的计算复杂度，可以只导入一部分稀疏的特征子集。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>特征交叉组合作为一种常用的特征工程方法，可以有效地提升模型的效果。特征交叉组合从人工方式开始，经历了模型辅助的阶段，最后发展到各种端到端模型的阶段。端到端模型从建模二阶交叉关系向构建高阶交叉关系的方向发展，同时建模方式也从bit-wise向vector-wise发展。</p><p><img src="/xdeepfm/feature_interaction.png" alt="图"></p><p>本文总结了FM家族的一系列深度学习模型，这些模型有一个共同的强制要求：所有field的embedding向量的维数是相同的。这个要求是合理的吗？我们知道不同的field对应的值空间大小是不一样的，比如淘宝商品ID的量级在十亿级，类目的量级在万级，用户年龄段的量级在十级，在如此巨大的差异的情况下，embedding向量的维数只能取得尽可能的大，这大大增加了模型的参数量级和网络的收敛时间。所以我认为本文提及的FM家族模型有两个主要缺点：</p><ol><li>强制要求所有field的embedding向量的维数，增加了网络复杂度；</li><li>对连续值特征不友好。</li></ol><p>大家对此有什么看法呢？欢迎在评论区留言。</p><p>部分模型的tensorflow源代码<a href="https://github.com/yangxudong/deeplearning">可以在此找到</a>，实现不一定完全正确，欢迎批评指正。</p><h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><p><a href="https://zhuanlan.zhihu.com/p/35465875">主流CTR预估模型的演化及对比</a><br><a href="https://zhuanlan.zhihu.com/p/43364598">玩转企业级Deep&amp;Cross Network模型你只差一步</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;众所周知，深度学习在计算机视觉、语音识别、自然语言处理等领域最先取得突破并成为主流方法。但是，深度学习为什么是在这些领域而不是其他领域最先成功呢？我想一个原因就是图像、语音、文本数据在空间和时间上具有一定的内在关联性。比如，图像中会有大量的像素与周围的像素比较类似；文本数据中语言会受到语法规则的限制。CNN对于空间特征有很好的学习能力，正如RNN对于时序特征有强大的表示能力一样，因此CNN和RNN在上述领域各领风骚好多年。&lt;/p&gt;
&lt;p&gt;在Web-scale的搜索、推荐和广告系统中，特征数据具有高维、稀疏、多类别的特点，一般情况下缺少类图像、语音、文本领域的时空关联性。因此，如何构建合适的网络结构以便在信息检索、推荐系统和计算广告领域取得良好的特征表示能力，进一步提升最终的业务效果成了学术界和工业界共同关注的问题。&lt;/p&gt;
&lt;p&gt;本文在跟踪了最近主流的互联网业务中大量使用的排序模型的基础上，总结出了深度CTR、CVR预估模型发展演化的三条主线，跟大家分享。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一条主脉络是以FM家族为代表的深度模型，它们的共同特点是自动学习从原始特征交叉组合新的高阶特征。&lt;/li&gt;
&lt;li&gt;第二条主脉络是一类使用attention机制处理时序特征的深度模型，以DIN、DIEN等模型为代表。&lt;/li&gt;
&lt;li&gt;第三条主脉络是以迁移学习、多任务学习为基础的联合训练模型或pre-train机制，以&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37562283&quot;&gt;ESMM&lt;/a&gt;、DUPN等模型为代表。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其中前两条主脉络虽然出发点不同，但个人认为也有一些共通之处，比如attention机制是不是可以在某种程度上理解为一种特殊形式的组合特征。第三条主脉络属于流程或框架层面的创建。本文的主要目标是理清楚第一条主线中各个经典的深度模型的发展演化脉络，包括它们的优缺点和共通之处。&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="CTR预估" scheme="http://xudongyang.coding.me/tags/CTR%E9%A2%84%E4%BC%B0/"/>
    
    <category term="xDeepFM" scheme="http://xudongyang.coding.me/tags/xDeepFM/"/>
    
    <category term="特征组合" scheme="http://xudongyang.coding.me/tags/%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88/"/>
    
  </entry>
  
  <entry>
    <title>距离玩转企业级DCN(Deep &amp; Cross Network)模型，你只差一步</title>
    <link href="http://xudongyang.coding.me/dcn/"/>
    <id>http://xudongyang.coding.me/dcn/</id>
    <published>2018-08-30T08:20:44.000Z</published>
    <updated>2020-12-04T14:53:24.067Z</updated>
    
    <content type="html"><![CDATA[<p>Deep &amp; Cross Network(DCN)在 2017 年由 google 和 Stanford 共同发表的一篇论文中被提出，类似于Wide &amp; Deep Network(WDL)，是用负杂网络预估CTR的一种方法。</p><p>特征工程一直是许多预测模型成功的关键。许多有效的特征都来自于原始特征的交叉组合。在WDL中，wide侧的交叉组合特征依然需要依靠hand-craft来完成。而DCN能对sparse和dense的输入自动学习特征交叉，可以有效地捕获有限阶（bounded degrees）上的有效特征交叉，无需人工特征工程或暴力搜索（exhaustive searching），并且计算代价较低。</p><p>本文在详细介绍Deep &amp; Cross Network网络结构的基础上，给出了高效实现DCN模型的tensorflow代码，主要点出了网络上一些主流实现中常犯的错误，让你真正能够在企业级的生产环境中玩转DCN模型。<br><a id="more"></a></p><h2 id="DCN网络结构"><a href="#DCN网络结构" class="headerlink" title="DCN网络结构"></a>DCN网络结构</h2><p>DCN模型以一个嵌入和堆叠层(embedding and stacking layer)开始，接着并列连一个cross network和一个deep network，接着通过一个combination layer将两个network的输出进行组合。</p><p><img src="/dcn/dcn.png" alt></p><h3 id="嵌入和堆叠层"><a href="#嵌入和堆叠层" class="headerlink" title="嵌入和堆叠层"></a>嵌入和堆叠层</h3><p>考虑具有稀疏和稠密特征的输入数据。在网络规模推荐系统的CTR预测任务中，输入主要是分类特征，如“country=usa”。这些特征通常是编码为独热向量如<code>[0,1,0]</code>；然而，这通常会产生超高维度的特征空间。</p><p>为了减少维数，我们采用嵌入过程将这些二进制特征转换成实数值的稠密向量（通常称为嵌入向量）：</p><script type="math/tex; mode=display">x_{embed,i} =W_{embed,i}x_i</script><p>其中$x_{embed,i}$是embedding vector，$x_i$是第$i$个category的二元输入，$W_{embed,i} \in R^{n_e \times n_v}$是对应的embedding matrix，会与网络中的其它参数一起进行优化，$n_e$,$n_v$分别是embedding size和vocabulary size。</p><p>最后，我们将嵌入向量与归一化稠密特征xdense叠加起来形成一个向量：<script type="math/tex">x_0 = [ x_{embed,1}^T, ..., X_{embed,k}^T, X_{dense}^T]。</script></p><p>这一部分在tensorflow中，使用<code>tf.feature_column</code>API可以很容易实现，大致代码结构如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">embed0 = tf.feature_column.embedding_column(...)</span><br><span class="line">...</span><br><span class="line">dense0 = tf.feature_column.indicator_column(...)</span><br><span class="line">dense1 = tf.feature_column.numeric_column(...)</span><br><span class="line">...</span><br><span class="line">columns = [embed0, ..., dense0, dense1, ...]</span><br><span class="line">x0 = tf.feature_column.input_layer(features, feature_columns)</span><br></pre></td></tr></table></figure></p><h2 id="交叉网络"><a href="#交叉网络" class="headerlink" title="交叉网络"></a>交叉网络</h2><p>交叉网络的核心思想是以有效的方式应用显式特征交叉。交叉网络由交叉层组成，每个层具有以下公式：</p><script type="math/tex; mode=display">x_{l+1} = x_0 x_l^T w_l + b_l + x_l = f(x_l, w_l, b_l) + x_l</script><p>其中:</p><ul><li>$x_l,x_{l+1}$是列向量（column vectors），分别表示来自第$l$层和第($l+1$)层cross layers的输出；</li><li>$w_l, b_l \in R^d$是第$l$层layer的weight和bias参数。</li></ul><p>在完成一个特征交叉f后，每个cross layer会将它的输入加回去，对应的mapping function $f：R^d \rightarrow R^d$，刚好等于残差$x_{l+1} - x_l$，这里借鉴了残差网络的思想。</p><p><img src="/dcn/cross_layer.jpg" alt></p><p><strong>特征的高阶交叉（high-degree interaction）</strong>：cross network的独特结构使得交叉特征的阶（the degress of cross features）随着layer的深度而增长。对于第$l$层layer，它的最高多项式阶（在输入$x_0$上）是$l+1$。 实际上，cross network由这些交叉项$x_1^{\alpha_1} x_2^{\alpha_2} … x_d^{\alpha_d}$组成，对应的阶从$1$到$l+1$。</p><p><strong>复杂度分析</strong>：假设$L_c$表示cross layers的数目，$d$表示输入$x_0$的维度。那么，在该cross network中涉及的参数数目为：$d \times L_c \times 2$。</p><p>一个cross network的时间和空间复杂度对于输入维度是线性关系。因而，比起它的deep部分，一个cross network引入的复杂度微不足道，DCN的整体复杂度与传统的DNN在同一水平线上。如此高效（efficiency）是受益于$x_0 x_l^T$的rank-one特性(两个向量的叉积)，它可以使我们生成所有的交叉项，无需计算或存储整个matrix。</p><p>搜索了网上主流的实现cross layer的方法，代码如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_layer</span>(<span class="params">x0, x, name</span>):</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(name):</span><br><span class="line">    input_dim = x0.get_shape().as_list()[<span class="number">1</span>]</span><br><span class="line">    w = tf.get_variable(<span class="string">&quot;weight&quot;</span>, [input_dim], initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>))</span><br><span class="line">    b = tf.get_variable(<span class="string">&quot;bias&quot;</span>, [input_dim], initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>))</span><br><span class="line">    xx0 = tf.expand_dims(x0, -<span class="number">1</span>)  <span class="comment"># shape &lt;?, d, 1&gt;</span></span><br><span class="line">    xx = tf.expand_dims(x, -<span class="number">1</span>)  <span class="comment"># shape &lt;?, d, 1&gt;</span></span><br><span class="line">    mat = tf.matmul(xx0, xx, transpose_b=<span class="literal">True</span>)  <span class="comment"># shape &lt;?, d, d&gt;</span></span><br><span class="line">    <span class="keyword">return</span> tf.tensordot(mat, w, <span class="number">1</span>) + b + x  <span class="comment"># shape &lt;?, d&gt;</span></span><br></pre></td></tr></table></figure><br>这种方法在逻辑上没有什么问题，但实际上却是<strong>非常消耗计算和存储资源</strong>的，原因在于显式地计算$x_0 x_l^T$需要非常大的内存空间来存储临时计算结果。我们来计算一下，一个cross layer仅仅是计算$x_0 x_l^T$这一个操作就需要消耗 $batch\_size \times d \times d \times 4$ 字节的内存（一个浮点数占4个字节）。在企业级的模型中，$d$通常是几千甚至几万的量级，假设$d=1k$，则需要$batch\_size \times 4M$的存储空间，这通常情况下已经是G级别的大小了，何况我们仅仅计算了一个Layer，别忘了我们总共有$L_c$个cross layer。另外，该操作的结果（一个矩阵）再和$w$向量相乘时也是非常消耗计算资源的。即使你在离线训练时通过减少cross layer的个数，减小batch_size等手段完成了模型的训练，在模型部署中线上之后，线性的打分系统依然要面临Out of Memory的风险，因为线上预测我们总是希望一次请求尽可能返回多条记录的预测分数，否则要么是影响全局的效果，要么是需要更多的请求次数，从而面临巨大的性能压力。</p><p>正确的实现方式不是先计算$x_0 x_l^T$，而是先计算$x_l^T w$，因为$x_l^T w$的计算结果是一个标量，几乎不占用存储空间。这两种方法的计算结果是一致的，因为矩阵乘法是满足结合律的： <code>(AB)C=A(BC)</code>。高效的实现代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_layer2</span>(<span class="params">x0, x, name</span>):</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(name):</span><br><span class="line">    input_dim = x0.get_shape().as_list()[<span class="number">1</span>]</span><br><span class="line">    w = tf.get_variable(<span class="string">&quot;weight&quot;</span>, [input_dim], initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>))</span><br><span class="line">    b = tf.get_variable(<span class="string">&quot;bias&quot;</span>, [input_dim], initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>))</span><br><span class="line">    xb = tf.tensordot(tf.reshape(x, [-<span class="number">1</span>, <span class="number">1</span>, input_dim]), w, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> x0 * xb + b + x</span><br></pre></td></tr></table></figure></p><p>在上面的实现中，我们使用了<code>tf.reshape</code>操作实现了$x_l$的转置，因为$x_l$实际上是一个向量，并不是一个矩阵，因此这种方法是可行的。下面给出构建整个交叉网络的tensorflow代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_cross_layers</span>(<span class="params">x0, params</span>):</span></span><br><span class="line">  num_layers = params[<span class="string">&#x27;num_cross_layers&#x27;</span>]</span><br><span class="line">  x = x0</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">    x = cross_layer2(x0, x, <span class="string">&#x27;cross_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">  <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></p><p>对于cross layer可以换一种理解方式。假设$\tilde{x} \in R^d$是一个cross layer的输入，cross layer首先构建$d^2$个关于$x_i \tilde{x}_j$的pairwise交叉，接着以一种内存高效的方式将它们投影到维度$d$上。如果采用全连接Layer那样直接投影的方式会带来3次方的开销。Cross layer提供了一种有效的解决方式，将开销减小到维度$d$的量级上：考虑到$x_p = x_0 \tilde{x}^T w$等价于：</p><script type="math/tex; mode=display">x_p^T = [x_1\tilde{x}_1 ... x_1\tilde{x}_d ... x_d\tilde{x}_1 ... x_d\tilde{x}_d] \left[\begin{array}{ccc}  w&0&...&0\\  0&w&...&0\\  \vdots&\vdots&\ddots&\vdots\\  0&0&...&w\end{array}\right]</script><p>其中，行向量包含了所有$d^2$个关于$x_i \tilde{x}_j$的pairwise交叉，投影矩阵具有一个块对角化结构，其中$w \in R^d$是一个列向量。</p><h2 id="深度网络"><a href="#深度网络" class="headerlink" title="深度网络"></a>深度网络</h2><p>交叉网络的参数数目少，从而限制了模型的能力（capacity）。为了捕获高阶非线性交叉，我们平行引入了一个深度网络。</p><p>深度网络就是一个全连接的前馈神经网络，每个深度层具有如下公式：<script type="math/tex">h_{l+1} = f(W_l h_l + b_l)</script><br>其中：</p><ul><li>$h_l \in R^{n_l}, h_{l+1} \in R^{n_{l+1}}$别是第$l$层和第($l+1$)层hidden layer；</li><li>$W_l \in R^{n_{l+1} \times n_l}, b_l \in R^{n_{l+1}}$第$l$个deep layer的参数；</li><li>$f(⋅)$是ReLU function。</li></ul><p><strong>复杂度分析</strong>：出于简洁性，我们假设所有的deep layers具有相同的size。假设$L_d$表示deep layers的数目，m表示deep layer的size。那么，在该deep network中的参数的数目为：</p><script type="math/tex; mode=display">d×m+m+(m2+m)×(L_d−1)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_deep_layers</span>(<span class="params">x0, params</span>):</span></span><br><span class="line">  <span class="comment"># Build the hidden layers, sized according to the &#x27;hidden_units&#x27; param.</span></span><br><span class="line">  net = x0</span><br><span class="line">  <span class="keyword">for</span> units <span class="keyword">in</span> params[<span class="string">&#x27;hidden_units&#x27;</span>]:</span><br><span class="line">    net = tf.layers.dense(net, units=units, activation=tf.nn.relu)</span><br><span class="line">  <span class="keyword">return</span> net</span><br></pre></td></tr></table></figure><h2 id="Combination-Layer"><a href="#Combination-Layer" class="headerlink" title="Combination Layer"></a>Combination Layer</h2><p>最后，将两个network的输出进行拼接（concatenate），然后将该拼接向量（concatenated vector）喂给一个标准的逻辑回归模型。<script type="math/tex">p = \sigma ( [x_{L_1}^T, h_{L_2}^T] w_{logits})</script></p><p>类似于WDL模型，我们对两个network进行jointly train，在训练期间，每个独立的network会察觉到另一个。下面给出整个模型的实现代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dcn_model_fn</span>(<span class="params">features, labels, mode, params</span>):</span></span><br><span class="line">  x0 = tf.feature_column.input_layer(features, params[<span class="string">&#x27;feature_columns&#x27;</span>])</span><br><span class="line">  last_deep_layer = build_deep_layers(x0, params)</span><br><span class="line">  last_cross_layer = build_cross_layers(x0, params)</span><br><span class="line">  last_layer = tf.concat([last_cross_layer, last_deep_layer], <span class="number">1</span>)</span><br><span class="line">  my_head = tf.contrib.estimator.binary_classification_head(thresholds=[<span class="number">0.5</span>])</span><br><span class="line">  logits = tf.layers.dense(last_layer, units=my_head.logits_dimension)</span><br><span class="line">  optimizer = tf.train.AdagradOptimizer(learning_rate=params[<span class="string">&#x27;learning_rate&#x27;</span>])</span><br><span class="line">  <span class="keyword">return</span> my_head.create_estimator_spec(</span><br><span class="line">    features=features,</span><br><span class="line">    mode=mode,</span><br><span class="line">    labels=labels,</span><br><span class="line">    logits=logits,</span><br><span class="line">    train_op_fn=<span class="keyword">lambda</span> loss: optimizer.minimize(loss, global_step=tf.train.get_global_step())</span><br><span class="line">  )</span><br></pre></td></tr></table></figure><p><img src="/dcn/dcn_tensor.png" alt></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>DCN主要有以下几点贡献：</p><ul><li>提出一种新型的交叉网络结构，可以用来提取交叉组合特征，并不需要人为设计的特征工程；</li><li>这种网络结构足够简单同时也很有效，可以获得随网络层数增加而增加的多项式阶（polynomial degree）交叉特征；</li><li>十分节约内存（依赖于正确地实现），并且易于使用；</li><li>实验结果表明，DCN相比于其他模型有更出色的效果，与DNN模型相比，较少的参数却取得了较好的效果。</li></ul><p><a href="https://github.com/yangxudong/deeplearning/tree/master/DCN">源代码Github</a></p><h2 id="论文阅读"><a href="#论文阅读" class="headerlink" title="论文阅读"></a>论文阅读</h2><p><a href="https://arxiv.org/pdf/1708.05123.pdf">Deep &amp; Cross Network for Ad Click Prediction</a></p><h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/35465875">主流CTR预估模型的演化及对比</a></li><li><a href="https://zhuanlan.zhihu.com/p/37562283">CVR预估的新思路：完整空间多任务模型</a></li><li><a href="https://yangxudong.github.io">个人博客</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;Deep &amp;amp; Cross Network(DCN)在 2017 年由 google 和 Stanford 共同发表的一篇论文中被提出，类似于Wide &amp;amp; Deep Network(WDL)，是用负杂网络预估CTR的一种方法。&lt;/p&gt;
&lt;p&gt;特征工程一直是许多预测模型成功的关键。许多有效的特征都来自于原始特征的交叉组合。在WDL中，wide侧的交叉组合特征依然需要依靠hand-craft来完成。而DCN能对sparse和dense的输入自动学习特征交叉，可以有效地捕获有限阶（bounded degrees）上的有效特征交叉，无需人工特征工程或暴力搜索（exhaustive searching），并且计算代价较低。&lt;/p&gt;
&lt;p&gt;本文在详细介绍Deep &amp;amp; Cross Network网络结构的基础上，给出了高效实现DCN模型的tensorflow代码，主要点出了网络上一些主流实现中常犯的错误，让你真正能够在企业级的生产环境中玩转DCN模型。&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="DCN" scheme="http://xudongyang.coding.me/tags/DCN/"/>
    
    <category term="CTR预估" scheme="http://xudongyang.coding.me/tags/CTR%E9%A2%84%E4%BC%B0/"/>
    
  </entry>
  
  <entry>
    <title>构建分布式Tensorflow模型系列之CVR预估案例ESMM模型</title>
    <link href="http://xudongyang.coding.me/esmm-1/"/>
    <id>http://xudongyang.coding.me/esmm-1/</id>
    <published>2018-08-16T09:03:31.000Z</published>
    <updated>2020-12-04T08:17:21.873Z</updated>
    
    <content type="html"><![CDATA[<p>本文是“基于Tensorflow高阶API构建大规模分布式深度学习模型系列”的第五篇，旨在通过一个完整的案例巩固一下前面几篇文章中提到的各类高阶API的使用方法，同时演示一下用tensorflow高阶API构建一个比较复杂的分布式深度学习模型的完整过程。</p><p>文本要实现的深度学习模式是阿里巴巴的算法工程师18年刚发表的论文《<a href="https://arxiv.org/abs/1804.07931">Entire Space Multi-Task Model: An Eﬀective Approach for Estimating Post-Click Conversion Rate</a>》中提出的ESMM模型，关于该模型的详细介绍可以参考我之前的一篇文章：《<a href="https://zhuanlan.zhihu.com/p/37562283">CVR预估的新思路：完整空间多任务模型</a>》。</p><a id="more"></a><p>ESMM模型是一个多任务学习（Multi-Task Learning）模型，它同时学习学习点击率和转化率两个目标，即模型直接预测展现转换率（pCTCVR）：单位流量获得成交的概率。模型的结构如图1所示。</p><p><img src="https://yangxudong.github.io/esmm/esmm.png" alt></p><p>ESMM模型有两个主要的特点:</p><ul><li>在整个样本空间建模。区别与传统的CVR预估方法通常使用“点击-&gt;成交”事情的日志来构建训练样本，ESMM模型使用“展现-&gt;点击-&gt;成交”事情的日志来构建训练样本。</li><li>共享特征表示。两个子任务（CTR预估和CVR预估）之间共享各类实体（产品、品牌、类目、商家等）ID的embedding向量表示。</li></ul><p>ESMM模型的损失函数由两部分组成，对应于pCTR 和pCTCVR 两个子任务，其形式如下：<br>\begin{align}<br>L(\theta_{cvr},\theta_{ctr}) &amp;=\sum_{i=1}^N l(y_i, f(x_i; \theta_{ctr}))\\<br>&amp;= \sum_{i=1}^N l(y_i\&amp;z_i, f(x_i; \theta_{ctr}) \times f(x_i; \theta_{cvr}))<br>\end{align}<br>其中，$\theta_{ctr}$和$\theta_{cvr}$分别是CTR网络和CVR网络的参数，$l(\cdot)$是交叉熵损失函数。在CTR任务中，有点击行为的展现事件构成的样本标记为正样本，没有点击行为发生的展现事件标记为负样本；在CTCVR任务中，同时有点击和购买行为的展现事件标记为正样本，否则标记为负样本。</p><p>ESMM模型由两个结构完全相同的子网络连接而成，我们把子网络对应的模型称之为Base模型。接下来，我们先介绍下如何用tensorflow实现Base模型。</p><h2 id="Base模型的实现"><a href="#Base模型的实现" class="headerlink" title="Base模型的实现"></a>Base模型的实现</h2><p>在Base模型的网络输入包括user field和item field两部分。user field主要由用户的历史行为序列构成，具体地说，包含了用户浏览的产品ID列表，以及用户浏览的品牌ID列表、类目ID列表等；不同的实体ID列表构成不同的field。网络的Embedding层，把这些实体ID都映射为固定长度的低维实数向量；接着之后的Field-wise Pooling层把同一个Field的所有实体embedding向量求和得到对应于当前Field的一个唯一的向量；之后所有Field的向量拼接（concat）在一起构成一个大的隐层向量；接着大的隐层向量之上再接入诺干全连接层，最后再连接到只有一个神经元的输出层。</p><h3 id="Feature-Column构建序列embedding和pooling"><a href="#Feature-Column构建序列embedding和pooling" class="headerlink" title="Feature Column构建序列embedding和pooling"></a>Feature Column构建序列embedding和pooling</h3><p>具体到tensorflow里，如何实现embedding layer以及field-wise pooling layer呢？</p><p>其实，用tensorflow的<a href="https://zhuanlan.zhihu.com/p/41663141">Feature Column API</a>可以非常容易地实现。在详细介绍之前，建议读者先阅读一下该系列文章的上一篇：《<a href="https://zhuanlan.zhihu.com/p/41663141">构建分布式Tensorflow模型系列:特征工程</a>》。</p><p>实现embedding layer需要用到<code>tf.feature_column.embedding_column</code>或者<code>tf.feature_column.shared_embedding_columns</code>，这里因为我们希望user field和item field的同一类型的实体共享相同的embedding映射空间，所有选用<code>tf.feature_column.shared_embedding_columns</code>。由于<code>shared_embedding_columns</code>函数只接受categorical_column列表作为参数，因此需要为原始特征数据先创建categorical_columns。</p><p>来看下具体的例子，假设在原始特征数据中，behaviorPids表示用户历史浏览过的产品ID列表；productId表示当前的候选产品ID；则构建embedding layer的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> feature_column <span class="keyword">as</span> fc</span><br><span class="line"><span class="comment"># user field</span></span><br><span class="line">pids = fc.categorical_column_with_hash_bucket(<span class="string">&quot;behaviorPids&quot;</span>, <span class="number">10240</span>, dtype=tf.int64)</span><br><span class="line"><span class="comment"># item field</span></span><br><span class="line">pid = fc.categorical_column_with_hash_bucket(<span class="string">&quot;productId&quot;</span>, <span class="number">1000000</span>, dtype=tf.int64)</span><br><span class="line"></span><br><span class="line">pid_embed = fc.shared_embedding_columns([pids, pid], <span class="number">100</span>, combiner=<span class="string">&#x27;sum&#x27;</span>, shared_embedding_collection_name=<span class="string">&quot;pid&quot;</span>)</span><br></pre></td></tr></table></figure><p>需要说明的是，在构建训练样本时要特别注意，behaviorPids列表必须是固定长度的，否则在使用dataset的batch方法时会报tensor shape不一致的错。然而，现实中每个用户浏览过的产品个数肯定会不一样，这时可以截取用户的最近N个浏览行为，当某些用户的浏览商品数不足N个时填充默认值-1（如果ID是用字符串表示的时候，填充空字符串）。那么为什么填充的默认值必须是-1呢？这时因为<code>categorical_column*</code>函数用默认值-1表示样本数据中未登录的值，-1表示的categorical_column经过embedding_column之后被映射到零向量，而零向量在后面的求和pooling操作中不影响结果。</p><p>那么，如何实现field-wise pooling layer呢？其实，在用<code>tf.feature_column.embedding_column</code>或者<code>tf.feature_column.shared_embedding_columns</code>API时不需要另外实现pooling layer，因为这2个函数同时实现了embedding向量映射和field-wise pooling。大家可能已经主要到了shared_embedding_columns函数的combiner=’sum’参数，这个参数就指明了当该field有多个embedding向量时融合为唯一一个向量的操作，’sum’操作即element-wise add。</p><p>上面的代码示例，仅针对产品这一实体特征进行了embedding和pooling操作，当有多个不同的实体特征时，仅需要采用相同的方法即可。</p><h3 id="实现weighted-sum-pooling操作"><a href="#实现weighted-sum-pooling操作" class="headerlink" title="实现weighted sum pooling操作"></a>实现weighted sum pooling操作</h3><p>上面的操作实现了行为序列特征的embedding和pooling，但有一个问题就是序列中的每个行为被同等对待了；某些情况下，我们可能希望行为序列中不同的实体ID在做sum pooling时有不同的权重。比如说，我们可能希望行为时间越近的产品的权重越高，或者与候选产品有相同属性（类目、品牌、商家等）的产品有更高的权重。</p><p>那么如何实现weighted sum pooling操作呢？答案就是使用<code>weighted_categorical_column</code>函数。我们必须在构建样本时添加一个额外的权重特征，权重特征表示行为序列中每个产品的权重，因此权重特征是一个与行为序列平行的列表（向量），两者的维度必须相同。另外，如果行为序列中有填充的默认值-1，那么权重特征中这些默认值对应的权重必须为0。代码示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> feature_column <span class="keyword">as</span> fc</span><br><span class="line"><span class="comment"># user field</span></span><br><span class="line">pids = fc.categorical_column_with_hash_bucket(<span class="string">&quot;behaviorPids&quot;</span>, <span class="number">10240</span>, dtype=tf.int64)</span><br><span class="line">pids_weighted = fc.weighted_categorical_column(pids, <span class="string">&quot;pidWeights&quot;</span>)</span><br><span class="line"><span class="comment"># item field</span></span><br><span class="line">pid = fc.categorical_column_with_hash_bucket(<span class="string">&quot;productId&quot;</span>, <span class="number">1000000</span>, dtype=tf.int64)</span><br><span class="line"></span><br><span class="line">pid_embed = fc.shared_embedding_columns([pids_weighted, pid], <span class="number">100</span>, combiner=<span class="string">&#x27;sum&#x27;</span>, shared_embedding_collection_name=<span class="string">&quot;pid&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="模型函数"><a href="#模型函数" class="headerlink" title="模型函数"></a>模型函数</h3><p>Base模型的其他组件就不过多介绍了，模型函数的代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_model</span>(<span class="params">features, labels, mode, params</span>):</span></span><br><span class="line">  net = fc.input_layer(features, params[<span class="string">&#x27;feature_columns&#x27;</span>])</span><br><span class="line">  <span class="comment"># Build the hidden layers, sized according to the &#x27;hidden_units&#x27; param.</span></span><br><span class="line">  <span class="keyword">for</span> units <span class="keyword">in</span> params[<span class="string">&#x27;hidden_units&#x27;</span>]:</span><br><span class="line">    net = tf.layers.dense(net, units=units, activation=tf.nn.relu)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;dropout_rate&#x27;</span> <span class="keyword">in</span> params <span class="keyword">and</span> params[<span class="string">&#x27;dropout_rate&#x27;</span>] &gt; <span class="number">0.0</span>:</span><br><span class="line">      net = tf.layers.dropout(net, params[<span class="string">&#x27;dropout_rate&#x27;</span>], training=(mode == tf.estimator.ModeKeys.TRAIN))</span><br><span class="line">  my_head = tf.contrib.estimator.binary_classification_head(thresholds=[<span class="number">0.5</span>])</span><br><span class="line">  <span class="comment"># Compute logits (1 per class).</span></span><br><span class="line">  logits = tf.layers.dense(net, my_head.logits_dimension, activation=<span class="literal">None</span>, name=<span class="string">&quot;my_model_output_logits&quot;</span>)</span><br><span class="line">  optimizer = tf.train.AdagradOptimizer(learning_rate=params[<span class="string">&#x27;learning_rate&#x27;</span>])</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_train_op_fn</span>(<span class="params">loss</span>):</span></span><br><span class="line">    <span class="keyword">return</span> optimizer.minimize(loss, global_step=tf.train.get_global_step())</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> my_head.create_estimator_spec(</span><br><span class="line">    features=features,</span><br><span class="line">    mode=mode,</span><br><span class="line">    labels=labels,</span><br><span class="line">    logits=logits,</span><br><span class="line">    train_op_fn=_train_op_fn</span><br><span class="line">  )</span><br></pre></td></tr></table></figure></p><h2 id="ESMM模型的实现"><a href="#ESMM模型的实现" class="headerlink" title="ESMM模型的实现"></a>ESMM模型的实现</h2><p>有了Base模型之后，ESMM模型的实现就已经成功了一大半。剩下的工作就是把两个子模型连接在一块，同时定义好整个模型的损失函数和优化操作即可。</p><p>在前面的文章中，我们分享过为tensorflow estimator定义模型函数时，需要为不同mode（训练、评估、预测）下定义构建计算graph的所有操作，并返回想要的<code>tf.estimator.EstimatorSpec</code>。在前面的介绍中，我们使用了Head API来简化了创建EstimatorSpec的过程，但在实现ESMM模型时没有现成的Head可用，必须手动创建EstimatorSpec。</p><p>在不同的mode下，模型函数必须返回包含不同图操作（op）的EstimatorSpec，具体地：</p><ul><li>For mode == ModeKeys.TRAIN: required fields are <code>loss</code> and <code>train_op</code>.</li><li>For mode == ModeKeys.EVAL: required field is <code>loss</code>.</li><li>For mode == ModeKeys.PREDICT: required fields are <code>predictions</code>.</li></ul><p>另外，如果模型需要导出以便提供线上服务，这时必须在mode == ModeKeys.EVAL定义<code>export_outputs</code>操作，并添加到返回的EstimatorSpec中。</p><p>实现ESMM模型的关键点在于定义该模型独特的损失函数。上文也提到，ESMM模型的损失函数有2部分构成，一部分对应于CTR任务，另一部分对应于CTCVR任务。具体如何定义，请参考下面的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_mode</span>(<span class="params">features, mode, params</span>):</span></span><br><span class="line">  net = fc.input_layer(features, params[<span class="string">&#x27;feature_columns&#x27;</span>])</span><br><span class="line">  <span class="comment"># Build the hidden layers, sized according to the &#x27;hidden_units&#x27; param.</span></span><br><span class="line">  <span class="keyword">for</span> units <span class="keyword">in</span> params[<span class="string">&#x27;hidden_units&#x27;</span>]:</span><br><span class="line">    net = tf.layers.dense(net, units=units, activation=tf.nn.relu)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;dropout_rate&#x27;</span> <span class="keyword">in</span> params <span class="keyword">and</span> params[<span class="string">&#x27;dropout_rate&#x27;</span>] &gt; <span class="number">0.0</span>:</span><br><span class="line">      net = tf.layers.dropout(net, params[<span class="string">&#x27;dropout_rate&#x27;</span>], training=(mode == tf.estimator.ModeKeys.TRAIN))</span><br><span class="line">  <span class="comment"># Compute logits</span></span><br><span class="line">  logits = tf.layers.dense(net, <span class="number">1</span>, activation=<span class="literal">None</span>)</span><br><span class="line">  <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_model</span>(<span class="params">features, labels, mode, params</span>):</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;ctr_model&#x27;</span>):</span><br><span class="line">    ctr_logits = build_mode(features, mode, params)</span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;cvr_model&#x27;</span>):</span><br><span class="line">    cvr_logits = build_mode(features, mode, params)</span><br><span class="line"></span><br><span class="line">  ctr_predictions = tf.sigmoid(ctr_logits, name=<span class="string">&quot;CTR&quot;</span>)</span><br><span class="line">  cvr_predictions = tf.sigmoid(cvr_logits, name=<span class="string">&quot;CVR&quot;</span>)</span><br><span class="line">  prop = tf.multiply(ctr_predictions, cvr_predictions, name=<span class="string">&quot;CTCVR&quot;</span>)</span><br><span class="line">  <span class="keyword">if</span> mode == tf.estimator.ModeKeys.PREDICT:</span><br><span class="line">    predictions = &#123;</span><br><span class="line">      <span class="string">&#x27;probabilities&#x27;</span>: prop,</span><br><span class="line">      <span class="string">&#x27;ctr_probabilities&#x27;</span>: ctr_predictions,</span><br><span class="line">      <span class="string">&#x27;cvr_probabilities&#x27;</span>: cvr_predictions</span><br><span class="line">    &#125;</span><br><span class="line">    export_outputs = &#123;</span><br><span class="line">      <span class="string">&#x27;prediction&#x27;</span>: tf.estimator.export.PredictOutput(predictions)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> tf.estimator.EstimatorSpec(mode, predictions=predictions, export_outputs=export_outputs)</span><br><span class="line"></span><br><span class="line">  y = labels[<span class="string">&#x27;cvr&#x27;</span>]</span><br><span class="line">  cvr_loss = tf.reduce_sum(tf.keras.backend.binary_crossentropy(y, prop), name=<span class="string">&quot;cvr_loss&quot;</span>)</span><br><span class="line">  ctr_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels[<span class="string">&#x27;ctr&#x27;</span>], logits=ctr_logits), name=<span class="string">&quot;ctr_loss&quot;</span>)</span><br><span class="line">  loss = tf.add(ctr_loss, cvr_loss, name=<span class="string">&quot;ctcvr_loss&quot;</span>)</span><br><span class="line"></span><br><span class="line">  ctr_accuracy = tf.metrics.accuracy(labels=labels[<span class="string">&#x27;ctr&#x27;</span>], predictions=tf.to_float(tf.greater_equal(ctr_predictions, <span class="number">0.5</span>)))</span><br><span class="line">  cvr_accuracy = tf.metrics.accuracy(labels=y, predictions=tf.to_float(tf.greater_equal(prop, <span class="number">0.5</span>)))</span><br><span class="line">  ctr_auc = tf.metrics.auc(labels[<span class="string">&#x27;ctr&#x27;</span>], ctr_predictions)</span><br><span class="line">  cvr_auc = tf.metrics.auc(y, prop)</span><br><span class="line">  metrics = &#123;<span class="string">&#x27;cvr_accuracy&#x27;</span>: cvr_accuracy, <span class="string">&#x27;ctr_accuracy&#x27;</span>: ctr_accuracy, <span class="string">&#x27;ctr_auc&#x27;</span>: ctr_auc, <span class="string">&#x27;cvr_auc&#x27;</span>: cvr_auc&#125;</span><br><span class="line">  tf.summary.scalar(<span class="string">&#x27;ctr_accuracy&#x27;</span>, ctr_accuracy[<span class="number">1</span>])</span><br><span class="line">  tf.summary.scalar(<span class="string">&#x27;cvr_accuracy&#x27;</span>, cvr_accuracy[<span class="number">1</span>])</span><br><span class="line">  tf.summary.scalar(<span class="string">&#x27;ctr_auc&#x27;</span>, ctr_auc[<span class="number">1</span>])</span><br><span class="line">  tf.summary.scalar(<span class="string">&#x27;cvr_auc&#x27;</span>, cvr_auc[<span class="number">1</span>])</span><br><span class="line">  <span class="keyword">if</span> mode == tf.estimator.ModeKeys.EVAL:</span><br><span class="line">    <span class="keyword">return</span> tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Create training op.</span></span><br><span class="line">  <span class="keyword">assert</span> mode == tf.estimator.ModeKeys.TRAIN</span><br><span class="line">  optimizer = tf.train.AdagradOptimizer(learning_rate=params[<span class="string">&#x27;learning_rate&#x27;</span>])</span><br><span class="line">  train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())</span><br><span class="line">  <span class="keyword">return</span> tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)</span><br></pre></td></tr></table></figure><p>至此，实现ESMM模型需要介绍的内容就结束了，完整的代码已经在github上共享了，欢迎大家下载试用。</p><p>完整源代码：<a href="https://github.com/yangxudong/deeplearning/tree/master/esmm">https://github.com/yangxudong/deeplearning/tree/master/esmm</a></p><h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/38470806">基于Tensorflow高阶API构建大规模分布式深度学习模型系列: 开篇</a></li><li><a href="https://zhuanlan.zhihu.com/p/38421397">基于Tensorflow高阶API构建大规模分布式深度学习模型系列：基于Dataset API处理Input pipeline</a></li><li><a href="https://zhuanlan.zhihu.com/p/41473323">基于Tensorflow高阶API构建大规模分布式深度学习模型系列: 自定义Estimator（以文本分类CNN模型为例）</a></li><li><a href="https://zhuanlan.zhihu.com/p/41663141">基于Tensorflow高阶API构建大规模分布式深度学习模型系列:特征工程 Feature Column</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文是“基于Tensorflow高阶API构建大规模分布式深度学习模型系列”的第五篇，旨在通过一个完整的案例巩固一下前面几篇文章中提到的各类高阶API的使用方法，同时演示一下用tensorflow高阶API构建一个比较复杂的分布式深度学习模型的完整过程。&lt;/p&gt;
&lt;p&gt;文本要实现的深度学习模式是阿里巴巴的算法工程师18年刚发表的论文《&lt;a href=&quot;https://arxiv.org/abs/1804.07931&quot;&gt;Entire Space Multi-Task Model: An Eﬀective Approach for Estimating Post-Click Conversion Rate&lt;/a&gt;》中提出的ESMM模型，关于该模型的详细介绍可以参考我之前的一篇文章：《&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37562283&quot;&gt;CVR预估的新思路：完整空间多任务模型&lt;/a&gt;》。&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="tensorflow" scheme="http://xudongyang.coding.me/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>基于Tensorflow高阶API构建大规模分布式深度学习模型系列之特征工程Feature Columns</title>
    <link href="http://xudongyang.coding.me/tensorflow-feature-columns/"/>
    <id>http://xudongyang.coding.me/tensorflow-feature-columns/</id>
    <published>2018-08-09T08:39:10.000Z</published>
    <updated>2020-12-04T08:17:21.940Z</updated>
    
    <content type="html"><![CDATA[<p>特征工程是机器学习流程中重要的一个环节，即使是通常用来做端到端学习的深度学习模型在训练之前也免不了要做一些特征工程相关的工作。Tensorflow平台提供的FeatureColumn API为特征工程提供了强大的支持。</p><p>Feature cloumns是原始数据和Estimator模型之间的桥梁，它们被用来把各种形式的原始数据转换为模型能够使用的格式。深度神经网络只能处理数值数据，网络中的每个神经元节点执行一些针对输入数据和网络权重的乘法和加法运算。然而，现实中的有很多非数值的类别数据，比如产品的品牌、类目等，这些数据如果不加转换，神经网络是无法处理的。另一方面，即使是数值数据，在仍给网络进行训练之前有时也需要做一些处理，比如标准化、离散化等。</p><p><img src="https://www.tensorflow.org/images/feature_columns/inputs_to_model_bridge.jpg" alt><br><a id="more"></a><br>在Tensorflow中，通过调用<code>tf.feature_column</code>模块来创建feature columns。有两大类feature column，一类是生成dense tensor的Dense Column；另一类是生成sparse tensor的Categorical Column。具体地，目前tensorflow提供的feature columns如下图所示。</p><p><img src="https://www.tensorflow.org/images/feature_columns/some_constructors.jpg" alt="feature columns"></p><h2 id="Numeric-column"><a href="#Numeric-column" class="headerlink" title="Numeric column"></a>Numeric column</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.feature_column.numeric_column(</span><br><span class="line">    key,</span><br><span class="line">    shape&#x3D;(1,),</span><br><span class="line">    default_value&#x3D;None,</span><br><span class="line">    dtype&#x3D;tf.float32,</span><br><span class="line">    normalizer_fn&#x3D;None</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li>key: 特征的名字。也就是对应的列名称。</li><li>shape: 该key所对应的特征的shape. 默认是1，但是比如one-hot类型的，shape就不是1，而是实际的维度。总之，这里是key所对应的维度，不一定是1.</li><li>default_value: 如果不存在使用的默认值</li><li>normalizer_fn: 对该特征下的所有数据进行转换。如果需要进行normalize，那么就是使用normalize的函数.这里不仅仅局限于normalize，也可以是任何的转换方法，比如取对数，取指数，这仅仅是一种变换方法.</li></ul><p>创建numeric column的方法如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Represent a tf.float64 scalar.</span><br><span class="line">numeric_feature_column&#x3D;tf.feature_column.numeric_column(key&#x3D;&quot;SepalLength&quot;, dtype&#x3D;tf.float64)</span><br></pre></td></tr></table></figure><br>默认情况下，numeric column创建的是一个标量值，也可以指定shape参数来创建向量、矩阵等多维数据。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Represent a 10-element vector in which each cell contains a tf.float32.</span><br><span class="line">vector_feature_column &#x3D; tf.feature_column.numeric_column(key&#x3D;&quot;Bowling&quot;, shape&#x3D;10)</span><br><span class="line"></span><br><span class="line"># Represent a 10x5 matrix in which each cell contains a tf.float32.</span><br><span class="line">matrix_feature_column &#x3D; tf.feature_column.numeric_column(key&#x3D;&quot;MyMatrix&quot;, shape&#x3D;[10,5])</span><br></pre></td></tr></table></figure><br>我们还可以为numeric column指定数值变换的函数normalizer_fn，为对原始数据做一些变换操作。可以使用下面的代码测试numeric column的效果。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import feature_column</span><br><span class="line">from tensorflow.python.feature_column.feature_column import _LazyBuilder</span><br><span class="line"></span><br><span class="line">def test_numeric():</span><br><span class="line">    price &#x3D; &#123;&#39;price&#39;: [[1.], [2.], [3.], [4.]]&#125;  # 4行样本</span><br><span class="line">    builder &#x3D; _LazyBuilder(price)</span><br><span class="line"></span><br><span class="line">    def transform_fn(x):</span><br><span class="line">        return x + 2</span><br><span class="line"></span><br><span class="line">    price_column &#x3D; feature_column.numeric_column(&#39;price&#39;, normalizer_fn&#x3D;transform_fn)</span><br><span class="line">    price_transformed_tensor &#x3D; price_column._get_dense_tensor(builder)</span><br><span class="line">    with tf.Session() as session:</span><br><span class="line">        print(session.run([price_transformed_tensor]))</span><br><span class="line"></span><br><span class="line">    # 使用input_layer</span><br><span class="line">    price_transformed_tensor &#x3D; feature_column.input_layer(price, [price_column])</span><br><span class="line">    with tf.Session() as session:</span><br><span class="line">        print(&#39;use input_layer&#39; + &#39;_&#39; * 40)</span><br><span class="line">        print(session.run([price_transformed_tensor]))</span><br><span class="line"></span><br><span class="line">test_numeric()</span><br></pre></td></tr></table></figure><br>执行后的输出为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[array([[3.],</span><br><span class="line">       [4.],</span><br><span class="line">       [5.],</span><br><span class="line">       [6.]], dtype&#x3D;float32)]</span><br><span class="line">use input_layer________________________________________</span><br><span class="line">[array([[3.],</span><br><span class="line">       [4.],</span><br><span class="line">       [5.],</span><br><span class="line">       [6.]], dtype&#x3D;float32)]</span><br></pre></td></tr></table></figure></p><h2 id="Bucketized-column"><a href="#Bucketized-column" class="headerlink" title="Bucketized column"></a>Bucketized column</h2><p>Bucketized column用来把numeric column的值按照提供的边界（boundaries)离散化为多个值。离散化是特征工程常用的一种方法。例如，把年份离散化为4个阶段，如下图所示。</p><p><img src="https://www.tensorflow.org/images/feature_columns/bucketized_column.jpg" alt="year"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.feature_column.bucketized_column(</span><br><span class="line">    source_column,</span><br><span class="line">    boundaries</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li>source_column: 必须是numeric_column</li><li>boundaries: 不同的桶。boundaries=[0., 1., 2.],产生的bucket就是, (-inf, 0.), [0., 1.), [1., 2.), and [2., +inf), 每一个区间分别表示0, 1, 2, 3,所以相当于分桶分了4个.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># First, convert the raw input to a numeric column.</span><br><span class="line">numeric_feature_column &#x3D; tf.feature_column.numeric_column(&quot;Year&quot;)</span><br><span class="line"></span><br><span class="line"># Then, bucketize the numeric column on the years 1960, 1980, and 2000.</span><br><span class="line">bucketized_feature_column &#x3D; tf.feature_column.bucketized_column(</span><br><span class="line">    source_column &#x3D; numeric_feature_column,</span><br><span class="line">    boundaries &#x3D; [1960, 1980, 2000])</span><br></pre></td></tr></table></figure><p>按照上述代码，可以把Year字段离散化为下表所示的结果。</p><div class="table-container"><table><thead><tr><th>Date Range</th><th>Represented as…</th></tr></thead><tbody><tr><td>&lt; 1960</td><td>[1, 0, 0, 0]</td></tr><tr><td>>= 1960 but &lt; 1980</td><td>[0, 1, 0, 0]</td></tr><tr><td>>= 1980 but &lt; 2000</td><td>[0, 0, 1, 0]</td></tr><tr><td>>= 2000</td><td>[0, 0, 0, 1]</td></tr></tbody></table></div><p>我们可以进一步做一些测试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def test_bucketized_column():</span><br><span class="line">    price &#x3D; &#123;&#39;price&#39;: [[5.], [15.], [25.], [35.]]&#125;  # 4行样本</span><br><span class="line">    price_column &#x3D; feature_column.numeric_column(&#39;price&#39;)</span><br><span class="line">    bucket_price &#x3D; feature_column.bucketized_column(price_column, [10, 20, 30, 40])</span><br><span class="line">    price_bucket_tensor &#x3D; feature_column.input_layer(price, [bucket_price])</span><br><span class="line">    with tf.Session() as session:</span><br><span class="line">        print(session.run([price_bucket_tensor]))</span><br><span class="line"></span><br><span class="line">test_bucketized_column()</span><br></pre></td></tr></table></figure><br>测试结果为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[array([[1., 0., 0., 0., 0.],</span><br><span class="line">       [0., 1., 0., 0., 0.],</span><br><span class="line">       [0., 0., 1., 0., 0.],</span><br><span class="line">       [0., 0., 0., 1., 0.]], dtype&#x3D;float32)]</span><br></pre></td></tr></table></figure></p><h2 id="Categorical-identity-column"><a href="#Categorical-identity-column" class="headerlink" title="Categorical identity column"></a>Categorical identity column</h2><p>与Bucketized column类似，Categorical identity column用单个唯一值表示bucket。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Create categorical output for an integer feature named &quot;my_feature_b&quot;,</span><br><span class="line"># The values of my_feature_b must be &gt;&#x3D; 0 and &lt; num_buckets</span><br><span class="line">identity_feature_column &#x3D; tf.feature_column.categorical_column_with_identity(</span><br><span class="line">    key&#x3D;&#39;my_feature_b&#39;,</span><br><span class="line">    num_buckets&#x3D;4) # Values [0, 4)</span><br></pre></td></tr></table></figure><br>上述代码可以生成下图所示的效果。<br><img src="https://www.tensorflow.org/images/feature_columns/categorical_column_with_identity.jpg" alt></p><h2 id="Categorical-vocabulary-column"><a href="#Categorical-vocabulary-column" class="headerlink" title="Categorical vocabulary column"></a>Categorical vocabulary column</h2><p>顾名思义，Categorical vocabulary column把一个vocabulary中的string映射为数值型的类别特征，是做one-hot编码的很好的方法。在tensorflow中有两种提供词汇表的方法，一种是用list，另一种是用file，对应的feature column分别为：</p><ul><li>tf.feature_column.categorical_column_with_vocabulary_list</li><li>tf.feature_column.categorical_column_with_vocabulary_file</li></ul><p>两者的定义如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">    key,</span><br><span class="line">    vocabulary_list,</span><br><span class="line">    dtype&#x3D;None,</span><br><span class="line">    default_value&#x3D;-1,</span><br><span class="line">    num_oov_buckets&#x3D;0</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><ul><li>key: feature名字</li><li>vocabulary_list: 对于category来说，进行转换的list.也就是category列表.</li><li>dtype: 仅仅string和int被支持，其他的类型是无法进行这个操作的.</li><li>default_value: 当不在vocabulary_list中的默认值，这时候num_oov_buckets必须是0.</li><li>num_oov_buckets: 用来处理那些不在vocabulary_list中的值，如果是0，那么使用default_value进行填充;如果大于0，则会在[len(vocabulary_list), len(vocabulary_list)+num_oov_buckets]这个区间上重新计算当前特征的值.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.feature_column.categorical_column_with_vocabulary_file(</span><br><span class="line">    key,</span><br><span class="line">    vocabulary_file,</span><br><span class="line">    vocabulary_size&#x3D;None,</span><br><span class="line">    num_oov_buckets&#x3D;0,</span><br><span class="line">    default_value&#x3D;None,</span><br><span class="line">    dtype&#x3D;tf.string</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li>vocabulary_file: 存储词汇表的文件名</li><li>其他参数的含义与<code>tf.feature_column.categorical_column_with_vocabulary_list</code>相同</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Given input &quot;feature_name_from_input_fn&quot; which is a string,</span><br><span class="line"># create a categorical feature by mapping the input to one of</span><br><span class="line"># the elements in the vocabulary list.</span><br><span class="line">vocabulary_feature_column &#x3D;</span><br><span class="line">    tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        key&#x3D;feature_name_from_input_fn,</span><br><span class="line">        vocabulary_list&#x3D;[&quot;kitchenware&quot;, &quot;electronics&quot;, &quot;sports&quot;])</span><br></pre></td></tr></table></figure><p>上述代码得到的结果如下：<br><img src="https://www.tensorflow.org/images/feature_columns/categorical_column_with_vocabulary.jpg" alt></p><p>为了加深理解，进一步做一些测试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">def test_categorical_column_with_vocabulary_list():</span><br><span class="line">    color_data &#x3D; &#123;&#39;color&#39;: [[&#39;R&#39;, &#39;R&#39;], [&#39;G&#39;, &#39;R&#39;], [&#39;B&#39;, &#39;G&#39;], [&#39;A&#39;, &#39;A&#39;]]&#125;  # 4行样本</span><br><span class="line">    builder &#x3D; _LazyBuilder(color_data)</span><br><span class="line">    color_column &#x3D; feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        &#39;color&#39;, [&#39;R&#39;, &#39;G&#39;, &#39;B&#39;], dtype&#x3D;tf.string, default_value&#x3D;-1</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    color_column_tensor &#x3D; color_column._get_sparse_tensors(builder)</span><br><span class="line">    with tf.Session() as session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        session.run(tf.tables_initializer())</span><br><span class="line">        print(session.run([color_column_tensor.id_tensor]))</span><br><span class="line"></span><br><span class="line">    # 将稀疏的转换成dense，也就是one-hot形式，只是multi-hot</span><br><span class="line">    color_column_identy &#x3D; feature_column.indicator_column(color_column)</span><br><span class="line">    color_dense_tensor &#x3D; feature_column.input_layer(color_data, [color_column_identy])</span><br><span class="line">    with tf.Session() as session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        session.run(tf.tables_initializer())</span><br><span class="line">        print(&#39;use input_layer&#39; + &#39;_&#39; * 40)</span><br><span class="line">        print(session.run([color_dense_tensor]))</span><br><span class="line"></span><br><span class="line">test_categorical_column_with_vocabulary_list()</span><br></pre></td></tr></table></figure><br>注意:</p><ul><li>input_layer: 只接受dense tensor</li><li>tables_initializer: 在sparser的时候使用的，如果不进行初始化会出现 Table not initialized. [Node: hash_table_Lookup = LookupTableFindV2 这样的异常</li></ul><p>结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[SparseTensorValue(indices&#x3D;array([[0, 0],</span><br><span class="line">       [0, 1],</span><br><span class="line">       [1, 0],</span><br><span class="line">       [1, 1],</span><br><span class="line">       [2, 0],</span><br><span class="line">       [2, 1],</span><br><span class="line">       [3, 0],</span><br><span class="line">       [3, 1]], dtype&#x3D;int64), values&#x3D;array([ 0,  0,  1,  0,  2,  1, -1, -1], dtype&#x3D;int64), dense_shape&#x3D;array([4, 2], dtype&#x3D;int64))]</span><br><span class="line">use input_layer________________________________________</span><br><span class="line">[array([[2., 0., 0.],</span><br><span class="line">       [1., 1., 0.],</span><br><span class="line">       [0., 1., 1.],</span><br><span class="line">       [0., 0., 0.]], dtype&#x3D;float32)]</span><br></pre></td></tr></table></figure></p><h2 id="Hashed-Column"><a href="#Hashed-Column" class="headerlink" title="Hashed Column"></a>Hashed Column</h2><p>为类别特征提供词汇表有时候会过于繁琐，特别是在词汇表非常大的时候，词汇表会非常消耗内存。<code>tf.feature_column.categorical_column_with_hash_bucket</code>允许用户指定类别的总数，通过hash的方式来得到最终的类别ID。伪代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># pseudocode</span><br><span class="line">feature_id &#x3D; hash(raw_feature) % hash_buckets_size</span><br></pre></td></tr></table></figure><br>用hash的方式产生类别ID，不可避免地会遇到hash冲突的问题，即可有多多个原来不相同的类别会产生相同的类别ID。因此，设置hash_bucket_size参数会显得比较重要。实践表明，hash冲突不会对神经网络模型造成太大的影响，因为模型可以通过其他特征作进一步区分。</p><p><img src="https://www.tensorflow.org/images/feature_columns/hashed_column.jpg" alt></p><p>同样来做一些测试，看看最终效果。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def test_categorical_column_with_hash_bucket():</span><br><span class="line">    color_data &#x3D; &#123;&#39;color&#39;: [[2], [5], [-1], [0]]&#125;  # 4行样本</span><br><span class="line">    builder &#x3D; _LazyBuilder(color_data)</span><br><span class="line">    color_column &#x3D; feature_column.categorical_column_with_hash_bucket(&#39;color&#39;, 7, dtype&#x3D;tf.int32)</span><br><span class="line">    color_column_tensor &#x3D; color_column._get_sparse_tensors(builder)</span><br><span class="line">    with tf.Session() as session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        session.run(tf.tables_initializer())</span><br><span class="line">        print(session.run([color_column_tensor.id_tensor]))</span><br><span class="line"></span><br><span class="line">    # 将稀疏的转换成dense，也就是one-hot形式，只是multi-hot</span><br><span class="line">    color_column_identy &#x3D; feature_column.indicator_column(color_column)</span><br><span class="line">    color_dense_tensor &#x3D; feature_column.input_layer(color_data, [color_column_identy])</span><br><span class="line"></span><br><span class="line">    with tf.Session() as session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        session.run(tf.tables_initializer())</span><br><span class="line">        print(&#39;use input_layer&#39; + &#39;_&#39; * 40)</span><br><span class="line">        print(session.run([color_dense_tensor]))</span><br><span class="line"></span><br><span class="line">test_categorical_column_with_hash_bucket()</span><br></pre></td></tr></table></figure><br>运行结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[SparseTensorValue(indices&#x3D;array([[0, 0],</span><br><span class="line">       [1, 0],</span><br><span class="line">       [3, 0]], dtype&#x3D;int64), values&#x3D;array([5, 1, 2], dtype&#x3D;int64), dense_shape&#x3D;array([4, 1], dtype&#x3D;int64))]</span><br><span class="line">use input_layer________________________________________</span><br><span class="line">[array([[0., 0., 0., 0., 0., 1., 0.],</span><br><span class="line">       [0., 1., 0., 0., 0., 0., 0.],</span><br><span class="line">       [0., 0., 0., 0., 0., 0., 0.],</span><br><span class="line">       [0., 0., 1., 0., 0., 0., 0.]], dtype&#x3D;float32)]</span><br></pre></td></tr></table></figure><br>需要注意的是，使用hash bucket的时候，原始值中-1或者空字符串””会被忽略，不会输出结果。</p><h2 id="Crossed-column"><a href="#Crossed-column" class="headerlink" title="Crossed column"></a>Crossed column</h2><p>交叉组合特征也是一种很常用的特征工程手段，尤其是在使用LR模型时。Crossed column仅仅适用于sparser特征，产生的依然是sparsor特征。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.feature_column.crossed_column(</span><br><span class="line">    keys,</span><br><span class="line">    hash_bucket_size,</span><br><span class="line">    hash_key&#x3D;None</span><br><span class="line">)</span><br></pre></td></tr></table></figure><br>具体地，Crossed特征对keys的笛卡尔积执行hash操作，再把hash的结果对hash_bucket_size取模得到最终的结果：<code>Hash(cartesian product of features) % hash_bucket_size</code>。</p><p>测试代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def test_crossed_column():</span><br><span class="line">    &quot;&quot;&quot; crossed column测试 &quot;&quot;&quot;</span><br><span class="line">    featrues &#x3D; &#123;</span><br><span class="line">        &#39;price&#39;: [[&#39;A&#39;], [&#39;B&#39;], [&#39;C&#39;]],</span><br><span class="line">        &#39;color&#39;: [[&#39;R&#39;], [&#39;G&#39;], [&#39;B&#39;]]</span><br><span class="line">    &#125;</span><br><span class="line">    price &#x3D; feature_column.categorical_column_with_vocabulary_list(&#39;price&#39;, [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])</span><br><span class="line">    color &#x3D; feature_column.categorical_column_with_vocabulary_list(&#39;color&#39;, [&#39;R&#39;, &#39;G&#39;, &#39;B&#39;])</span><br><span class="line">    p_x_c &#x3D; feature_column.crossed_column([price, color], 16)</span><br><span class="line">    p_x_c_identy &#x3D; feature_column.indicator_column(p_x_c)</span><br><span class="line">    p_x_c_identy_dense_tensor &#x3D; feature_column.input_layer(featrues, [p_x_c_identy])</span><br><span class="line">    with tf.Session() as session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        session.run(tf.tables_initializer())</span><br><span class="line">        print(session.run([p_x_c_identy_dense_tensor]))</span><br><span class="line">test_crossed_column()</span><br></pre></td></tr></table></figure><br>结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],</span><br><span class="line">       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],</span><br><span class="line">       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],</span><br><span class="line">      dtype&#x3D;float32)]</span><br></pre></td></tr></table></figure></p><h2 id="Indicator-and-embedding-columns"><a href="#Indicator-and-embedding-columns" class="headerlink" title="Indicator and embedding columns"></a>Indicator and embedding columns</h2><p>Indicator columns 和 embedding columns 不能直接作用在原始特征上，而是作用在categorical columns上。</p><p>在前面的众多例子中，我们已经使用过indicator_column来把categorical column得到的稀疏tensor转换为one-hot或者multi-hot形式的稠密tensor，这里就不赘述了。</p><p>当某些特征的类别数量非常大时，使用indicator_column来把原始数据转换为神经网络的输入就变得非常不灵活，这时通常使用embedding column把原始特征映射为一个低维稠密的实数向量。同一类别的embedding向量间的距离通常可以用来度量类别直接的相似性。</p><p>Embedding column与indicator column之间的区别可以用下图表示。<br><img src="https://www.tensorflow.org/images/feature_columns/embedding_vs_indicator.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.feature_column.embedding_column(</span><br><span class="line">    categorical_column,</span><br><span class="line">    dimension,</span><br><span class="line">    combiner&#x3D;&#39;mean&#39;,</span><br><span class="line">    initializer&#x3D;None,</span><br><span class="line">    ckpt_to_load_from&#x3D;None,</span><br><span class="line">    tensor_name_in_ckpt&#x3D;None,</span><br><span class="line">    max_norm&#x3D;None,</span><br><span class="line">    trainable&#x3D;True</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li>categorical_column: 使用categoryical_column产生的sparsor column</li><li>dimension: 定义embedding的维数</li><li>combiner: 对于多个entries进行的推导。默认是meam, 但是 sqrtn在词袋模型中，有更好的准确度。</li><li>initializer: 初始化方法，默认使用高斯分布来初始化。</li><li>tensor_name_in_ckpt: 可以从check point中恢复</li><li>ckpt_to_load_from: check point file，这是在 tensor_name_in_ckpt 不为空的情况下设置的.</li><li>max_norm: 默认是l2</li><li>trainable: 是否可训练的，默认是true</li></ul><p>测试代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def test_embedding():</span><br><span class="line">    tf.set_random_seed(1)</span><br><span class="line">    color_data &#x3D; &#123;&#39;color&#39;: [[&#39;R&#39;, &#39;G&#39;], [&#39;G&#39;, &#39;A&#39;], [&#39;B&#39;, &#39;B&#39;], [&#39;A&#39;, &#39;A&#39;]]&#125;  # 4行样本</span><br><span class="line">    builder &#x3D; _LazyBuilder(color_data)</span><br><span class="line">    color_column &#x3D; feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        &#39;color&#39;, [&#39;R&#39;, &#39;G&#39;, &#39;B&#39;], dtype&#x3D;tf.string, default_value&#x3D;-1</span><br><span class="line">    )</span><br><span class="line">    color_column_tensor &#x3D; color_column._get_sparse_tensors(builder)</span><br><span class="line"></span><br><span class="line">    color_embeding &#x3D; feature_column.embedding_column(color_column, 4, combiner&#x3D;&#39;sum&#39;)</span><br><span class="line">    color_embeding_dense_tensor &#x3D; feature_column.input_layer(color_data, [color_embeding])</span><br><span class="line"></span><br><span class="line">    with tf.Session() as session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        session.run(tf.tables_initializer())</span><br><span class="line">        print(session.run([color_column_tensor.id_tensor]))</span><br><span class="line">        print(&#39;embeding&#39; + &#39;_&#39; * 40)</span><br><span class="line">        print(session.run([color_embeding_dense_tensor]))</span><br><span class="line"></span><br><span class="line">test_embedding()</span><br></pre></td></tr></table></figure><br>测试结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[SparseTensorValue(indices&#x3D;array([[0, 0],</span><br><span class="line">       [0, 1],</span><br><span class="line">       [1, 0],</span><br><span class="line">       [1, 1],</span><br><span class="line">       [2, 0],</span><br><span class="line">       [2, 1],</span><br><span class="line">       [3, 0],</span><br><span class="line">       [3, 1]], dtype&#x3D;int64), values&#x3D;array([ 0,  1,  1, -1,  2,  2, -1, -1], dtype&#x3D;int64), dense_shape&#x3D;array([4, 2], dtype&#x3D;int64))]</span><br><span class="line">embeding________________________________________</span><br><span class="line">[array([[-0.8339818 , -0.4975947 ,  0.09368954,  0.16094571],</span><br><span class="line">       [-0.6342659 , -0.19216162,  0.18877633,  0.17648602],</span><br><span class="line">       [ 1.5531666 ,  0.27847385,  0.12863553,  1.2628161 ],</span><br><span class="line">       [ 0.        ,  0.        ,  0.        ,  0.        ]],</span><br><span class="line">      dtype&#x3D;float32)]</span><br></pre></td></tr></table></figure><br>从上面的测试结果可以看出不在vocabulary里的数据’A’在经过<code>categorical_column_with_vocabulary_list</code>操作时映射为默认值-1，而<strong>默认值-1在embeding column时映射为0向量</strong>，这是一个很有用的特性，可以用-1来填充一个不定长的ID序列，这样可以得到定长的序列，然后经过embedding column之后，填充的-1值不影响原来的结果。在下一篇文章中，我会通过一个例子来演示这个特性。</p><p>有时候在同一个网络模型中，有多个特征可能需要共享相同的embeding映射空间，比如用户历史行为序列中的商品ID和候选商品ID，这时候可以用到<code>tf.feature_column.shared_embedding_columns</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.feature_column.shared_embedding_columns(</span><br><span class="line">    categorical_columns,</span><br><span class="line">    dimension,</span><br><span class="line">    combiner&#x3D;&#39;mean&#39;,</span><br><span class="line">    initializer&#x3D;None,</span><br><span class="line">    shared_embedding_collection_name&#x3D;None,</span><br><span class="line">    ckpt_to_load_from&#x3D;None,</span><br><span class="line">    tensor_name_in_ckpt&#x3D;None,</span><br><span class="line">    max_norm&#x3D;None,</span><br><span class="line">    trainable&#x3D;True</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li>categorical_columns 为需要共享embeding映射空间的类别特征列表</li><li>其他参数与embedding column类似</li></ul><p>测试代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">def test_shared_embedding_column_with_hash_bucket():</span><br><span class="line">    color_data &#x3D; &#123;&#39;color&#39;: [[2, 2], [5, 5], [0, -1], [0, 0]],</span><br><span class="line">                  &#39;color2&#39;: [[2], [5], [-1], [0]]&#125;  # 4行样本</span><br><span class="line">    builder &#x3D; _LazyBuilder(color_data)</span><br><span class="line">    color_column &#x3D; feature_column.categorical_column_with_hash_bucket(&#39;color&#39;, 7, dtype&#x3D;tf.int32)</span><br><span class="line">    color_column_tensor &#x3D; color_column._get_sparse_tensors(builder)</span><br><span class="line">    color_column2 &#x3D; feature_column.categorical_column_with_hash_bucket(&#39;color2&#39;, 7, dtype&#x3D;tf.int32)</span><br><span class="line">    color_column_tensor2 &#x3D; color_column2._get_sparse_tensors(builder)</span><br><span class="line">    with tf.Session() as session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        session.run(tf.tables_initializer())</span><br><span class="line">        print(&#39;not use input_layer&#39; + &#39;_&#39; * 40)</span><br><span class="line">        print(session.run([color_column_tensor.id_tensor]))</span><br><span class="line">        print(session.run([color_column_tensor2.id_tensor]))</span><br><span class="line"></span><br><span class="line">    # 将稀疏的转换成dense，也就是one-hot形式，只是multi-hot</span><br><span class="line">    color_column_embed &#x3D; feature_column.shared_embedding_columns([color_column2, color_column], 3, combiner&#x3D;&#39;sum&#39;)</span><br><span class="line">    print(type(color_column_embed))</span><br><span class="line">    color_dense_tensor &#x3D; feature_column.input_layer(color_data, color_column_embed)</span><br><span class="line"></span><br><span class="line">    with tf.Session() as session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        session.run(tf.tables_initializer())</span><br><span class="line">        print(&#39;use input_layer&#39; + &#39;_&#39; * 40)</span><br><span class="line">        print(session.run(color_dense_tensor))</span><br><span class="line"></span><br><span class="line">test_shared_embedding_column_with_hash_bucket()</span><br></pre></td></tr></table></figure><br>测试结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">not use input_layer________________________________________</span><br><span class="line">[SparseTensorValue(indices&#x3D;array([[0, 0],</span><br><span class="line">       [0, 1],</span><br><span class="line">       [1, 0],</span><br><span class="line">       [1, 1],</span><br><span class="line">       [2, 0],</span><br><span class="line">       [3, 0],</span><br><span class="line">       [3, 1]], dtype&#x3D;int64), values&#x3D;array([5, 5, 1, 1, 2, 2, 2], dtype&#x3D;int64), dense_shape&#x3D;array([4, 2], dtype&#x3D;int64))]</span><br><span class="line">[SparseTensorValue(indices&#x3D;array([[0, 0],</span><br><span class="line">       [1, 0],</span><br><span class="line">       [3, 0]], dtype&#x3D;int64), values&#x3D;array([5, 1, 2], dtype&#x3D;int64), dense_shape&#x3D;array([4, 1], dtype&#x3D;int64))]</span><br><span class="line">&lt;class &#39;list&#39;&gt;</span><br><span class="line">use input_layer________________________________________</span><br><span class="line">[[ 0.37802923 -0.27973637  0.11547407  0.75605845 -0.55947274  0.23094814]</span><br><span class="line"> [-0.5264772   0.86587846 -0.36023238 -1.0529544   1.7317569  -0.72046477]</span><br><span class="line"> [ 0.          0.          0.         -0.9269535  -0.17690836  0.42011076]</span><br><span class="line"> [-0.9269535  -0.17690836  0.42011076 -1.853907   -0.35381672  0.8402215 ]]</span><br></pre></td></tr></table></figure><br>需要注意的是，<strong><code>tf.feature_column.shared_embedding_columns</code>的返回值是一个与参数categorical_columns维数相同的列表</strong>。</p><h2 id="Weighted-categorical-column"><a href="#Weighted-categorical-column" class="headerlink" title="Weighted categorical column"></a>Weighted categorical column</h2><p>有时候我们需要给一个类别特征赋予一定的权重，比如给用户行为序列按照行为发生的时间到某个特定时间的差来计算不同的权重，这是可以用到weighted_categorical_column。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.feature_column.weighted_categorical_column(</span><br><span class="line">    categorical_column,</span><br><span class="line">    weight_feature_key,</span><br><span class="line">    dtype&#x3D;tf.float32</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><p>测试代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def test_weighted_categorical_column():</span><br><span class="line">    color_data &#x3D; &#123;&#39;color&#39;: [[&#39;R&#39;], [&#39;G&#39;], [&#39;B&#39;], [&#39;A&#39;]],</span><br><span class="line">                  &#39;weight&#39;: [[1.0], [2.0], [4.0], [8.0]]&#125;  # 4行样本</span><br><span class="line">    color_column &#x3D; feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        &#39;color&#39;, [&#39;R&#39;, &#39;G&#39;, &#39;B&#39;], dtype&#x3D;tf.string, default_value&#x3D;-1</span><br><span class="line">    )</span><br><span class="line">    color_weight_categorical_column &#x3D; feature_column.weighted_categorical_column(color_column, &#39;weight&#39;)</span><br><span class="line">    builder &#x3D; _LazyBuilder(color_data)</span><br><span class="line">    with tf.Session() as session:</span><br><span class="line">        id_tensor, weight &#x3D; color_weight_categorical_column._get_sparse_tensors(builder)</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        session.run(tf.tables_initializer())</span><br><span class="line">        print(&#39;weighted categorical&#39; + &#39;-&#39; * 40)</span><br><span class="line">        print(session.run([id_tensor]))</span><br><span class="line">        print(&#39;-&#39; * 40)</span><br><span class="line">        print(session.run([weight]))</span><br><span class="line">test_weighted_categorical_column()</span><br></pre></td></tr></table></figure><br>测试结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">weighted categorical----------------------------------------</span><br><span class="line">[SparseTensorValue(indices&#x3D;array([[0, 0],</span><br><span class="line">       [1, 0],</span><br><span class="line">       [2, 0],</span><br><span class="line">       [3, 0]], dtype&#x3D;int64), values&#x3D;array([ 0,  1,  2, -1], dtype&#x3D;int64), dense_shape&#x3D;array([4, 1], dtype&#x3D;int64))]</span><br><span class="line">----------------------------------------</span><br><span class="line">[SparseTensorValue(indices&#x3D;array([[0, 0],</span><br><span class="line">       [1, 0],</span><br><span class="line">       [2, 0],</span><br><span class="line">       [3, 0]], dtype&#x3D;int64), values&#x3D;array([1., 2., 4., 8.], dtype&#x3D;float32), dense_shape&#x3D;array([4, 1], dtype&#x3D;int64))]</span><br></pre></td></tr></table></figure><br>可以看到，相对于前面其他categorical_column来说多了weight这个tensor。weighted_categorical_column的一个用例就是，<strong>weighted_categorical_column的结果传入给shared_embedding_columns可以对ID序列的embeding向量做加权融合</strong>。限于篇幅的原因，完整的使用案例请期待下一篇博文。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.tensorflow.org/guide/feature_columns?hl=zh-cn">https://www.tensorflow.org/guide/feature_columns?hl=zh-cn</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;特征工程是机器学习流程中重要的一个环节，即使是通常用来做端到端学习的深度学习模型在训练之前也免不了要做一些特征工程相关的工作。Tensorflow平台提供的FeatureColumn API为特征工程提供了强大的支持。&lt;/p&gt;
&lt;p&gt;Feature cloumns是原始数据和Estimator模型之间的桥梁，它们被用来把各种形式的原始数据转换为模型能够使用的格式。深度神经网络只能处理数值数据，网络中的每个神经元节点执行一些针对输入数据和网络权重的乘法和加法运算。然而，现实中的有很多非数值的类别数据，比如产品的品牌、类目等，这些数据如果不加转换，神经网络是无法处理的。另一方面，即使是数值数据，在仍给网络进行训练之前有时也需要做一些处理，比如标准化、离散化等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tensorflow.org/images/feature_columns/inputs_to_model_bridge.jpg&quot; alt&gt;&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="tensorflow" scheme="http://xudongyang.coding.me/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>基于Tensorflow高阶API构建大规模分布式深度学习模型系列之自定义Estimator（以文本分类CNN模型为例）</title>
    <link href="http://xudongyang.coding.me/tensorflow-word-cnn/"/>
    <id>http://xudongyang.coding.me/tensorflow-word-cnn/</id>
    <published>2018-08-07T06:08:44.000Z</published>
    <updated>2020-12-04T08:17:21.941Z</updated>
    
    <content type="html"><![CDATA[<p>Tensorflow在1.4版本中引入了<code>tf.estimator.train_and_evaluate</code>函数，用来替换老版中Experiment类提供的功能。<code>tf.estimator.train_and_evaluate</code>简化了训练、评估和导出Estimator模型的过程，抽象了模型分布式训练和评估的细节，使得同样的代码在本地与分布式集群上的行为一致。</p><p>这意味着使用<code>train_and_evaluate</code> API，我们可以在本地和分布式集群上、不同的设备和硬件上跑同样的代码，而不需要修改代码已适应不同的部署环境。而且训练之后的模型可以很方便地导出以便在打分服务（tensorflow serving）中使用。</p><p>本文简要介绍如何自定义Estimator模型并通过使用<code>tf.estimator.train_and_evaluate</code>完成训练和评估。</p><p>主要步骤：</p><ol><li>构建自己的Estimator模型</li><li>定义在训练和测试过程中数据如何输入给模型</li><li>定义传递给<code>tf.estimator.train_and_evaluate</code>函数的训练、评估和导出的详述参数(TrainSpec and EvalSpec)</li><li>使用<code>tf.estimator.train_and_evaluate</code>训练并评估模型</li></ol><a id="more"></a><h2 id="文本分类任务"><a href="#文本分类任务" class="headerlink" title="文本分类任务"></a>文本分类任务</h2><p>在介绍详细的模型开发步骤之前，先看一下我们要完成的作品的目标：文本分类。文本分类在很多场景都有应用，这里就不详述了。</p><p>我们使用的数据集是《<a href="https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz">DBPedia Ontology Classification Dataset</a>》(可点击下载)，是从数据集DBpedia 2014中挑选的14个类别的互不重叠的本体（Company, EducationalInstitution, Artist, Athlete, OfficeHolder, MeanOfTransportation, Building, NaturalPlace, Village, Animal, Plant, Album, Film, WrittenWork），每个本体类别随机选择了40,000 个训练样本和5,000个测试样本。因此，总共有560,000个训练样本和70,000个测试样本。</p><blockquote><p>The files train.csv and test.csv contain all the training samples as comma-sparated values. There are 3 columns in them, corresponding to class index (1 to 14), title and content. The title and content are escaped using double quotes (“), and any internal double quote is escaped by 2 double quotes (“”). There are no new lines in title or content.</p></blockquote><p>在训练过程了，我们丢弃了title字段，仅使用content字段的内容去拟合类标签。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>文本实现一种基于CNN网络的文本分类模型，该模型由Yoon Kim在论文《<a href="https://arxiv.org/abs/1408.5882">Convolutional Neural Networks for Sentence Classification</a>》中提出，网络结构如下图所示。</p><p><img src="/tensorflow-word-cnn/arch.png" alt="img"></p><p>具体地，网络的输入层为一个定长为$n$的句子（不定长的句子用固定的tokenerm填充），句子中的每个词经过embedding层映射为一个$m$维的实数向量，这样每个句子就转换为一个二维的$n \times m$的矩阵。</p><p>然后在此矩阵上应用多个不同大小的卷积操作，得到多个特征映射（feature map）。例如，一个窗口大小为$h \times m$的卷积过滤器$w \in R^{hm}$作用在包含$h$个词向量的窗口上，得到一个新的特征$c_i=f(w \cdot x_{i:i+h-1} + b)$，其中$b$是偏重，$f$是一个非线性函数，比如tanh函数。该卷积过滤器作用在当前句子对应的每一个可能的词向量窗口$\{x_{1:h},x_{2:h+1}, \cdots, x_{n-h+1:n} \}$上，得到一个特征映射${\bf {c}}=[ c_1, c_2, \cdots, c_{n-h+1} ]$ 。</p><p>网络会同时应用多个不同size $h$的卷积操作，这样就能得到多组特征映射，每组特征的维数为$R^{n-h+1}$。假设一共有$k$组特征映射。接着在每组特征映射上执行一个最大池化操作（max-overtime<br>pooling operation），即$\hat{c}=max\{ {\bf {c}} \}$。最大池化操作用来捕捉每一组特征映射中最重要的特征，同时使得不同size的特征映射塌陷到一个固定维数为1的特征上。这样$k$组特征映射就映射到一个$k$维的特征表示向量上。</p><p>最后，经过了前面的embedding层，卷积层，池化层之后，再接几个全连接层，这样网络结构就完整了。</p><p><img src="/tensorflow-word-cnn/word_cnn.png" alt="tensorboard"></p><h2 id="构建Estimator"><a href="#构建Estimator" class="headerlink" title="构建Estimator"></a>构建Estimator</h2><p>Tensorflow的Estimator类提供了分布式模型训练和评估的内置支持，屏蔽了不同底层硬件平台（CPU、GPU、TPU）的差异。因此，建议大家总是使用Estimator来封装自己的模型。Tensorflow还提供了一些“Pre-made”的Estimator的子类可以用来高效地创建一些常用的标准模型，比如常用的“wide and deep”模型就可以用<code>DNNLinearCombinedClassifier</code>来创建。</p><p>Estimator的核心是模型函数（model function），模型函数构建训练、评估和预测用的计算图。当使用pre-made的Estimator时，模型函数已经为我们实现好了。当我们使用自定义的Estimator来创建自己的模型时，最重要的工作就是编写自己的模型函数。</p><p>模型函数的签名如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def my_model_fn(</span><br><span class="line">   features, # This is batch_features from input_fn</span><br><span class="line">   labels,   # This is batch_labels from input_fn</span><br><span class="line">   mode,     # An instance of tf.estimator.ModeKeys</span><br><span class="line">   params):  # Additional configuration</span><br></pre></td></tr></table></figure></p><p>前两个参数是输入函数(input_fn)返回的特性和标签，mode参数表明调用者是在训练、预测还是评估，params是其他一些自定义参数，通常是一个dict。</p><div class="table-container"><table><thead><tr><th>Estimator method</th><th>Estimator Mode</th></tr></thead><tbody><tr><td>train()</td><td>ModeKeys.TRAIN</td></tr><tr><td>evaluate()</td><td>ModeKeys.EVAL</td></tr><tr><td>predict()</td><td>ModeKeys.PREDICT</td></tr></tbody></table></div><p>在模型函数内部，需要定义网络对应的计算图（graph)，并为模型在三个不同的阶段（训练、评估、预测）指定额外的操作，通过EstimatorSpec对象返回。</p><p>在训练阶段返回的EstimatorSpec对象需要包含计算loss和最小化loss的操作（op）；在评估阶段返回的EstimatorSpec对象需要包含计算metrics的操作，已经跟模型导出有个的操作；在预测阶段返回的EstimatorSpec对象需要包含跟获取预测结果有个的操作。具体如何定义这些EstimatorSpec对象可以参考<a href="https://www.tensorflow.org/guide/custom_estimators?hl=zh-cn">官方文档</a>。</p><p>通常情况下，自己定义不同阶段的EstimatorSpec对象比较麻烦，这时可以用到另一个高阶API Head来帮忙简化开发任务。</p><p>我们的整个模型函数的代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">def my_model(features, labels, mode, params):</span><br><span class="line">  sentence &#x3D; features[&#39;sentence&#39;]</span><br><span class="line">  # Get word embeddings for each token in the sentence</span><br><span class="line">  embeddings &#x3D; tf.get_variable(name&#x3D;&quot;embeddings&quot;, dtype&#x3D;tf.float32,</span><br><span class="line">                               shape&#x3D;[params[&quot;vocab_size&quot;], FLAGS.embedding_size])</span><br><span class="line">  sentence &#x3D; tf.nn.embedding_lookup(embeddings, sentence) # shape:(batch, sentence_len, embedding_size)</span><br><span class="line">  # add a channel dim, required by the conv2d and max_pooling2d method</span><br><span class="line">  sentence &#x3D; tf.expand_dims(sentence, -1) # shape:(batch, sentence_len&#x2F;height, embedding_size&#x2F;width, channels&#x3D;1)</span><br><span class="line"></span><br><span class="line">  pooled_outputs &#x3D; []</span><br><span class="line">  for filter_size in params[&quot;filter_sizes&quot;]:</span><br><span class="line">      conv &#x3D; tf.layers.conv2d(</span><br><span class="line">          sentence,</span><br><span class="line">          filters&#x3D;FLAGS.num_filters,</span><br><span class="line">          kernel_size&#x3D;[filter_size, FLAGS.embedding_size],</span><br><span class="line">          strides&#x3D;(1, 1),</span><br><span class="line">          padding&#x3D;&quot;VALID&quot;,</span><br><span class="line">          activation&#x3D;tf.nn.relu)</span><br><span class="line">      pool &#x3D; tf.layers.max_pooling2d(</span><br><span class="line">          conv,</span><br><span class="line">          pool_size&#x3D;[FLAGS.sentence_max_len - filter_size + 1, 1],</span><br><span class="line">          strides&#x3D;(1, 1),</span><br><span class="line">          padding&#x3D;&quot;VALID&quot;)</span><br><span class="line">      pooled_outputs.append(pool)</span><br><span class="line">  h_pool &#x3D; tf.concat(pooled_outputs, 3) # shape: (batch, 1, len(filter_size) * embedding_size, 1)</span><br><span class="line">  h_pool_flat &#x3D; tf.reshape(h_pool, [-1, FLAGS.num_filters * len(params[&quot;filter_sizes&quot;])]) # shape: (batch, len(filter_size) * embedding_size)</span><br><span class="line">  if &#39;dropout_rate&#39; in params and params[&#39;dropout_rate&#39;] &gt; 0.0:</span><br><span class="line">    h_pool_flat &#x3D; tf.layers.dropout(h_pool_flat, params[&#39;dropout_rate&#39;], training&#x3D;(mode &#x3D;&#x3D; tf.estimator.ModeKeys.TRAIN))</span><br><span class="line">  logits &#x3D; tf.layers.dense(h_pool_flat, FLAGS.num_classes, activation&#x3D;None)</span><br><span class="line"></span><br><span class="line">  optimizer &#x3D; tf.train.AdagradOptimizer(learning_rate&#x3D;params[&#39;learning_rate&#39;])</span><br><span class="line">  def _train_op_fn(loss):</span><br><span class="line">    return optimizer.minimize(loss, global_step&#x3D;tf.train.get_global_step())</span><br><span class="line"></span><br><span class="line">  my_head &#x3D; tf.contrib.estimator.multi_class_head(n_classes&#x3D;FLAGS.num_classes)</span><br><span class="line">  return my_head.create_estimator_spec(</span><br><span class="line">    features&#x3D;features,</span><br><span class="line">    mode&#x3D;mode,</span><br><span class="line">    labels&#x3D;labels,</span><br><span class="line">    logits&#x3D;logits,</span><br><span class="line">    train_op_fn&#x3D;_train_op_fn</span><br><span class="line">  )</span><br></pre></td></tr></table></figure></p><h2 id="定义输入流-input-pipeline"><a href="#定义输入流-input-pipeline" class="headerlink" title="定义输入流 input pipeline"></a>定义输入流 input pipeline</h2><p>在Tensorflow中定义网络输入推荐使用<a href="https://zhuanlan.zhihu.com/p/38421397">Dataset API</a>。</p><p>在本文的文本分类任务中，原始训练数据的格式在前面已经介绍过，每一行是逗号分隔的3列的csv格式的数据。第一列是类标签，第三列是我们用来作为输入的句子。首先我们需要做一下预处理，把特殊符号和一些非字母类的其他文本内容去掉，然后构建完整的词汇表。词汇表用来把词映射到唯一的一个数字ID。在处理输入的过程中，我们需要依赖词到ID的映射来处理原始输入。最终构建的训练样本的形式为&lt;[word_id list], class_label&gt;。</p><p>输入函数的代码如下，完整的代码请访问github。输入函数中，我们使用了<code>tf.contrib.lookup.index_table_from_file</code>函数来负责把词汇表映射到唯一的ID。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def input_fn(path_csv, path_vocab, shuffle_buffer_size, num_oov_buckets):</span><br><span class="line">  vocab &#x3D; tf.contrib.lookup.index_table_from_file(path_vocab, num_oov_buckets&#x3D;num_oov_buckets)</span><br><span class="line">  # Load csv file, one example per line</span><br><span class="line">  dataset &#x3D; tf.data.TextLineDataset(path_csv)</span><br><span class="line">  # Convert line into list of tokens, splitting by white space; then convert each token to an unique id</span><br><span class="line">  dataset &#x3D; dataset.map(lambda line: parse_line(line, vocab))</span><br><span class="line">  if shuffle_buffer_size &gt; 0:</span><br><span class="line">    dataset &#x3D; dataset.shuffle(shuffle_buffer_size).repeat()</span><br><span class="line">  dataset &#x3D; dataset.batch(FLAGS.batch_size).prefetch(1)</span><br><span class="line">  return dataset</span><br></pre></td></tr></table></figure><h2 id="模型的训练"><a href="#模型的训练" class="headerlink" title="模型的训练"></a>模型的训练</h2><p>定义好模型函数与输入函数之后，就可以用Estimator封装好分类器。同时需要定义estimator需要的TrainSpec和EvalSpec，把训练数据和评估数据喂给模型，这样就万事俱备了，最后只需要调用<code>tf.estimator.train_and_evaluate</code>就可以开始训练和评估模型了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">classifier &#x3D; tf.estimator.Estimator(</span><br><span class="line">  model_fn&#x3D;my_model,</span><br><span class="line">  params&#x3D;&#123;</span><br><span class="line">    &#39;vocab_size&#39;: config[&quot;vocab_size&quot;],</span><br><span class="line">    &#39;filter_sizes&#39;: map(int, FLAGS.filter_sizes.split(&#39;,&#39;)),</span><br><span class="line">    &#39;learning_rate&#39;: FLAGS.learning_rate,</span><br><span class="line">    &#39;dropout_rate&#39;: FLAGS.dropout_rate</span><br><span class="line">  &#125;,</span><br><span class="line">  config&#x3D;tf.estimator.RunConfig(model_dir&#x3D;FLAGS.model_dir, save_checkpoints_steps&#x3D;FLAGS.save_checkpoints_steps)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_spec &#x3D; tf.estimator.TrainSpec(</span><br><span class="line">  input_fn&#x3D;lambda: input_fn(path_train, path_words, FLAGS.shuffle_buffer_size, config[&quot;num_oov_buckets&quot;]),</span><br><span class="line">  max_steps&#x3D;FLAGS.train_steps</span><br><span class="line">)</span><br><span class="line">input_fn_for_eval &#x3D; lambda: input_fn(path_eval, path_words, 0, config[&quot;num_oov_buckets&quot;])</span><br><span class="line">eval_spec &#x3D; tf.estimator.EvalSpec(input_fn&#x3D;input_fn_for_eval, throttle_secs&#x3D;300)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文以文本分类任务为例，详细介绍了如何创建一个基于Estimator接口的tensorflow模型，并使用<code>tf.estimator.train_and_evaluate</code>来完成模型训练和评估的完整过程。</p><p>完整源代码链接：<a href="https://github.com/yangxudong/deeplearning/tree/master/word_cnn">yangxudong/deeplearning</a></p><p>论文《Convolutional Neural Networks for Sentence Classification》下载地址：<a href="https://arxiv.org/abs/1408.5882">https://arxiv.org/abs/1408.5882</a></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://cloud.google.com/blog/products/gcp/easy-distributed-training-with-tensorflow-using-tfestimatortrain-and-evaluate-on-cloud-ml-engine">Easy distributed training with TensorFlow using tf.estimator.train_and_evaluate on Cloud ML Engine</a></li><li><a href="https://www.tensorflow.org/guide/custom_estimators?hl=zh-cn">Tensorflow官方文档： Creating Custom Estimators</a></li></ol><h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/38470806">基于Tensorflow高阶API构建大规模分布式深度学习模型系列: 开篇</a></li><li><a href="https://zhuanlan.zhihu.com/p/38421397">基于Tensorflow高阶API构建大规模分布式深度学习模型系列：基于Dataset API处理Input pipeline</a></li><li><a href="https://zhuanlan.zhihu.com/p/41473323">基于Tensorflow高阶API构建大规模分布式深度学习模型系列: 自定义Estimator（以文本分类CNN模型为例）</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;Tensorflow在1.4版本中引入了&lt;code&gt;tf.estimator.train_and_evaluate&lt;/code&gt;函数，用来替换老版中Experiment类提供的功能。&lt;code&gt;tf.estimator.train_and_evaluate&lt;/code&gt;简化了训练、评估和导出Estimator模型的过程，抽象了模型分布式训练和评估的细节，使得同样的代码在本地与分布式集群上的行为一致。&lt;/p&gt;
&lt;p&gt;这意味着使用&lt;code&gt;train_and_evaluate&lt;/code&gt; API，我们可以在本地和分布式集群上、不同的设备和硬件上跑同样的代码，而不需要修改代码已适应不同的部署环境。而且训练之后的模型可以很方便地导出以便在打分服务（tensorflow serving）中使用。&lt;/p&gt;
&lt;p&gt;本文简要介绍如何自定义Estimator模型并通过使用&lt;code&gt;tf.estimator.train_and_evaluate&lt;/code&gt;完成训练和评估。&lt;/p&gt;
&lt;p&gt;主要步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;构建自己的Estimator模型&lt;/li&gt;
&lt;li&gt;定义在训练和测试过程中数据如何输入给模型&lt;/li&gt;
&lt;li&gt;定义传递给&lt;code&gt;tf.estimator.train_and_evaluate&lt;/code&gt;函数的训练、评估和导出的详述参数(TrainSpec and EvalSpec)&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;tf.estimator.train_and_evaluate&lt;/code&gt;训练并评估模型&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="tensorflow" scheme="http://xudongyang.coding.me/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>基于Tensorflow高阶API构建大规模分布式深度学习模型系列:基于Dataset API处理Input pipeline</title>
    <link href="http://xudongyang.coding.me/tensorflow-dataset/"/>
    <id>http://xudongyang.coding.me/tensorflow-dataset/</id>
    <published>2018-07-08T02:23:02.000Z</published>
    <updated>2020-12-04T08:17:21.939Z</updated>
    
    <content type="html"><![CDATA[<p>在TensorFlow 1.3版本之前，读取数据一般有两种方法：</p><ul><li>使用placeholder + feed_dict读内存中的数据</li><li>使用文件名队列（string_input_producer）与内存队列（reader）读硬盘中的数据</li></ul><p>Dataset API同时支持从内存和硬盘的数据读取，相比之前的两种方法在语法上更加简洁易懂。Dataset API可以更方便地与其他高阶API配合，快速搭建网络模型。此外，如果想要用到TensorFlow新出的Eager模式，就必须要使用Dataset API来读取数据。</p><p><strong>Dataset可以看作是相同类型“元素”的有序列表</strong>。在实际使用时，单个“元素”可以是向量，也可以是字符串、图片，甚至是tuple或者dict。</p><a id="more"></a><h3 id="从内存中读取数据"><a href="#从内存中读取数据" class="headerlink" title="从内存中读取数据"></a>从内存中读取数据</h3><p>用tf.data.Dataset.from_tensor_slices创建了一个最简单的Dataset：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">dataset &#x3D; tf.data.Dataset.from_tensor_slices(np.array([1.0, 2.0, 3.0, 4.0, 5.0]))</span><br></pre></td></tr></table></figure><br>如何将这个dataset中的元素取出呢？方法是从Dataset中实例化一个Iterator，然后对Iterator进行迭代。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">iterator &#x3D; dataset.make_one_shot_iterator()</span><br><span class="line">one_element &#x3D; iterator.get_next()</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    for i in range(5):</span><br><span class="line">        print(sess.run(one_element))</span><br></pre></td></tr></table></figure><br>由于Tensorflow采用了符号式编程（symbolic style programs）模式，而非常见的命令式编程（imperative style programs）模式，因此必须创建一个Session对象才能运行程序。上述代码中，one_element只是一个Tensor，并不是一个实际的值。调用sess.run(one_element)后，才能真正地取出一个值。如果一个dataset中元素被读取完了，再尝试sess.run(one_element)的话，就会抛出tf.errors.OutOfRangeError异常，这个行为与使用队列方式读取数据的行为是一致的。</p><p>其实，<strong>tf.data.Dataset.from_tensor_slices的功能不止如此，它的真正作用是切分传入Tensor的第一个维度，生成相应的dataset</strong>。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset &#x3D; tf.data.Dataset.from_tensor_slices(np.random.uniform(size&#x3D;(5, 2)))</span><br></pre></td></tr></table></figure><br>传入的数值是一个矩阵，它的形状为(5, 2)，tf.data.Dataset.from_tensor_slices就会切分它形状上的第一个维度，最后生成的dataset中一个含有5个元素，每个元素的形状是(2, )，即每个元素是矩阵的一行。</p><p>下面我们来看看如何从Dict中构建dataset:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataset &#x3D; tf.data.Dataset.from_tensor_slices(</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;a&quot;: np.array([1.0, 2.0, 3.0, 4.0, 5.0]),</span><br><span class="line">        &quot;b&quot;: np.random.uniform(size&#x3D;(5, 2))</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><br>这时函数会分别切分”a”中的数值以及”b”中的数值，最终dataset中的一个元素就是类似于{“a”: 1.0, “b”: [0.9, 0.1]}的形式。</p><h3 id="从文件中读取数据"><a href="#从文件中读取数据" class="headerlink" title="从文件中读取数据"></a>从文件中读取数据</h3><p>在实际应用中，模型的训练和评估数据总是以文件的形式存在文件系统中，目前Dataset API提供了三种从文件读取数据并创建Dataset的方式，分别用来读取不同存储格式的文件。<br><img src="https://pic2.zhimg.com/80/v2-f9f42cc5c00573f7baaa815795f1ce45_hd.jpg" alt></p><ul><li>tf.data.TextLineDataset()：这个函数的输入是一个文件的列表，输出是一个dataset。dataset中的每一个元素就对应了文件中的一行。可以使用这个函数来读入CSV文件。</li><li>tf.data.FixedLengthRecordDataset()：这个函数的输入是一个文件的列表和一个record_bytes，之后dataset的每一个元素就是文件中固定字节数record_bytes的内容。通常用来读取以二进制形式保存的文件，如CIFAR10数据集就是这种形式。</li><li>tf.data.TFRecordDataset()：顾名思义，这个函数是用来读TFRecord文件的，dataset中的每一个元素就是一个TFExample。</li></ul><p>需要说明的是，这三种读取文件数据创建dataset的方法，不仅能读取本地文件系统中的文件，还能读取分布式文件系统（如HDFS）中的文件，这为模型的分布式训练创造了良好的条件。</p><h3 id="Dataset的常用Transformation操作"><a href="#Dataset的常用Transformation操作" class="headerlink" title="Dataset的常用Transformation操作"></a>Dataset的常用Transformation操作</h3><p>一个Dataset通过数据变换操作可以生成一个新的Dataset。下面介绍数据格式变换、过滤、数据打乱、生产batch和epoch等常用Transformation操作。</p><h4 id="（1）map"><a href="#（1）map" class="headerlink" title="（1）map"></a>（1）map</h4><p>map接收一个函数，Dataset中的每个元素都会被当作这个函数的输入，并将函数返回值作为新的Dataset，如我们可以对dataset中每个元素的值取平方：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset &#x3D; tf.data.Dataset.from_tensor_slices(np.array([1.0, 2.0, 3.0, 4.0, 5.0]))</span><br><span class="line">dataset &#x3D; dataset.map(lambda x: x * x) # 1.0, 4.0, 9.0, 16.0, 25.0</span><br></pre></td></tr></table></figure></p><h4 id="（2）filter"><a href="#（2）filter" class="headerlink" title="（2）filter"></a>（2）filter</h4><p>filter操作可以过滤掉dataset不满足条件的元素，它接受一个布尔函数作为参数，dataset中的每个元素都作为该布尔函数的参数，布尔函数返回True的元素保留下来，布尔函数返回False的元素则被过滤掉。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset &#x3D; dataset.filter(filter_func)</span><br></pre></td></tr></table></figure></p><h4 id="（3）shuffle"><a href="#（3）shuffle" class="headerlink" title="（3）shuffle"></a>（3）shuffle</h4><p>shuffle功能为打乱dataset中的元素，它有一个参数buffer_size，表示打乱时使用的buffer的大小：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset &#x3D; dataset.shuffle(buffer_size&#x3D;10000)</span><br></pre></td></tr></table></figure></p><h4 id="（4）repeat"><a href="#（4）repeat" class="headerlink" title="（4）repeat"></a>（4）repeat</h4><p>repeat的功能就是将整个序列重复多次，主要用来处理机器学习中的epoch，假设原先的数据是一个epoch，使用repeat(5)就可以将之变成5个epoch：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset &#x3D; dataset.repeat(5)</span><br></pre></td></tr></table></figure><br>如果直接调用repeat()的话，生成的序列就会无限重复下去，没有结束，因此也不会抛出tf.errors.OutOfRangeError异常。</p><h4 id="（5）batch"><a href="#（5）batch" class="headerlink" title="（5）batch"></a>（5）batch</h4><p>batch就是将多个元素组合成batch，如下面的程序将dataset中的每个元素组成了大小为32的batch：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset &#x3D; dataset.batch(32)</span><br></pre></td></tr></table></figure><br>需要注意的是，必须要保证dataset中每个元素拥有相同的shape才能调用batch方法，否则会抛出异常。在调用map方法转换元素格式的时候尤其要注意这一点。</p><h3 id="Dataset元素变换案例"><a href="#Dataset元素变换案例" class="headerlink" title="Dataset元素变换案例"></a>Dataset元素变换案例</h3><h4 id="1-解析CSV文件"><a href="#1-解析CSV文件" class="headerlink" title="1. 解析CSV文件"></a>1. 解析CSV文件</h4><p>假设我们有一个Tab分隔4个字段的文件，则可用如下的代码解析并生成dataset。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">_CSV_COLUMNS &#x3D; [&#39;field1&#39;, &#39;field2&#39;, &#39;field3&#39;, &#39;field4&#39;]</span><br><span class="line">_CSV_COLUMN_DEFAULTS&#x3D;[[&#39;&#39;], [&#39;&#39;], [0.0], [0.0]]</span><br><span class="line"></span><br><span class="line">def input_fn(data_file, shuffle, batch_size):</span><br><span class="line">  def parse_csv(value):</span><br><span class="line">    columns &#x3D; tf.decode_csv(value, record_defaults&#x3D;_CSV_COLUMN_DEFAULTS, field_delim&#x3D;&#39;\t&#39;)</span><br><span class="line">    features &#x3D; dict(zip(_CSV_COLUMNS, columns))</span><br><span class="line">    labels &#x3D; features.pop(&#39;ctr_flag&#39;)</span><br><span class="line">    return features, tf.equal(labels, &#39;1.0&#39;)</span><br><span class="line"></span><br><span class="line">  # Extract lines from input files using the Dataset API.</span><br><span class="line">  dataset &#x3D; tf.data.TextLineDataset(data_file)</span><br><span class="line">  if shuffle: dataset &#x3D; dataset.shuffle(buffer_size&#x3D;100000)</span><br><span class="line">  dataset &#x3D; dataset.map(parse_csv, num_parallel_calls&#x3D;100)</span><br><span class="line">  # We call repeat after shuffling, rather than before, to prevent separate</span><br><span class="line">  # epochs from blending together.</span><br><span class="line">  dataset &#x3D; dataset.repeat()</span><br><span class="line">  dataset &#x3D; dataset.batch(batch_size)</span><br><span class="line">  return dataset</span><br></pre></td></tr></table></figure><br>上述代码主要利用tf.decode_csv函数来把CSV文件记录转换为Tensors列表，每一列对应一个Tensor。</p><h4 id="2-解析特殊格式的文本文件"><a href="#2-解析特殊格式的文本文件" class="headerlink" title="2. 解析特殊格式的文本文件"></a>2. 解析特殊格式的文本文件</h4><p>有时候我们的训练数据可能有特殊的格式，比如CVS文件其中某些字段是JSON格式的字符串，我们要把JSON字符串的内容也解析出来，这个时候tf.decode_csv函数就不够用了。</p><p>是时候请万能函数tf.py_func上场了，tf.py_func函数能够把一个任意的python函数封装成tensorflow的op，提供了极大的灵活性，其定义如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.py_func(</span><br><span class="line">    func,</span><br><span class="line">    inp,</span><br><span class="line">    Tout,</span><br><span class="line">    stateful&#x3D;True,</span><br><span class="line">    name&#x3D;None</span><br><span class="line">)</span><br></pre></td></tr></table></figure><br>tf.py_func的核心是一个func函数(由用户自己定义)，该函数被封装成graph中的一个节点（op)。第二个参数inp是一个由Tensor组成的list，在执行时，inp的各个Tensor的值被取出来传给func作为参数。func的返回值会被tf.py_func转换为Tensors，这些Tensors的类型由Tout指定。当func只有一个返回值时，Tout是一个单独的tensorflow数据类型；当func函数有多个返回值时，Tout是一个tensorflow数据类型组成的元组或列表。参数stateful表示func函数是否有状态（产生副作用）。</p><p>在使用过程中，有几个需要注意的地方：</p><ul><li>func函数的返回值类型一定要和Tout指定的tensor类型一致。</li><li>tf.py_func中的func是脱离Graph的，在func中不能定义可训练的参数参与网络训练(反传)。</li><li>tf.py_func操作只能在CPU上运行；如果使用分布式TensorFlow，tf.py_func操作必须放在与客户端相同进程的CPU设备上。</li><li>tf.py_func操作返回的tensors是没有定义形状（shape）的，必须调用set_shape方法为各个返回值设置shape，才能参与后续的计算。</li></ul><p>先来看一个简单的示例，func函数接受单个参数并产生单个返回值的情况。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def filter_func(line):</span><br><span class="line">  fields &#x3D; line.decode().split(&quot;\t&quot;)</span><br><span class="line">  if len(fields) &lt; 8:</span><br><span class="line">    return False</span><br><span class="line">  for field in fields:</span><br><span class="line">    if not field:</span><br><span class="line">      return False</span><br><span class="line">  return True</span><br><span class="line"></span><br><span class="line">dataset &#x3D; dataset.filter(lambda x: tf.py_func(filter_func, [x], tf.bool, False))</span><br></pre></td></tr></table></figure></p><p>再来看一个稍微复杂一点的例子，该例子解析一个带有json格式字段的CSV文件，json字段被平铺开来和其他字段并列作为返回值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">def parse_line(line):</span><br><span class="line">  _COLUMNS &#x3D; [&quot;sellerId&quot;, &quot;brandId&quot;, &quot;cateId&quot;]</span><br><span class="line">  _INT_COLUMNS &#x3D; [&quot;click&quot;, &quot;productId&quot;, &quot;matchType&quot;, &quot;position&quot;, &quot;hour&quot;]</span><br><span class="line">  _FLOAT_COLUMNS &#x3D; [&quot;matchScore&quot;, &quot;popScore&quot;, &quot;brandPrefer&quot;, &quot;catePrefer&quot;]</span><br><span class="line">  _STRING_COLUMNS &#x3D; [&quot;phoneResolution&quot;, &quot;phoneBrand&quot;, &quot;phoneOs&quot;]</span><br><span class="line">  _SEQ_COLUMNS &#x3D; [&quot;behaviorC1ids&quot;, &quot;behaviorBids&quot;, &quot;behaviorCids&quot;, &quot;behaviorPids&quot;]</span><br><span class="line"></span><br><span class="line">  def get_content(record):</span><br><span class="line">    import datetime</span><br><span class="line">    fields &#x3D; record.decode().split(&quot;\t&quot;)</span><br><span class="line">    if len(fields) &lt; 8:</span><br><span class="line">      raise ValueError(&quot;invalid record %s&quot; % record)</span><br><span class="line">    for field in fields:</span><br><span class="line">      if not field:</span><br><span class="line">        raise ValueError(&quot;invalid record %s&quot; % record)</span><br><span class="line">    fea &#x3D; json.loads(fields[1])</span><br><span class="line">    if fea[&quot;time&quot;]:</span><br><span class="line">      dt &#x3D; datetime.datetime.fromtimestamp(fea[&quot;time&quot;])</span><br><span class="line">      fea[&quot;hour&quot;] &#x3D; dt.hour</span><br><span class="line">    else:</span><br><span class="line">      fea[&quot;hour&quot;] &#x3D; 0</span><br><span class="line">    seq_len &#x3D; 10</span><br><span class="line">    for x in _SEQ_COLUMNS:</span><br><span class="line">      sequence &#x3D; fea.setdefault(x, [])</span><br><span class="line">      n &#x3D; len(sequence)</span><br><span class="line">      if n &lt; seq_len:</span><br><span class="line">        sequence.extend([-1] * (seq_len - n))</span><br><span class="line">      elif n &gt; seq_len:</span><br><span class="line">        fea[x] &#x3D; sequence[:seq_len]</span><br><span class="line">      seq_len &#x3D; 20</span><br><span class="line"></span><br><span class="line">    elems &#x3D; [np.int64(fields[2]), np.int64(fields[3]), np.int64(fields[4]), np.int64(fields[6]), fields[7]]</span><br><span class="line">    elems +&#x3D; [np.int64(fea.get(x, 0)) for x in _INT_COLUMNS]</span><br><span class="line">    elems +&#x3D; [np.float32(fea.get(x, 0.0)) for x in _FLOAT_COLUMNS]</span><br><span class="line">    elems +&#x3D; [fea.get(x, &quot;&quot;) for x in _STRING_COLUMNS]</span><br><span class="line">    elems +&#x3D; [np.int64(fea[x]) for x in _SEQ_COLUMNS]</span><br><span class="line">    return elems</span><br><span class="line"></span><br><span class="line">  out_type &#x3D; [tf.int64] * 4 + [tf.string] + [tf.int64] * len(_INT_COLUMNS) + [tf.float32] * len(_FLOAT_COLUMNS) + [</span><br><span class="line">    tf.string] * len(_STRING_COLUMNS) + [tf.int64] * len(_SEQ_COLUMNS)</span><br><span class="line">  result &#x3D; tf.py_func(get_content, [line], out_type)</span><br><span class="line">  n &#x3D; len(result) - len(_SEQ_COLUMNS)</span><br><span class="line">  for i in range(n):</span><br><span class="line">    result[i].set_shape([])</span><br><span class="line">  result[n].set_shape([10])</span><br><span class="line">  for i in range(n + 1, len(result)):</span><br><span class="line">    result[i].set_shape([20])</span><br><span class="line">  columns &#x3D; _COLUMNS + _INT_COLUMNS + _FLOAT_COLUMNS + _STRING_COLUMNS + _SEQ_COLUMNS</span><br><span class="line">  features &#x3D; dict(zip(columns, result))</span><br><span class="line">  labels &#x3D; features.pop(&#39;click&#39;)</span><br><span class="line">  return features, labels</span><br><span class="line"></span><br><span class="line">def my_input_fn(filenames, batch_size, shuffle_buffer_size):</span><br><span class="line">  dataset &#x3D; tf.data.TextLineDataset(filenames)</span><br><span class="line">  dataset &#x3D; dataset.filter(lambda x: tf.py_func(filter_func, [x], tf.bool, False))</span><br><span class="line">  dataset &#x3D; dataset.map(parse_line, num_parallel_calls&#x3D;100)</span><br><span class="line">  # Shuffle, repeat, and batch the examples.</span><br><span class="line">  if shuffle_buffer_size &gt; 0:</span><br><span class="line">    dataset &#x3D; dataset.shuffle(shuffle_buffer_size)</span><br><span class="line">  dataset &#x3D; dataset.repeat().batch(batch_size)</span><br><span class="line">  return dataset</span><br></pre></td></tr></table></figure></p><h4 id="3-解析TFRECORD文件"><a href="#3-解析TFRECORD文件" class="headerlink" title="3. 解析TFRECORD文件"></a>3. 解析TFRECORD文件</h4><p>Tfrecord是tensorflow官方推荐的训练数据存储格式，它更容易与网络应用架构相匹配。</p><p>Tfrecord本质上是二进制的Protobuf数据，因而其读取、传输的速度更快。Tfrecord文件的每一条记录都是一个<code>tf.train.Example</code>的实例。<code>tf.train.Example</code>的proto格式的定义如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">message Example &#123;</span><br><span class="line">  Features features &#x3D; 1;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">message Features &#123;</span><br><span class="line">  map&lt;string, Feature&gt; feature &#x3D; 1;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">message Feature &#123;</span><br><span class="line">  oneof kind &#123;</span><br><span class="line">    BytesList bytes_list &#x3D; 1;</span><br><span class="line">    FloatList float_list &#x3D; 2;</span><br><span class="line">    Int64List int64_list &#x3D; 3;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>使用tfrecord文件格式的另一个好处是数据结构统一，屏蔽了底层的数据结构。在类似于图像分类的任务中，原始数据是各个图片以单独的小文件的形式存在，label又以文件夹的形式存在，处理这样的数据比较麻烦，比如随机打乱，分batch等操作；而所有原始数据转换为一个或几个单独的tfrecord文件后处理起来就会比较方便。</p><p>来看看tensorflow读取tfrecord文件并转化为训练features和labels的代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">def parse_exmp(serial_exmp):</span><br><span class="line">  features &#x3D; &#123;</span><br><span class="line">    &quot;click&quot;: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">    &quot;behaviorBids&quot;: tf.FixedLenFeature([20], tf.int64),</span><br><span class="line">    &quot;behaviorCids&quot;: tf.FixedLenFeature([20], tf.int64),</span><br><span class="line">    &quot;behaviorC1ids&quot;: tf.FixedLenFeature([10], tf.int64),</span><br><span class="line">    &quot;behaviorSids&quot;: tf.FixedLenFeature([20], tf.int64),</span><br><span class="line">    &quot;behaviorPids&quot;: tf.FixedLenFeature([20], tf.int64),</span><br><span class="line">    &quot;productId&quot;: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">    &quot;sellerId&quot;: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">    &quot;brandId&quot;: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">    &quot;cate1Id&quot;: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">    &quot;cateId&quot;: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">    &quot;tab&quot;: tf.FixedLenFeature([], tf.string),</span><br><span class="line">    &quot;matchType&quot;: tf.FixedLenFeature([], tf.int64)</span><br><span class="line">  &#125;</span><br><span class="line">  feats &#x3D; tf.parse_single_example(serial_exmp, features&#x3D;features)</span><br><span class="line">  labels &#x3D; feats.pop(&#39;click&#39;)</span><br><span class="line">  return feats, labels</span><br><span class="line"></span><br><span class="line">def train_input_fn(filenames, batch_size, shuffle_buffer_size):</span><br><span class="line">  dataset &#x3D; tf.data.TFRecordDataset(filenames)</span><br><span class="line">  dataset &#x3D; dataset.map(parse_exmp, num_parallel_calls&#x3D;100)</span><br><span class="line">  # Shuffle, repeat, and batch the examples.</span><br><span class="line">  if shuffle_buffer_size &gt; 0:</span><br><span class="line">    dataset &#x3D; dataset.shuffle(shuffle_buffer_size)</span><br><span class="line">  dataset &#x3D; dataset.repeat().batch(batch_size)</span><br><span class="line">  return dataset</span><br></pre></td></tr></table></figure></p><p>这里我们再说说如何把原始数据转换为tfrecord文件格式，请参考下面的代码片段：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 建立tfrecorder writer</span><br><span class="line">writer &#x3D; tf.python_io.TFRecordWriter(&#39;csv_train.tfrecords&#39;)</span><br><span class="line"></span><br><span class="line">for i in xrange(train_values.shape[0]):</span><br><span class="line">    image_raw &#x3D; train_values[i].tostring()</span><br><span class="line"></span><br><span class="line">    # build example protobuf</span><br><span class="line">    example &#x3D; tf.train.Example(</span><br><span class="line">      features&#x3D;tf.train.Features(feature&#x3D;&#123;</span><br><span class="line">        &#39;image_raw&#39;:  tf.train.Feature(bytes_list&#x3D;tf.train.BytesList(value&#x3D;[image_raw])),</span><br><span class="line">        &#39;label&#39;: tf.train.Feature(int64_list&#x3D;tf.train.Int64List(value&#x3D;[train_labels[i]]))</span><br><span class="line">    &#125;))</span><br><span class="line">    writer.write(record&#x3D;example.SerializeToString())</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><br>然而，大规模的训练数据用这种方式转换格式会比较低效，更好的实践是用hadoop或者spark这种分布式计算平台，并行实现数据转换任务。这里给出一个用Hadoop MapReduce编程模式转换为tfrecord文件格式的开源实现：<a href="https://github.com/tensorflow/ecosystem/tree/master/hadoop">Hadoop MapReduce InputFormat/OutputFormat for TFRecords</a>。由于该实现指定了protobuf的版本，因而可能会跟自己真正使用的hadoop平台自己的protobuf版本不一致，hadoop在默认情况下总是优先使用HADOOP_HOME/lib下的jar包，从而导致运行时错误，遇到这种情况时，只需要设置<code>mapreduce.task.classpath.user.precedence=true</code>参数，优先使用自己指定版本的jar包即可。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://zhuanlan.zhihu.com/p/30751039">https://zhuanlan.zhihu.com/p/30751039</a><br><a href="https://www.skcript.com/svr/why-every-tensorflow-developer-should-know-about-tfrecord/">https://www.skcript.com/svr/why-every-tensorflow-developer-should-know-about-tfrecord/</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在TensorFlow 1.3版本之前，读取数据一般有两种方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用placeholder + feed_dict读内存中的数据&lt;/li&gt;
&lt;li&gt;使用文件名队列（string_input_producer）与内存队列（reader）读硬盘中的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Dataset API同时支持从内存和硬盘的数据读取，相比之前的两种方法在语法上更加简洁易懂。Dataset API可以更方便地与其他高阶API配合，快速搭建网络模型。此外，如果想要用到TensorFlow新出的Eager模式，就必须要使用Dataset API来读取数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dataset可以看作是相同类型“元素”的有序列表&lt;/strong&gt;。在实际使用时，单个“元素”可以是向量，也可以是字符串、图片，甚至是tuple或者dict。&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="tensorflow" scheme="http://xudongyang.coding.me/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>基于Tensorflow高阶API构建大规模分布式深度学习模型系列</title>
    <link href="http://xudongyang.coding.me/tensorflow-high-level-api/"/>
    <id>http://xudongyang.coding.me/tensorflow-high-level-api/</id>
    <published>2018-06-25T07:00:28.000Z</published>
    <updated>2020-12-04T08:17:21.940Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Tensorflow高阶API简介"><a href="#Tensorflow高阶API简介" class="headerlink" title="Tensorflow高阶API简介"></a>Tensorflow高阶API简介</h2><p>在tensorflow高阶API（Estimator、Dataset、Layer、FeatureColumn等）问世之前，用tensorflow开发、训练、评估、部署深度学习模型，并没有统一的规范和高效的标准流程。Tensorflow的实践者们基于低阶API开发的代码在可移植性方面可能会遇到各种困难。例如，单机可以运行的模型希望改成能够分布式环境下运行需要对代码做额外的改动，如果在一个异构的环境中训练模型，则还需要额外花精力处理哪些部分跑在CPU上，哪些部分跑在GPU上。当不同的机器有不同数量的GPU数量时，问题更加复杂。</p><p>为了能够快速支持新的网络架构的实验测试，深度学习框架都很重视网络架构搭建的灵活性需求，因此能让用户随心所欲地自定义代码实现是很重要的一块功能。</p><p>模型构建的灵活性与简洁性需求看似是矛盾的。从开发者的视角，简洁性意味着当模型架构确定时实现不应该需要太多额外的技能要求，不必对深度学习框架有很深刻的洞察，就能够实验不同的模型特性。在内置简洁性属性的框架下开发者能够较轻松地开发出高质量的鲁棒性较好的模型软件，不会一不小心就踩到坑里。另一方面，灵活性意味着开发者能够实现任意的想要的模型结构，这需要框架能够提供一些相对低价的API。类似于Caffe这样的深度学习框架提供了DSL（domain specific language）来描述模型的结构，虽然搭建已知的成熟的模型架构比较方便，但却不能轻松搭建任意想要的模型结构。这就好比用积木搭建房子，如果现在需要一个特殊的以前没有出现过的积木块以便搭建一个特殊的房子，那就无计可施了。</p><p>Tensorflow高阶API正是为了同时满足模型构建的灵活性与简洁性需求应运而生的，它能够让开发者快速搭建出高质量的模型，又能够使用结合低阶API实现不受限制的模型结构。<br><a id="more"></a><br>下面就来看看tensorflow中有哪些常用的高阶API吧。<br><img src="https://3.bp.blogspot.com/-l2UT45WGdyw/Wbe7au1nfwI/AAAAAAAAD1I/GeQcQUUWezIiaFFRCiMILlX2EYdG49C0wCLcBGAs/s1600/image6.png" alt></p><h3 id="Estimator（估算器）"><a href="#Estimator（估算器）" class="headerlink" title="Estimator（估算器）"></a>Estimator（估算器）</h3><p>Estimator类是机器学习模型的抽象，其设计灵感来自于典典大名的Python机器学习库Scikit-learn。Estimator允许开发者自定义任意的模型结构、损失函数、优化方法以及如何对这个模型进行训练、评估和导出等内容，同时屏蔽了与底层硬件设备、分布式网络数据传输等相关的细节。</p><p><img src="/tensorflow-high-level-api/estimator.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.estimator.Estimator(</span><br><span class="line">    model_fn&#x3D;model_fn,  # First-class function</span><br><span class="line">    params&#x3D;params,  # HParams</span><br><span class="line">    config&#x3D;run_config  # RunConfig</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>要创建Estimator，需要传入一个模型函数、一组参数和一些配置。</p><ul><li>传入的参数应该是模型超参数的一个集合，可以是一个dictionary。</li><li>传入的配置用于指定模型如何运行训练和评估，以及在哪里存储结果。这个配置是一个RunConfig对象，该对象会把模型运行环境相关的信息告诉Estimator。</li><li>模型函数是一个Python函数，它根据给定的输入构建模型。</li></ul><p>Estimator类有三个主要的方法：train/fit、evaluate、predict，分别表示模型的训练、评估和预测。三个方法都接受一个用户自定义的输入函数input_fn，执行input_fn获取输入数据。Estimator的这三个方法最终都会调用模型函数（model_fn）执行具体的操作，不同方法被调用时，传递给model_fn的mode参数也是不同的，如下一小节中描述的那样，mode参数是让用户在编写模型函数时知道当前定义的操作是用在模型生命周期的哪一个阶段。</p><p>Tensorflow本身还提供了很多内置的开箱即用的Estimator，内置的 Estimator 是 tf.estimator.Estimator 基类的子类，而自定义 Estimator 是 tf.estimator.Estimator 的实例，如下图所示。<br><img src="/tensorflow-high-level-api/estimator_types.png" alt></p><h3 id="模型函数"><a href="#模型函数" class="headerlink" title="模型函数"></a>模型函数</h3><p>模型函数是用户自定义的一个python函数，它定义了模型训练、评估和预测所需的计算图节点（op）。</p><p>模型函数接受输入特征和标签作为参数，同时用mode参数来告知用户模型是在训练、评估或是在执行推理。mode是tf.estimator.ModeKeys对象，它有三个可取的值：TRAIN、EVAL、PREDICT。模型函数的最后一个参数是超参数集合，它们与传递给Estimator的超参数集合相同。模型函数返回一个EstimatorSpec对象，该对象定义了一个完整的模型。EstimatorSpec对象用于对操作进行预测、损失、训练和评估，因此，它定义了一个用于训练、评估和推理的完整的模型图。</p><p>一个简单的模型函数示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def model_fn(features, target, mode, params)</span><br><span class="line">  predictions &#x3D; tf.stack(tf.fully_connected, [50, 50, 1])</span><br><span class="line">  loss &#x3D; tf.losses.mean_squared_error(target, predictions)</span><br><span class="line">  train_op &#x3D; tf.train.create_train_op(</span><br><span class="line">    loss, tf.train.get_global_step(),</span><br><span class="line">    params[’learning_rate’], params[’optimizer’])</span><br><span class="line">  return EstimatorSpec(mode&#x3D;mode,</span><br><span class="line">                       predictions&#x3D;predictions,</span><br><span class="line">                       loss&#x3D;loss,</span><br><span class="line">                       train_op&#x3D;train_op)</span><br></pre></td></tr></table></figure><h3 id="Dataset（数据集）"><a href="#Dataset（数据集）" class="headerlink" title="Dataset（数据集）"></a>Dataset（数据集）</h3><p>在tensorflow中，构建模型输入流水线的最佳实践就是使用Dataset API。Dataset API底层使用C++实现，能够绕过python的一些性能限制，性能很好。</p><p>Dataset是对训练、评估、预测阶段所用的数据的抽象表示，其提供了数据读取、解析、打乱（shuffle）、过滤、分批（batch）等操作，是构建模型输入管道的利器，我将会在另外一篇文章《<a href="https://zhuanlan.zhihu.com/p/38421397">基于Tensorflow高阶API构建大规模分布式深度学习模型系列：基于Dataset API处理Input pipeline</a>》中详细介绍。</p><h3 id="Feature-Columns（特征列）"><a href="#Feature-Columns（特征列）" class="headerlink" title="Feature Columns（特征列）"></a>Feature Columns（特征列）</h3><p>Feature Columns是特征工程的利器，其能够方便地把原始数据转换为模型的输入数据，并提供了一些常用的数据变换操作，如特征交叉、one-hot编码、embedding编码等。关于Feature Column，也将会在另外一篇文章中详细介绍。</p><h3 id="Layers"><a href="#Layers" class="headerlink" title="Layers"></a>Layers</h3><p>Layer是一组简单的可重复利用的代码，表示神经网络模型中的“层”这个概率。Tensorflow中的layer可以认为是一系列操作（op）的集合，与op一样也是输入tensor并输出tensor的（tensor-in-tensor-out)。Tensorflow中即内置了全连接这样的简单layer，也有像inception网络那样的复杂layer。使用layers来搭建网络模型会更加方便。</p><h3 id="Head"><a href="#Head" class="headerlink" title="Head"></a>Head</h3><p>Head API对网络最后一个隐藏层之后的部分进行了抽象，它的主要设计目标是简化模型函数（model_fn）的编写。Head知道如何计算损失（loss）、评估度量标准（metric)、预测结果（prediction）。为了支持不同的模型，Head接受logits和labels作为参数，并生成表示loss、metric和prediction的张量。有时为了避免计算完整的logit张量，Head也接受最后一个隐藏的激活值作为输入。</p><p>一个使用Head简化model_fn编写的例子如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def model_fn(features, target, mode, params):</span><br><span class="line">  last_layer &#x3D; tf.stack(tf.fully_connected, [50, 50])</span><br><span class="line">  head &#x3D; tf.multi_class_head(n_classes&#x3D;10)</span><br><span class="line">  return head.create_estimator_spec(</span><br><span class="line">    features, mode, last_layer,</span><br><span class="line">    label&#x3D;target,</span><br><span class="line">    train_op_fn&#x3D;lambda loss: my_optimizer.minimize(loss, tf.train.get_global_step())</span><br></pre></td></tr></table></figure></p><p>我们也可以用一个Heads列表来创建一个特殊类型的Head，来完成多目标学习的任务，如下面的例子那样。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def model_fn(features, target, mode, params):</span><br><span class="line">  last_layer &#x3D; tf.stack(tf.fully_connected, [50, 50])</span><br><span class="line">  head1 &#x3D; tf.multi_class_head(n_classes&#x3D;2,label_name&#x3D;’y’, head_name&#x3D;’h1’)</span><br><span class="line">  head2 &#x3D; tf.multi_class_head(n_classes&#x3D;10,label_name&#x3D;’z’, head_name&#x3D;’h2’)</span><br><span class="line">  head &#x3D; tf.multi_head([head1, head2])</span><br><span class="line">  return head.create_model_fn_ops(features,</span><br><span class="line">    features, mode, last_layer,</span><br><span class="line">    label&#x3D;target,</span><br><span class="line">    train_op_fn&#x3D;lambda loss: my_optimizer.minimize(loss, tf.train.get_global_step())</span><br></pre></td></tr></table></figure></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Tensorflow高阶API简化了模型代码的编写过程，大大降价了新手的入门门槛，使我们能够用一种标准化的方法开发出实验与生产环境部署的代码。使用Tensorflow高阶API能够使我们避免走很多弯路，提高深度学习的实践效率，我们应该尽可能使用高阶API来开发模型。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://arxiv.org/abs/1708.02637">TensorFlow Estimators: Managing Simplicity vs. Flexibility in High-Level Machine Learning Frameworks</a></li><li><a href="https://www.tensorflow.org/get_started/custom_estimators">自定义estimators</a></li><li><a href="https://www.tensorflow.org/get_started/feature_columns">Feature columns</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;Tensorflow高阶API简介&quot;&gt;&lt;a href=&quot;#Tensorflow高阶API简介&quot; class=&quot;headerlink&quot; title=&quot;Tensorflow高阶API简介&quot;&gt;&lt;/a&gt;Tensorflow高阶API简介&lt;/h2&gt;&lt;p&gt;在tensorflow高阶API（Estimator、Dataset、Layer、FeatureColumn等）问世之前，用tensorflow开发、训练、评估、部署深度学习模型，并没有统一的规范和高效的标准流程。Tensorflow的实践者们基于低阶API开发的代码在可移植性方面可能会遇到各种困难。例如，单机可以运行的模型希望改成能够分布式环境下运行需要对代码做额外的改动，如果在一个异构的环境中训练模型，则还需要额外花精力处理哪些部分跑在CPU上，哪些部分跑在GPU上。当不同的机器有不同数量的GPU数量时，问题更加复杂。&lt;/p&gt;
&lt;p&gt;为了能够快速支持新的网络架构的实验测试，深度学习框架都很重视网络架构搭建的灵活性需求，因此能让用户随心所欲地自定义代码实现是很重要的一块功能。&lt;/p&gt;
&lt;p&gt;模型构建的灵活性与简洁性需求看似是矛盾的。从开发者的视角，简洁性意味着当模型架构确定时实现不应该需要太多额外的技能要求，不必对深度学习框架有很深刻的洞察，就能够实验不同的模型特性。在内置简洁性属性的框架下开发者能够较轻松地开发出高质量的鲁棒性较好的模型软件，不会一不小心就踩到坑里。另一方面，灵活性意味着开发者能够实现任意的想要的模型结构，这需要框架能够提供一些相对低价的API。类似于Caffe这样的深度学习框架提供了DSL（domain specific language）来描述模型的结构，虽然搭建已知的成熟的模型架构比较方便，但却不能轻松搭建任意想要的模型结构。这就好比用积木搭建房子，如果现在需要一个特殊的以前没有出现过的积木块以便搭建一个特殊的房子，那就无计可施了。&lt;/p&gt;
&lt;p&gt;Tensorflow高阶API正是为了同时满足模型构建的灵活性与简洁性需求应运而生的，它能够让开发者快速搭建出高质量的模型，又能够使用结合低阶API实现不受限制的模型结构。&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://xudongyang.coding.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="tensorflow" scheme="http://xudongyang.coding.me/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>完整空间多任务模型：CVR预估的有效方法</title>
    <link href="http://xudongyang.coding.me/esmm/"/>
    <id>http://xudongyang.coding.me/esmm/</id>
    <published>2018-05-16T05:25:58.000Z</published>
    <updated>2020-12-04T08:17:21.874Z</updated>
    
    <content type="html"><![CDATA[<p>在诸如信息检索、推荐系统、在线广告投放系统等工业级的应用中准确预估转化率（post-click conversion rate，CVR）是至关重要的。例如，在电商平台的推荐系统中，最大化场景商品交易总额（GMV）是平台的重要目标之一，而GMV可以拆解为流量×点击率×转化率×客单价，可见转化率是优化目标的重要因子；从用户体验的角度来说准确预估的转换率被用来平衡用户的点击偏好与购买偏好。</p><p>阿里妈妈算法团队最近发表了一篇关于CVR预估的论文《Entire Space Multi-Task Model: An Eﬀective Approach for Estimating Post-Click Conversion Rate》，提出了一种新颖的CVR预估模型，称之为“完整空间多任务模型”（Entire Space Multi-Task Model，ESMM），下文简称为ESMM模型。ESMM模型创新地利用用户行为序列数据，在完整的样本数据空间同时学习点击率和转化率（post-view clickthrough&amp;conversion rate，CTCVR），解决了传统CVR预估模型难以克服的样本选择偏差（sample selection bias）和训练数据过于稀疏（data sparsity ）的问题。<br><a id="more"></a><br>以电子商务平台为例，用户在观察到系统展现的推荐商品列表后，可能会点击自己感兴趣的商品，进而产生购买行为。换句话说，用户行为遵循一定的顺序决策模式：impression → click → conversion。CVR模型旨在预估用户在观察到曝光商品进而点击到商品详情页之后购买此商品的概率，即pCVR = p(conversion|click,impression)。</p><p>假设训练数据集为$S=\{(x_i,y_i \to z_i)\}|_{i=1}^N$，其中的样本$(x,y \to z)$是从域$X \times Y \times Z$中按照某种分布采样得到的，$X$是特征空间，$Y$和$Z$是标签空间，$N$ 为数据集中的样本总数量。在CVR预估任务中，$x$ 是高维稀疏多域的特征向量，$y$ 和 $z$ 的取值为0或1，分别表示是否点击和是否购买。$y \to z$揭示了用户行为的顺序性，即点击事情一般发生在购买事件之前。CVR模型的目标是预估条件概率pCVR ，与其相关的两个概率为点击率pCTR 和点击且转换率 pCTCVR ，它们之间的关系如下：<br><img src="/esmm/ctcvr.png" alt="图片"></p><p>传统的CVR预估任务通常采用类似于CTR预估的技术，比如最近很流行的深度学习模型。然而，有别于CTR预估任务，CVR预估任务面临一些特有的挑战：1) 样本选择偏差；2) 训练数据稀疏；3) 延迟反馈等。</p><p><img src="/esmm/sample-space.png" alt="图片"> 图1. 训练样本空间</p><p>延迟反馈的问题不在本文讨论的范围内，下面简单介绍一下样本选择偏差与训练数据稀疏的问题。如图1所示，最外面的大椭圆为整个样本空间$S$，其中有点击事件（$y=1$）的样本组成的集合为$S_c=\{(x_j, z_j)|y_j = 1\}|_{j=1}^M$，对应图中的阴影区域，传统的CVR模型就是用此集合中的样本来训练的，同时训练好的模型又需要在整个样本空间做预测推断。由于点击事件相对于展现事件来说要少很多，因此$S_c$只是样本空间$S$的一个很小的子集，从$S_c$上提取的特征相对于从$S$中提取的特征而言是有偏的，甚至是很不相同。从而，按这种方法构建的训练样本集相当于是从一个与真实分布不一致的分布中采样得到的，这一定程度上违背了机器学习算法之所以有效的前提：训练样本与测试样本必须独立地采样自同一个分布，即独立同分布的假设。总结一下，训练样本从整体样本空间的一个较小子集中提取，而训练得到的模型却需要对整个样本空间中的样本做推断预测的现象称之为样本选择偏差。样本选择偏差会伤害学到的模型的泛化性能。</p><p>推荐系统展现给用户的商品数量要远远大于被用户点击的商品数量，同时有点击行为的用户也仅仅只占所有用户的一小部分，因此有点击行为的样本空间图片: $S_c$相对于整个样本空间$S$ 来说是很小的，通常来讲，量级要少1~3个数量级。如表1所示，在淘宝公开的训练数据集上，$S_c$只占整个样本空间$S$的4%。这就是所谓的训练数据稀疏的问题，高度稀疏的训练数据使得模型的学习变得相当困难。<br><img src="/esmm/dataset.png" alt="图片"></p><p>阿里妈妈的算法同学提出的ESMM模型借鉴了多任务学习的思路，引入了两个辅助的学习任务，分别用来拟合pCTR和pCTCVR，从而同时消除了上文提到的两个挑战。ESMM模型能够充分利用用户行为的顺序性模式，其模型架构如图2所示。</p><p><img src="/esmm/esmm.png" alt="图片"> 图2. ESMM模型</p><p>整体来看，对于一个给定的展现，ESMM模型能够同时输出预估的pCTR、pCVR 和pCTCVR。它主要由两个子神经网络组成，左边的子网络用来拟合pCVR ，右边的子网络用来拟合pCTR。两个子网络的结构是完全相同的，这里把子网络命名为BASE模型。两个子网络的输出结果相乘之后即得到pCTCVR，并作为整个任务的输出。</p><p>需要强调的是，ESMM模型有两个主要的特点，使其区别于传统的CVR预估模型，分别阐述如下。</p><ol><li><p>在整个样本空间建模。由下面的等式可以看出，pCVR 可以在先估计出pCTR 和pCTCVR之后推导出来。从原理上来说，相当于分别单独训练两个模型拟合出pCTR 和pCTCVR，再通过pCTCVR 除以pCTR 得到最终的拟合目标pCVR 。<br><img src="/esmm/ctcvr-devision.png" alt="图片"><br> 但是，由于pCTR 通常很小，除以一个很小的浮点数容易引起数组不稳定问题（计算内存溢出）。所以ESMM模型采用了乘法的形式，而没有采用除法形式。<br> pCTR 和pCTCVR 是ESMM模型需要估计的两个主要因子，而且是在整个样本空间上建模得到的，pCVR 只是一个中间变量。由此可见，ESMM模型是在整个样本空间建模，而不像传统CVR预估模型那样只在点击样本空间建模。</p></li><li><p>共享特征表示。ESMM模型借鉴迁移学习的思路，在两个子网络的embedding层共享embedding向量（特征表示）词典。网络的embedding层把大规模稀疏的输入数据映射到低维的表示向量，该层的参数占了整个网络参数的绝大部分，需要大量的训练样本才能充分学习得到。由于CTR任务的训练样本量要大大超过CVR任务的训练样本量，ESMM模型中特征表示共享的机制能够使得CVR子任务也能够从只有展现没有点击的样本中学习，从而能够极大地有利于缓解训练数据稀疏性问题。</p></li></ol><p>需要补充说明的是，ESMM模型的损失函数由两部分组成，对应于pCTR 和pCTCVR 两个子任务，其形式如下：</p><script type="math/tex; mode=display">L(\theta_{cvr},\theta_{ctr}) =\sum_{i=1}^N l(y_i, f(x_i; \theta_{ctr}))+ \sum_{i=1}^N l(y_i\&z_i, f(x_i; \theta_{ctr}) \times f(x_i; \theta_{cvr}))</script><p>其中，$\theta_{ctr}$和$\theta_{cvr}$分别是CTR网络和CVR网络的参数，$l(\cdot)$是交叉熵损失函数。在CTR任务中，有点击行为的展现事件构成的样本标记为正样本，没有点击行为发生的展现事件标记为负样本；在CTCVR任务中，同时有点击和购买行为的展现事件标记为正样本，否则标记为负样本。</p><p>由于ESMM模型创新性地利用了用户的序列行为做完模型的训练样本，因此并没有公开的数据集可供测试，阿里的技术同学从淘宝的日志中采样了一部分数据，作为公开的测试集，下载地址为：<a href="https://tianchi.aliyun.com/datalab/dataSet.html?dataId=408">https://tianchi.aliyun.com/datalab/dataSet.html?dataId=408</a> 。阿里妈妈的工程师们分别在公开的数据集和淘宝生产环境的数据集上做了测试，相对于其他几个主流的竞争模型，都取得了更好的性能。</p><p><img src="/esmm/comparison-public.png" alt></p><p>表2是在公开数据集上的不同算法AUC效果对比情况，其中BASE模型是ESMM模型中左边的子神经网络模型，由于其只在点击样本空间训练，会遭遇样本选择偏差和数据稀疏的问题，因为效果也是较差的。DIVISION模型是先分别训练出拟合CTR和CTCVR的模型，再拿CTCVR模型的预测结果除以CTR模型的预测结果得到对CVR模型的预估。ESMM-NS模型是ESMM模型的一个变种模型，其在ESMM模型的基础上去掉了特征表示共享的机制。AMAN、OVERSAMPLING、UNBIAS是三个竞争模型。</p><p><img src="/esmm/comparison-product.png" alt> 图3.在淘宝生产环境数据集上几种不同算法的性能测试对比</p><p>图3是ESMM模型在淘宝生产环境数据集上的测试效果对比。相对于BASE模型，ESMM模型在CVR任务中AUC指标提升了 2.18%，在CTCVR任务中AUC指标提升了2.32%。通常AUC指标提升0.1%就可认为是一个显著的改进。</p><p>综上所述，ESMM模型是一个新颖的CVR预估方法，其首创了利用用户行为序列数据在完整样本空间建模，避免了传统CVR模型经常遭遇的样本选择偏差和训练数据稀疏的问题，取得了显著的效果。另一方面，ESMM模型的贡献在于其提出的利用学习CTR和CTCVR的辅助任务，迂回地学习CVR的思路。ESMM模型中的BASE子网络可以替换为任意的学习模型，因此ESMM的框架可以非常容易地和其他学习模型集成，从而吸收其他学习模型的优势，进一步提升学习效果，想象空间巨大。</p><p>原文链接：<a href="https://arxiv.org/abs/1804.07931">https://arxiv.org/abs/1804.07931</a></p><p>关于ESMM模型的实现，请参考另一篇文章：<a href="/esmm-1/" title="构建分布式Tensorflow模型系列之CVR预估案例ESMM模型">构建分布式Tensorflow模型系列之CVR预估案例ESMM模型</a></p><p>完整源代码：<a href="https://github.com/yangxudong/deeplearning/tree/master/esmm">https://github.com/yangxudong/deeplearning/tree/master/esmm</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在诸如信息检索、推荐系统、在线广告投放系统等工业级的应用中准确预估转化率（post-click conversion rate，CVR）是至关重要的。例如，在电商平台的推荐系统中，最大化场景商品交易总额（GMV）是平台的重要目标之一，而GMV可以拆解为流量×点击率×转化率×客单价，可见转化率是优化目标的重要因子；从用户体验的角度来说准确预估的转换率被用来平衡用户的点击偏好与购买偏好。&lt;/p&gt;
&lt;p&gt;阿里妈妈算法团队最近发表了一篇关于CVR预估的论文《Entire Space Multi-Task Model: An Eﬀective Approach for Estimating Post-Click Conversion Rate》，提出了一种新颖的CVR预估模型，称之为“完整空间多任务模型”（Entire Space Multi-Task Model，ESMM），下文简称为ESMM模型。ESMM模型创新地利用用户行为序列数据，在完整的样本数据空间同时学习点击率和转化率（post-view clickthrough&amp;amp;conversion rate，CTCVR），解决了传统CVR预估模型难以克服的样本选择偏差（sample selection bias）和训练数据过于稀疏（data sparsity ）的问题。&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="CTR预估" scheme="http://xudongyang.coding.me/tags/CTR%E9%A2%84%E4%BC%B0/"/>
    
    <category term="CVR预估" scheme="http://xudongyang.coding.me/tags/CVR%E9%A2%84%E4%BC%B0/"/>
    
  </entry>
  
  <entry>
    <title>Contextual Bandit算法在推荐系统中的实现及应用</title>
    <link href="http://xudongyang.coding.me/linucb/"/>
    <id>http://xudongyang.coding.me/linucb/</id>
    <published>2018-04-16T11:51:15.000Z</published>
    <updated>2020-12-04T08:17:21.908Z</updated>
    
    <content type="html"><![CDATA[<p>推荐系统选择商品展现给用户，并期待用户的正向反馈（点击、成交）。然而推荐系统并不能提前知道用户在观察到商品之后如何反馈，也就是不能提前获得本次推荐的收益，唯一能做的就是不停地尝试，并实时收集反馈以便更新自己试错的策略。目的是使得整个过程损失的收益最小。这一过程就类似与一个赌徒在赌场里玩老虎机赌博。赌徒要去摇老虎机，走进赌场一看，一排老虎机，外表一模一样，但是每个老虎机吐钱的概率可不一样，他不知道每个老虎机吐钱的概率分布是什么，那么每次该选择哪个老虎机可以做到最大化收益呢？这就是多臂赌博机问题（Multi-armed bandit problem, MAB）。</p><p>MAB问题的难点是Exploitation-Exploration(E&amp;E)两难的问题：对已知的吐钱概率比较高的老虎机，应该更多的去尝试(exploitation)，以便获得一定的累计收益；对未知的或尝试次数较少的老虎机，还要分配一定的尝试机会（exploration），以免错失收益更高的选择，但同时较多的探索也意味着较高的风险（机会成本）。</p><p>Bandit算法是一类用来实现Exploitation-Exploration机制的策略。根据是否考虑上下文特征，Bandit算法分为context-free bandit和contextual bandit两大类。<br><a id="more"></a></p><h2 id="1-UCB"><a href="#1-UCB" class="headerlink" title="1. UCB"></a>1. UCB</h2><p>Context-free Bandit算法有很多种，比如$\epsilon-greedy$、softmax、Thompson Sampling、UCB(Upper Confidence Bound)等。</p><p>在此，重点介绍一下UCB方法的基本思想。在统计学中，对于一个未知量的估计，总能找到一种量化其置信度的方法。最普遍的分布正态分布（或曰高斯分布）$N(μ,δ)$，其中的$μ$就是估计量的期望，而$δ$则表示其不确定性（$δ$越大则表示越不可信）。比如你掷一个标准的6面色子，它的平均值是3.5，而如果你只掷一次，比如说到2，那你对平均值的估计只能是2，但是这个置信度应该很低，我们可以知道，这个色子的预估平均值是2，而以95%的置信区间在[1.4,5.2]。</p><p>UCB（Upper Confidence Bound - 置信上限）就是以收益（bonus）均值的置信区间上限代表对该arm未来收益的预估值：</p><script type="math/tex; mode=display">\hat{\mu_i} + \sqrt{\frac{2ln(n)}{n_i}}</script><p>其中$\hat{\mu_i}$是对arm $i$期望收益的预估，$n$是总的选择次数，${n_i}$是对arm $i$的尝试次数，可以看到尝试越多，其预估值与置信上限的差值就越小，也就是越有置信度。</p><p>UCB在此时的决策是选择置信区间上界最大的arm。这个策略的好处是，能让没有机会尝试的arm得到更多尝试的机会，是骡子是马拉出来溜溜！</p><ul><li>对于未知或较少尝试的arm，尽管其均值可能很低，但是由于其不确定性会导致置信区间的上界较大，从而有较大的概率触发exploration</li><li>对于已经很熟悉的arm(尝试过较多次)，更多的是触发exploitation机制：如果其均值很高，会获得更多的利用机会；反之，则会减少对其尝试的机会</li></ul><h2 id="2-LinUCB"><a href="#2-LinUCB" class="headerlink" title="2. LinUCB"></a>2. LinUCB</h2><p>在推荐系统中，通常把待推荐的商品作为MAB问题的arm。UCB这样的context-free类算法，没有充分利用推荐场景的上下文信息，为所有用户的选择展现商品的策略都是相同的，忽略了用户作为一个个活生生的个性本身的兴趣点、偏好、购买力等因素都是不同的，因而，同一个商品在不同的用户、不同的情景下接受程度是不同的。故在实际的推荐系统中，context-free的MAB算法基本都不会被采用。</p><p>与context-free MAB算法对应的是Contextual Bandit算法，顾名思义，这类算法在实现E&amp;E时考虑了上下文信息，因而更加适合实际的个性化推荐场景。</p><p>形式化地说，在时间步$t$，<strong>contextual-bandit算法</strong>观察到当前用户$u_t$，以及每个可选择的商品（arm）$a$的特征向量$x_{t,a}$。$x_{t,a}$称之为上下文信息，它概况了用户和商品两方面的信息。算法根据之前观察到的反馈结果选择一个商品$a_t$展现给用户，并接受到用户的反馈收益$r_{t,a_t}$，$r_{t,a_t}$的期望取决于用户和商品两个方面。接着，算法根据新的观察$(x_{t,a},a_t,r_{t,a_t})$改进自身选择商品展现的策略，目标是使得整个过程中损失的收益最小，即regret值$R_A(T)$最小。$R_A(T)$的定义如下：</p><script type="math/tex; mode=display">R_A(T)=E\left[ \sum_{t=1}^T r,a_t^* \right]-E\left[ \sum_{t=1}^T r,a_t \right]</script><p>其中，$T$为实验的总步数；$a_t^*$为在时间步$t$时有最大期望收益的arm，不能提前得知。</p><p>LinUCB是处理Contextual Bandit的一个方法，在LinUCB中，设定每个arm的期望收益为该arm的特征向量(context)的线性函数，如下：</p><p>\begin{align}<br>E\left[r_{t,a}|x_{t,a}\right] = x_{t,a}^T\theta_a<br>\end{align}</p><p>$\theta_a$是LinUCB模型的参数，维度为$d$。每个arm维护一个$\theta_a$</p><p>对于单个arm $a$，以其前$m$个context向量为行向量组成的矩阵称为$D_a$，维度为$m \times n$。前$m$个收益（reward）组成的向量称为$c_a$。采用平方损失函数</p><script type="math/tex; mode=display">loss=\sum_{i=1}^m\left(c_{a,i}-\sum_{j=0}^d \theta_{a,j}x_{ij} \right)^2 + \lambda\sum_{j=0}^d \theta_{a,j}^2</script><p>，其中$\lambda$为正则项系数。求损失函数的最小值，令损失函数对$\theta_a$求导，结果为</p><script type="math/tex; mode=display">\nabla_{\theta_a}loss=2D_a^T(c_a-D_a\theta_a)-2\lambda\theta_a</script><p>令$\nabla_{\theta_a}loss=0, \lambda=1$，可得</p><script type="math/tex; mode=display">\theta_a = (D_a^TD_a + I)^{-1}D_a^Tc_a</script><p>使用岭回归（ridge regression）方法，可以得到$\theta_a$的概率分布为高斯分布：</p><p>\begin{align}<br>\theta_a \sim N \left((D_a^TD_a + I)^{-1}D_a^Tc_a, (D_a^TD_a + I)^{-1}\right)<br>\end{align}</p><p>为了符号简洁，令</p><p>\begin{align}<br>\hat{\theta}_a &amp;= (D_a^TD_a + I)^{-1}D_a^Tc_a \\<br>A_a &amp;= D_a^TD_a + I<br>\end{align}</p><p>于是$\theta_a$的概率分布可表示为$\theta_a \sim N(\hat{\theta}_a, A_a^{-1})$</p><p>于是在第$t$次时可以得到<script type="math/tex">x_{t,a}^T\theta_a \sim N(x_{t,a}^T\hat{\theta}_a, x_{t,a}^TA_a^{-1}x_{t,a})</script>，也就是<script type="math/tex">r_{t,a} \sim N(x_{t,a}^T\hat{\theta}_a, x_{t,a}^TA_a^{-1}x_{t,a})</script></p><p>根据高斯分布的性质，得到置信上界后就可以使用普通UCB规则了，即每次选择 $x_{t,a}^T\hat{\theta}_a + \alpha \sqrt{x_{t,a}^TA_a^{-1}x_{t,a})}$最大的arm。</p><p>需要注意的是，$A_a$与$D_a^Tc_a$可以增量异步更新，于是标准流程如下：</p><ul><li>设定$\alpha$</li><li>For $t$ = 1,2,3,…<ul><li>对所有的arm获得本次的context向量</li><li>For all $a$<ul><li>if $a$ is new<ul><li>设置$A_a$为单位矩阵</li><li>设置$b_a$为$d$维零向量</li></ul></li><li>计算$\hat{\theta}_a = A_a^{-1}b_a$</li><li>计算上界 $p_{t,a}=x_{t,a}^T\hat{\theta}_a + \alpha \sqrt{x_{t,a}^TA_a^{-1}x_{t,a})}$</li></ul></li><li>选择最大上界$p_{t,a}$对应的arm即$a_t$，并得到对应的$r_t$</li><li>更新$A_{a_t} = A_{a_t} + x_{t,a_t}x_{t,a_t}^T$</li><li>更新$b_{a_t} = b_{a_t} + r_tx_{t,a_t}$</li></ul></li></ul><p>LinUCB算法的优势：</p><ul><li>计算复杂度与arm的数量成线性关系</li><li>支持动态变化的候选arm集合</li></ul><h2 id="3-业务场景介绍"><a href="#3-业务场景介绍" class="headerlink" title="3. 业务场景介绍"></a>3. 业务场景介绍</h2><p>在我们的电商平台App首页，有一个商品瀑布流推荐场景，每次大概展示30个商品左右。商品候选集都是运营人工精选的历史销售情况较好，在更多流量刺激下有可能成为爆款的商品，并且每天都会汰换掉一部分，加入一些新品进来。</p><p>用过实现LinUcb算法，系统会对每个商品做充分的exploration和exploitation，从而发掘出真正有销售潜力的商品，逐渐淘汰掉不够理想的商品，纠正运营人工选品的局限。经过考验的商品，说明在一段时间内销量还是不错的，这些商品运营可以深度控价，要求商家提供更多的优惠和让利给用户，从而形成良性循环，同时也给其他商家树立标杆，促进平台更加健康地发展。</p><h2 id="4-系统架构"><a href="#4-系统架构" class="headerlink" title="4. 系统架构"></a>4. 系统架构</h2><p>在我们的系统中，LinUCB算法的实现分为两个部分：一部分实现在推荐引擎里，主要完成特征向量提取、获取每个商品的$A_a$矩阵和$b_a$向量数据、完成置信区间上届的计算、并选择最终展现的商品；另一部分逻辑实现在实时计算平台Storm上，这部分任务实时解析场景的曝光、点击和购买行为日志，每条日志里包含了商品ID、时间戳和特征向量等信息，根据公式更新每个商品的$A_a$矩阵和$b_a$向量，并把更新后的结果写到Redis缓存里，供推荐引擎获取。</p><p><img src="/linucb/LinUCB.png" alt="linucb"></p><h2 id="5-核心代码逻辑"><a href="#5-核心代码逻辑" class="headerlink" title="5. 核心代码逻辑"></a>5. 核心代码逻辑</h2><p>每个商品都维护一个队列queue，用于临时存放接受到的行为事件。之所以不在接受到事情的时候立马处理掉，主要有两个原因：一是用户对每个展现商品的反馈并不是原子操作，比如反馈是曝光未点击，或是曝光且点击但未购买，还是即曝光又点击最后还购买了，这些操作不是一步就能完成的，而是保护了好几步，因此在仅仅收到曝光事情或者点击事情时，我们不知道用户的反馈序列操作有没有结束，也就不能准确设置反馈的收益值；二是由于客户端对曝光事情有缓存不是实时上报的，因而不能保证曝光事情一定在点击事情之前被上传到日志服务器。</p><p>具体实现时，设置一个时间间隔（比如，5分钟），一个曝光或者点击事情到达Storm计算节点时，先缓存在队列里，等待设置好的时间间隔后，再消费掉。如果在时间间隔内高优先级的事情到达，则会直接移除掉低优先级的事情。优先级顺序为购买大于点击、点击大于曝光。另外，为了防止日志重复上报，还会根据推荐引擎的请求ID（不同请求不同）对接受到是事情去重。当然，为了容错，如果预设的事情队列满了，则会动态把时间间隔缩短为原来的二分之一，把新的时间间隔之前的事情强制消费掉，这个过程会递归执行，直到队列的长度小于预设的大小为止。</p><p>Storm任务中，某个商品的参数（$A_a$矩阵和$b_a$向量）更新逻辑：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">public int consume(Event newEvent, Config config) &#123;</span><br><span class="line">    if (newEvent.getPid() !&#x3D; pid)</span><br><span class="line">        return -1;</span><br><span class="line"></span><br><span class="line">    reset(config);</span><br><span class="line"></span><br><span class="line">    int showConsumedCount &#x3D; 0;</span><br><span class="line">    int clickConsumedCount &#x3D; 0;</span><br><span class="line">    long current &#x3D; System.currentTimeMillis();</span><br><span class="line">    Iterator&lt;Event&gt; iter &#x3D; queue.iterator();</span><br><span class="line">    while (iter.hasNext()) &#123;</span><br><span class="line">        Event event &#x3D; iter.next();</span><br><span class="line">        if (event.isSameFlow(newEvent)) &#123;</span><br><span class="line">            if (newEvent.isShow()) &#123;</span><br><span class="line">                newEvent &#x3D; null; &#x2F;&#x2F; 重复曝光，或者点击事件在曝光事件前到达</span><br><span class="line">                break;</span><br><span class="line">            &#125;</span><br><span class="line">            if (newEvent.isClick() &amp;&amp; event.isClick()) &#123;</span><br><span class="line">                newEvent &#x3D; null; &#x2F;&#x2F; 重复点击事件</span><br><span class="line">                break;</span><br><span class="line">            &#125;</span><br><span class="line">            iter.remove(); &#x2F;&#x2F; 高优先级的事情会覆盖低优先级的事情</span><br><span class="line">            if (null &#x3D;&#x3D; newEvent.getItemTrackData()) &#123;</span><br><span class="line">                newEvent.setItemTrackData(event.getItemTrackData());</span><br><span class="line">            &#125;</span><br><span class="line">            continue;</span><br><span class="line">        &#125;</span><br><span class="line">        if (current - event.getTimestamp() &lt; config.cacheTimeSpan)</span><br><span class="line">            continue;</span><br><span class="line"></span><br><span class="line">        INDArray xt &#x3D; event.getFeature(config);</span><br><span class="line">        INDArray x &#x3D; xt.transpose();</span><br><span class="line">        A.addi(x.mmul(xt));</span><br><span class="line">        double reward &#x3D; event.getReward();</span><br><span class="line">        if (reward &gt; 0.0)</span><br><span class="line">            b.addi(x.muli(reward));</span><br><span class="line">        iter.remove();</span><br><span class="line">        if (event.isShow())</span><br><span class="line">            showConsumedCount ++;</span><br><span class="line">        else if (event.isClick())</span><br><span class="line">            clickConsumedCount ++;</span><br><span class="line">    &#125;</span><br><span class="line">    if (null &#x3D;&#x3D; newEvent)</span><br><span class="line">        return 0;</span><br><span class="line">    if (newEvent.getType().equals(EventType.BUY)) &#123;</span><br><span class="line">        &#x2F;&#x2F; 购买事情立即消费</span><br><span class="line">        INDArray xt &#x3D; newEvent.getFeature(config);</span><br><span class="line">        if (null &#x3D;&#x3D; xt) &#123;</span><br><span class="line">            LogPushUtil.push(&quot;BuyFeatureMissingEvent&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        else if (xt.length() &#x3D;&#x3D; b.length()) &#123;</span><br><span class="line">            INDArray x &#x3D; xt.transpose();</span><br><span class="line">            A.addi(x.mmul(xt));</span><br><span class="line">            double reward &#x3D; newEvent.getReward();</span><br><span class="line">            b.addi(x.muli(reward));</span><br><span class="line">            LogPushUtil.push(&quot;BuyEventConsumed&quot;);</span><br><span class="line">            records +&#x3D; config.updateRecords;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; else if (StringUtils.isNotEmpty(newEvent.getItemTrackData())) &#123;</span><br><span class="line">        queue.add(newEvent);</span><br><span class="line">        checkQueueIsFullOrNot(config.cacheTimeSpan &#x2F; 2, config);</span><br><span class="line">    &#125;</span><br><span class="line">    if (showConsumedCount &gt; 0) &#123;</span><br><span class="line">        records +&#x3D; showConsumedCount;</span><br><span class="line">        LogPushUtil.push(&quot;ShowEventConsumed&quot;, showConsumedCount);</span><br><span class="line">    &#125;</span><br><span class="line">    if (clickConsumedCount &gt; 0) &#123;</span><br><span class="line">        records +&#x3D; clickConsumedCount;</span><br><span class="line">        LogPushUtil.push(&quot;ClickEventConsumed&quot;, clickConsumedCount);</span><br><span class="line">    &#125;</span><br><span class="line">    if (records &gt;&#x3D; config.updateRecords) &#123;</span><br><span class="line">        writeToRedis(config);</span><br><span class="line">    &#125;</span><br><span class="line">    return records;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在线推荐引擎计算每个商品的ucb分数的代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">private void parallelGetLinUcbScore(Session session, INDArray features, List&lt;Item&gt; items) throws InterruptedException &#123;</span><br><span class="line">    int concurrency &#x3D; Math.min(session.config.linUcbConcurrency, items.size());</span><br><span class="line">    int num &#x3D; items.size() &#x2F; concurrency;</span><br><span class="line"></span><br><span class="line">    ExecutorService es &#x3D; session.context.getThreadExecutorService(session.reqId, session.reqId.getSceneId());</span><br><span class="line">    final CountDownLatch countDownLatch &#x3D; new CountDownLatch(concurrency);</span><br><span class="line">    int left &#x3D; items.size() - num * concurrency;</span><br><span class="line">    int start &#x3D; 0, end &#x3D; num;</span><br><span class="line">    for (int i &#x3D; 0; i &lt; concurrency; ++i) &#123;</span><br><span class="line">        if (i &lt; left)</span><br><span class="line">            end++;</span><br><span class="line">        Logger.debug(&quot;prepare to start linucb score sub thread: [&quot; + start + &quot;, &quot; + end + &quot;]&quot;);</span><br><span class="line">        int finalStart &#x3D; start;</span><br><span class="line">        int finalEnd &#x3D; end;</span><br><span class="line">        Runnable runnable &#x3D; () -&gt; &#123;</span><br><span class="line">            long startTime &#x3D; System.currentTimeMillis();</span><br><span class="line">            try &#123;</span><br><span class="line">                getLinUcbScore(session, features, items, finalStart, finalEnd);</span><br><span class="line">            &#125; catch (Exception e) &#123;</span><br><span class="line">                String exception &#x3D; ExceptionUtils.getFullStackTrace(e);</span><br><span class="line">                Logger.error(&quot;linucb worker exception:&quot;, exception);</span><br><span class="line">            &#125;</span><br><span class="line">            finally &#123;</span><br><span class="line">                countDownLatch.countDown();</span><br><span class="line">            &#125;</span><br><span class="line">            long time &#x3D; System.currentTimeMillis() - startTime;</span><br><span class="line">            Logger.info(&quot;[Timer] compute sub linUcb scores [&quot;, finalStart, &quot;, &quot;, finalEnd, &quot;] taken&quot;, time, &quot;ms&quot;);</span><br><span class="line">        &#125;;</span><br><span class="line">        es.execute(TtlRunnable.get(runnable));</span><br><span class="line">        start &#x3D; end;</span><br><span class="line">        end &#x3D; start + num;</span><br><span class="line">    &#125;</span><br><span class="line">    countDownLatch.await(session.config.linUcbTimeOut, TimeUnit.MILLISECONDS);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void getLinUcbScore(Session session, INDArray features, List&lt;Item&gt; items, int start, int end) throws IOException &#123;</span><br><span class="line">    if (items.isEmpty() || null &#x3D;&#x3D; features)</span><br><span class="line">        return;</span><br><span class="line">    StopWatch stopWatch &#x3D; StopWatch.CreateStopWatchAndStart();</span><br><span class="line">    for (int i &#x3D; start; i &lt; end; ++i) &#123;</span><br><span class="line">        stopWatch.restart();</span><br><span class="line">        Item item &#x3D; items.get(i);</span><br><span class="line">        long pid &#x3D; item.getProductId();</span><br><span class="line">        byte[] matrix &#x3D; getLinUcbMatrix(session, pid);</span><br><span class="line"></span><br><span class="line">        INDArray feature &#x3D; features.getRow(i);</span><br><span class="line">        INDArray featureT &#x3D; feature.transpose();</span><br><span class="line">        Logger.detail(&quot;&lt;&quot;, i, &quot;&gt;&quot;, pid, &quot;item feature:&quot;, item.getTrackInfo(), &quot;vector:&quot;, feature);</span><br><span class="line">        if (matrix &#x3D;&#x3D; null) &#123;</span><br><span class="line">            double p &#x3D; session.config.linUcbAlpha * FastMath.sqrt(feature.mmul(featureT).getDouble(0));</span><br><span class="line">            item.setMatchScore(p);</span><br><span class="line">            Logger.info(&quot;&lt;&quot;, i, &quot;&gt; linucb new item:&quot;, pid, &quot;ucb score:&quot;, p);</span><br><span class="line">            continue;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ByteArrayInputStream in &#x3D; new ByteArrayInputStream(matrix);</span><br><span class="line">        INDArray[] Ab &#x3D; ByteSerde.fromByteArrayStream(in);</span><br><span class="line">        if (Ab.length &lt; 2)</span><br><span class="line">            continue;</span><br><span class="line">        INDArray invertA &#x3D; Ab[0];</span><br><span class="line">        INDArray b &#x3D; Ab[1];</span><br><span class="line">        Logger.detail(&quot;&lt;&quot;, i, &quot;&gt;&quot;, pid, &quot;[Timer] fetch matrix taken&quot;, stopWatch.click(), &quot;ms&quot;);</span><br><span class="line">        if (b.length() !&#x3D; feature.length()) &#123;</span><br><span class="line">            Logger.error(&quot;the length of b is&quot;, b.length(), &quot;should be&quot;, feature.length());</span><br><span class="line">            double p &#x3D; session.config.linUcbAlpha * FastMath.sqrt(feature.mmuli(featureT).getFloat(0));</span><br><span class="line">            item.setMatchScore(p);</span><br><span class="line">            continue;</span><br><span class="line">        &#125;</span><br><span class="line">        INDArray theta &#x3D; invertA.mmul(b);</span><br><span class="line">        INDArray thetaX &#x3D; theta.transposei().mmul(featureT);</span><br><span class="line">        INDArray temp &#x3D; feature.mmuli(invertA).mmul(featureT);</span><br><span class="line">        double p &#x3D; thetaX.getDouble(0);</span><br><span class="line">        item.setPreferScore(p);</span><br><span class="line">        p +&#x3D; session.config.linUcbAlpha * FastMath.sqrt(temp.getDouble(0));</span><br><span class="line">        item.setMatchScore(p);</span><br><span class="line">        Logger.detail(&quot;&lt;&quot;, i, &quot;&gt;&quot;, pid, &quot;[Timer] one iteration linucb score taken&quot;, stopWatch.click(), &quot;ms. match score:&quot;, p);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>实现中矩阵计算的部分，用了ND4J（<a href="https://nd4j.org/）的库。">https://nd4j.org/）的库。</a></p><h2 id="6-业务效果"><a href="#6-业务效果" class="headerlink" title="6. 业务效果"></a>6. 业务效果</h2><p>经过线上充分的A/B测试，最终测得LinUCB算法的UV CTR相对基准桶提升25%+，UV价值提升20%+。并且算法能够很好地支持商品动态上下架。</p><h2 id="7-参考资料"><a href="#7-参考资料" class="headerlink" title="7. 参考资料"></a>7. 参考资料</h2><p>[Lihong Li, et al, 2010] A Contextual-Bandit Approach to Personalized News Article Recommendation.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;推荐系统选择商品展现给用户，并期待用户的正向反馈（点击、成交）。然而推荐系统并不能提前知道用户在观察到商品之后如何反馈，也就是不能提前获得本次推荐的收益，唯一能做的就是不停地尝试，并实时收集反馈以便更新自己试错的策略。目的是使得整个过程损失的收益最小。这一过程就类似与一个赌徒在赌场里玩老虎机赌博。赌徒要去摇老虎机，走进赌场一看，一排老虎机，外表一模一样，但是每个老虎机吐钱的概率可不一样，他不知道每个老虎机吐钱的概率分布是什么，那么每次该选择哪个老虎机可以做到最大化收益呢？这就是多臂赌博机问题（Multi-armed bandit problem, MAB）。&lt;/p&gt;
&lt;p&gt;MAB问题的难点是Exploitation-Exploration(E&amp;amp;E)两难的问题：对已知的吐钱概率比较高的老虎机，应该更多的去尝试(exploitation)，以便获得一定的累计收益；对未知的或尝试次数较少的老虎机，还要分配一定的尝试机会（exploration），以免错失收益更高的选择，但同时较多的探索也意味着较高的风险（机会成本）。&lt;/p&gt;
&lt;p&gt;Bandit算法是一类用来实现Exploitation-Exploration机制的策略。根据是否考虑上下文特征，Bandit算法分为context-free bandit和contextual bandit两大类。&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="算法模型" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%AE%97%E6%B3%95%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="推荐系统" scheme="http://xudongyang.coding.me/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="LinUCB" scheme="http://xudongyang.coding.me/tags/LinUCB/"/>
    
    <category term="在线学习" scheme="http://xudongyang.coding.me/tags/%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="E&amp;E" scheme="http://xudongyang.coding.me/tags/E-E/"/>
    
  </entry>
  
  <entry>
    <title>商品人气分模型</title>
    <link href="http://xudongyang.coding.me/item-pop-score/"/>
    <id>http://xudongyang.coding.me/item-pop-score/</id>
    <published>2018-04-10T09:27:29.000Z</published>
    <updated>2020-12-04T08:17:21.907Z</updated>
    
    <content type="html"><![CDATA[<p>在电商平台中，量化每个商品的静态质量及受欢迎的程度有着重要的意义。我们把这个量化值称之为商品人气分。商品人气分在搜索排序、个性化推荐排序及推荐候选集截断、竞价广告系统中都有着重要的应用。</p><p>商品人气分受哪些因素的影响，以及这些因素最终如何共同决定商品人气分值？本文总结了一个实际系统中人气分模型的构建过程，从特征和模型两个角度来回答上述两个问题。<br><a id="more"></a></p><h2 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h2><p>多维度交叉统计特征是一类重要的特征来源，主要有以下4个维度：实体、时间段、行为类型、统计量。</p><ol><li>实体维度：商品、品牌、商家（店铺）、叶子类目、一级类目等。</li><li>时间维度：1天、3天、7天、14天、30天、时间衰减加权等。</li><li>行为维度：曝光、浏览、收藏、加购、购买、评级、商详页停留时间、是否退货等。</li><li>统计维度：数量、人数、频率、排名（百分比）、点击率、转化率、金额等。</li></ol><p>具体地，每个特征从以上4个维度中各取一到两个进行组合，再从历史数据中统计该组合特征最终的特征值。比如，商品（实体）最近1天（时间）的曝光（行为）量（统计指标）；商品所在店铺（实体）最近30天（时间）的销量（行为类型+统计维度）；商品（实体）最近7天（时间）的平均成交（行为）单价（统计）在同一叶子类目下的排名百分比（统计）；等等。由以上方法产生的特征数量级相当于4个维度的笛卡尔积。可以看出这些特征覆盖了大家常说的销售额、销售量、转化率、评论数、好评率、差评率、退货率、加购数、收藏关注度、详情页访问深度等方方面面。</p><p>另外还有一些不便归类到上述4个维度的特征，比如商品“年龄”（从上架到目前为止的时间间隔），DQC，店铺DSR，ID类特征（如一级类目）等。</p><h2 id="样本"><a href="#样本" class="headerlink" title="样本"></a>样本</h2><p>最近1天的成交日志留着生成训练目标（该商品当天有成交则为正样本，当天没有成交则为负样本），1天前的一个月的各类日志用来统计特征值，这样便可以生成1天的训练数据。</p><p>为了有足够数量的训练样本，我们取7天的训练数据的并集作为最终的训练集，同时留一到两天的数据作为验证集合测试集。流程如下图所示。</p><p><img src="/item-pop-score/sample.png" alt></p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>选用了GBDT作为待拟合的模型，损失函数为binaryLogLoss函数，最终模型的结果解释为商品未来1天有成交的概率。之所以选择GBDT模型，是因为一方面我们需要足够的非线性拟合能力；另外一方面是因为GBDT算法足够简单，在大多数任务中都表现良好，并且开源的工具也比较成熟。</p><p>模型调参基本遵循业界的经验值，同时各个参数在小范围内用GridSearch的方法交叉验证取得。特别值得一提的是设置样本权重对最终效果的提升有很大帮助，具体地，所有负样本的权重设置为1，正样本的权重设置为该商品在当天的成交件数。</p><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p>在我们公司多个推荐场景的实测结果，与没有人气分的基准桶相比，UV点击率和UV价值都取得了5%~10%左右的提升。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在电商平台中，量化每个商品的静态质量及受欢迎的程度有着重要的意义。我们把这个量化值称之为商品人气分。商品人气分在搜索排序、个性化推荐排序及推荐候选集截断、竞价广告系统中都有着重要的应用。&lt;/p&gt;
&lt;p&gt;商品人气分受哪些因素的影响，以及这些因素最终如何共同决定商品人气分值？本文总结了一个实际系统中人气分模型的构建过程，从特征和模型两个角度来回答上述两个问题。&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="http://xudongyang.coding.me/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="GBDT" scheme="http://xudongyang.coding.me/tags/GBDT/"/>
    
  </entry>
  
</feed>
